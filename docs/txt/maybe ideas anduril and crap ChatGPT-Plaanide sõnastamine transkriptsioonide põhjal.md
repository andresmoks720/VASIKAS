# Plaanide sõnastamine transkriptsioonide põhjal

**User:** Andres Moks (andres.moks@gmail.com)  
**Created:** 12/14/2025 3:28:31  
**Updated:** 12/27/2025 1:38:46  
**Exported:** 12/27/2025 1:39:40  
**Link:** [https://chatgpt.com/c/693e12be-1f58-8329-af80-66c64061a2dd](https://chatgpt.com/c/693e12be-1f58-8329-af80-66c64061a2dd)  

## Prompt:
sõnasta transkriptsioonide põhjal: mis on plaanid (ajakavade ja summadega, kui on aru saada)

## Response:
Thought for 43s

Allpool on transkriptsioonidest kokku korjatud “plaanipilt” (ajakavad + summad/mahud seal, kus neid mainitakse).

1) Suur siht ja lõpptulemus
---------------------------

*   Eesmärk on ehitada “troonimüür”/drooniseire ökosüsteem: **sensorid + nende andmete koondamine ühte infosüsteemi/kaardirakendusse**, et korrapidaja/juhtimine näeks ühtset pilti, mitte eraldi “iga seadme oma liidest”.
    Tannar 121225 Recording 355\_res…
*   **Lõppeesmärk projektis:** idapiir on sensoritega kaetud ja süsteem suudab näidata/anda esmase tuvastuse (kaardirakenduse “valmis produkt”).
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…

2) Ajakava (mis kuupäevadest läbi käivad)
-----------------------------------------

*   Projekti raam-ajaks räägitakse **kuni 2027. aasta lõpuni** (“siis pannakse projekt kinni”), ning eesmärk on selleks ajaks **kogu idapiir sensoritega kaetud**.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…
*   Samas kõlab ootus, et **seda tõenäoliselt pikendatakse** (ehk 2027 lõpp on “baasverstapost”, mitte tingimata päris lõpp).
    Tannar 121225 Recording 355\_res…

3) Rahastus ja hanked (summad, mis mainitakse)
----------------------------------------------

*   **Detsembris / “järgmine nädal”** mainitakse tulevat **taotlust 250 miljoni** peale, millest omakorda räägitakse, et esitatakse **60 miljoni** taotlus, et **katta piiril 38 positsiooni radarite ja sensoritega**.
    Tannar 121225 Recording 355\_res…
*   Radarite poolel käib läbi, et **radarid tulevad “neljasaja kuuekümne miljonilisest” hankest** (kaitseväega seotud suur hange), kuhu “peaks radarid tulema”.
    Tannar 121225 Recording 355\_res…
*   Lisaks on mainitud, et piiril olev tehnika tuleb **eri allikatest (riigirahastus, välisrahastus, erinevad projektid)**, mis teeb “ühte plaani” juhtimise keerukamaks.
    Tannar 121225 Recording 355\_res…

4) Mis tehakse kohe / prototüübi “mänguväljak”
----------------------------------------------

*   Prototüübis arvestatakse: **kasutame olemasolevaid sensoreid + see, mis “DevSec’iga tuleb”**.
    Tannar 121225 Recording 355\_res…
*   Konkreetsed “olemas” asjad, mis mainitakse prototüübi kontekstis:
    *   piiril **3 Lanteroni seadet**
        Tannar 121225 Recording 355\_res…
    *   Transpordiameti/VLA kaudu **11 seadet** (paigutus sõltub vajadusest; kõlab ka Tallinnakatte mõte).
        Tannar 121225 Recording 355\_res…
    *   “tulevad järjest sensorid”: **“20 km – 6 tükki”** (tehniline kirjeldus justkui tehtud, aga “keegi ei tea täna, millised nad välja näevad / kas töötavad”).
        Tannar 121225 Recording 355\_res…

5) Mahud/numbrid (orienteeruvad, transkriptsioonis “kokku arvestatud”)
----------------------------------------------------------------------

Need kõlavad pigem planeerimis- ja dimensioneerimisloogikana (mitte lõplik kinnitatud ost):

*   **Radarid:** “praegu radarid on 15” ja “tulevikus (tuimalt \*5) 75”.
    Sys Recording 354\_resampled\_mon…
*   “Positsioonid” (laiem katteplaneerimine): läbi käib **68 positsiooni** (sh linnad nagu Tallinn/Pärnu/Narva; linnas “4 positsiooni kindlasti”).
    Sys Recording 354\_resampled\_mon…
*   **Mobiilsed RF sensorid:** **90 tk** (jaotus prefektuuridele/üksustele on transkriptsioonis lahti seletatud).
    Sys Recording 354\_resampled\_mon…
*   **Remote ID:** **210 tk** (akustika hetkel “0”, aga arvestatakse, et see kiht võib tulla).
    Sys Recording 354\_resampled\_mon…

6) Tehniline suund (kuidas “ehitatakse”, mitte ainult “ostetakse”)
------------------------------------------------------------------

*   Suund on, et hangitavad seadmed peaksid olema **integreeritavad / “plug-in-play”** ja tehnilised nõuded/integreeritavus peavad ühtima arendatava süsteemiga.
    Tannar 121225 Recording 355\_res…
*   Koostöö kaitseväega: täna kirjeldatakse olukorda, kus **on “üks kaitseväe arvuti kuskil piiri peal”, mis näitab KV sensorite infot**; edasises süsteemis tahetakse kokkulepitud alustel ja õigustega seda pilti jagada (rolli- ja õiguspõhine nähtavus).
    Tannar 121225 Recording 355\_res…

Kui sul on vaja, saan sama sisu sõnastada ka “üheleheküljeliseks projektibriefiks” (eesmärk–verstapostid–hanked/rahad–riskid–järgmised sammud) või panna plaanid tabelisse (verstapost / tähtaeg / eelarveraam / vastutaja).

## Prompt:
vaata failides olevat infot ning paku välja edasine tegevuskava: mis tegevustega peaks jätkama (ainult infosüsteemi vaates, mitte füüsiline pool, finants ega juriidika)

## Response:
Thought for 47s

Siin on edasine tegevuskava **ainult infosüsteemi vaates**, nii nagu transkriptsioonidest välja joonistub: ehitada “tarkvarakokku”/ühtne pilt, kuhu eri sensorite info kokku jookseb ja mida eri asutused näevad rolli järgi.

Ppa\_resampled\_mono\_PRE180\_vadli…

1) Raamista toode: kellele, mis otsuse jaoks, mis ekraanil
----------------------------------------------------------

**Jätkata kohe nõuete ja kasutusjuhtude kokkupanekuga**, sest transkriptsioonides kõlab mitu eri “vaadet”:

*   “Üks terviklik Eesti droonipilt” juhtimiskeskuses, et ei killustuks sektoriteks.
    Sys Recording 354\_resampled\_mon…
*   “Lihtne vaade” (55+ operaatorile): võimalikult vähe kihte, selge kaart, lihtsad staatused/tegevused.
    Tannar 121225 Recording 355\_res…
*   Operatsioonivaade: samale kaardile kihid juurde, detailid, ajalugu, filtrid.
    Tannar 121225 Recording 355\_res…

Praktiline väljund: 10–15 “user story’t” (korrapidaja, juhtimiskeskuse operaator, patrull/“kilp”, ETOD turvatiim, KV staap) + 2–3 põhilist töövoogu (tuvastus → kontroll → teavitus → tegevus).

Tannar 121225 Recording 355\_res…

Ppa\_resampled\_mono\_PRE180\_vadli…

2) Otsusta arhitektuuri “süda”: standardne andmemudel + adapterid
-----------------------------------------------------------------

Transkriptsioonides on läbiv mõte: **palju eri sensoreid/asutusi**, aga üks infosüsteem.

Ppa\_resampled\_mono\_PRE180\_vadli…

Selleks tasub jätkata nii:

*   **Kanooniline sündmuse- ja “track’i” andmemudel** (Detection / Track / Asset / Coverage / Alert).
*   **Adapteri/plugina muster**: iga tootja/andmeallikas räägib “oma keelt”, aga teie süsteemi siseneb alati sama skeemiga sündmus. (Siin haakub ka “Anduril on modulaarne, standardid ees” mõttega: võtta ideena, mitte religioonina.)
    Tannar 121225 Recording 355\_res…
*   **Integratsiooni “leping”**: JSON skeemid, versioonimine, testvektorid, veakoodid, “minimaalne kohustuslik väli” vs “valikuline luksus”.

Tulemus: üks koht, kuhu uusi sensoreid on võimalik lisada ilma kogu süsteemi ringi ehitamata (mida te ka sõnaliselt tahate).

Tannar 121225 Recording 355\_res…

3) Ehita ligipääs ja nähtavus õiguste järgi (mitte “eraldi süsteemid”)
----------------------------------------------------------------------

See on transkriptsioonides väga konkreetne vajadus: **eri kasutajad/asutused ei tohi näha sama pilti**, ja KV puhul on lisaks “maskimine”.

Tannar 121225 Recording 355\_res…

Tannar 121225 Recording 355\_res…

Ppa\_resampled\_mono\_PRE180\_vadli…

**Jätkata tegevustega:**

*   Rolli- ja atribuudi-põhine ligipääs (RBAC/ABAC): _organisatsioon + geograafia + ülesanne + olukorra režiim_ (nt tava / operatsioon).
    Tannar 121225 Recording 355\_res…
*   Kaardikihid ja objektid filtreeritakse serveri poolel (mitte ainult UI-s).
*   “Mõjuala” loogika: korrapidajale kuvad katte-ala/“covered area”, mitte sensorite täpseid positsioone või tundlikke detaile.
    Tannar 121225 Recording 355\_res…

4) Tee päris “vertikaallugu”: 1 kaart + 1 andmeallikas + 1 häire
----------------------------------------------------------------

Praegu kirjeldatakse prototüübi faasi kui “paneme seadmed külge, näitame integreeritud andmeid serveritest” ja tootmisfaas tuleb hiljem.

Ppa\_resampled\_mono\_PRE180\_vadli…

**Edasi tasub jätkata vertikaallõikega**, mis tõestab süsteemi loogika ära:

*   Ingest → normaliseerimine → kaart (reaalajas) → lihtne staatus (tuvastatud/mitte, “roheline” registreeritud jne) → üks häirekanal (nt SMS/teavitus operaatorile).
    Tannar 121225 Recording 355\_res…
*   “Töötab veebis” põhimõte: sisselogimine, rollid, 1 URL, ilma lokaalsete installitsirkusteta.
    Tannar 121225 Recording 355\_res…

See annab kohe “toote tunnetuse” ja paljastab varakult, mis on päriselt raske (latentsus, filtrid, kasutajaloogika, andmekvaliteet).

5) Planeeri KV andmevoo päris-integratsioon (asenda “üks arvuti piiril”)
------------------------------------------------------------------------

Hetkeseisuna on mainitud, et koostöö on sisuliselt “üks KV arvuti piiri peal näitab midagi”. Infosüsteemi vaates on see ajutine hack.

Tannar 121225 Recording 355\_res…

**Jätkata sihipäraselt:**

*   defineeri KV feed’i integreerimisviis (API / message bus / failipõhine vahetus) + milline info on _juba maskitud_ vs mis maskitakse teie poolel;
*   tee see samasse adapterimudelisse nagu kõik muu (et KV ei oleks “erisüsteem”).
    Tannar 121225 Recording 355\_res…

6) UI/UX: kaks režiimi, mitte üks “überpaneel”
----------------------------------------------

Transkriptsioonides kõlab väga selgelt, et üks ekraan ei sobi kõigile: Ljudmilla-operaator vs operatsioon/staap.

Tannar 121225 Recording 355\_res…

**Jätkata:**

*   “Lihtrežiim” (vaikimisi): kaart + minimaalsed ikoonid + selged tegevusnupud.
*   “Prorežiim”: kihid (sensoritüübid, ajalugu, filtrid, tsoonid), detailvaade track’ile, audit.
*   Sama backend, sama õiguste mudel.

7) DevOps/ops-hügieen: standardne paigaldus, logid, mõõdikud
------------------------------------------------------------

Kirjeldatakse, et protos pannakse tootjate Dockeri/Ubuntu VM-idega asju püsti ja tehakse tunnelid/võrgud korda.

Ppa\_resampled\_mono\_PRE180\_vadli…

Infosüsteemi jätkutegevus (ilma võrgu-füüsika detailidesse minemata):

*   standardne “deployment blueprint” (konteinerid, konfiguratsioon, secrets, keskkonnad dev/test/prod);
*   keskne logimine + auditeerimine (eriti, kui eri asutused ja eri õigused);
*   monitooring (latentsus, sündmuste maht, adapterite vead) – sest muidu hakkab “kõik hangub ära” olema püsielu.
    Tannar 121225 Recording 355\_res…

8) “Integratsiooni kvaliteedivärav”: testid, simulaator, sertifitseerimine
--------------------------------------------------------------------------

Kuna sensorite maailm on kirju ja jutt käib standarditest/protokollidest ning “tehke nii, et kirjutate sinna auku”, siis infosüsteemi mõttes on vaja kontrolli, et liidestused ei lagundaks tervikut.

Tannar 121225 Recording 355\_res…

**Jätkata:**

*   adapterite automaattestid + “sensorisimulaator” (et arendaja saab ilma päris seadmeta liidestust testida);
*   versioonihaldus andmeskeemidele;
*   “minimum integration checklist” (sündmus, asukoht, usaldus, ajatempli kvaliteet, seadme ID jne).

* * *

Kui panna see üheks lauseks: **järgmine mõistlik samm on teha vertikaallugu (andmevoog → kaart → õigused → häire) samaaegselt selge standardse andmemudeli ja õiguste/vaadete raamiga**, sest need kolm teemat korduvad transkriptsioonides kõige rohkem ja on kogu infosüsteemi “selgroog”.

Ppa\_resampled\_mono\_PRE180\_vadli…

Tannar 121225 Recording 355\_res…

Tannar 121225 Recording 355\_res…

## Prompt:
kes võiks olla potentsiaalsed osapooles kes huvitatud projektis osalemisest / andmetest?

2/2

## Response:
Thought for 59s

Transkriptsioonidest joonistub üsna selge “ökosüsteem”: üks keskne drooniseire infosüsteem, kuhu **eri asutused/objektid annavad andmeid** ja kust **eri rollid tarbivad ühist pilti** (õiguste/maskimisega).

Ppa\_resampled\_mono\_PRE180\_vadli…

Tannar 121225 Recording 355\_res…

### Riigi “põhikasutajad” (operatiivne pilt ja reageerimine)

*   **PPA**: juhtimiskeskus, korrapidajad, kordonid/piiripunktid, patrullid – nemad on see “igapäevane kasutaja”, kellele peab pilt olema arusaadav ja töövood (häire → kontroll → reageerimine) toimima.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…
*   **Häirekeskus / häda(l)a-juhtimiskeskus**: mainitakse ideena, et pilt/roll võib liikuda nende meeskonda; lisaks on neil operatiivlogika patrullile info edastamiseks.
    Sys Recording 354\_resampled\_mon…
    Tannar 121225 Recording 355\_res…
*   **Keskkriminaalpolitsei ja isikukaitse funktsioon**: tekib vajadus “objekti/isikukaitse vaatele” ja sündmuste eskaleerimisele.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…

### Kaitse- ja julgeolekupartnerid (andmete jagamine, maskimine, ristkasutus)

*   **Kaitsevägi** (sh peastaap): nimetatakse põhipartneriks; neil on oma sensoripilt ning rõhutatakse, et nähtavus peab olema rollipõhine ja osa infot on maskitud.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…
*   **Kaitseliit**: mainitakse samas rivis kui KV ja Transpordiamet kui võimalikud seadmete/andmete omanikud, kelle info võiks koonduda kesksesse “tarkvarakokku”.
    Ppa\_resampled\_mono\_PRE180\_vadli…
*   **KaPo ja VLA**: nimetatakse otsesõnu struktuuriüksustena, kes annavad sisendeid ja kellel on huvi ligipääsu vastu (aga läbi teie süsteemi, mitte “otse sensoritele”).
    Tannar 121225 Recording 355\_res…

### Tsiviil-lennunduse ja “luba/registri” andmeallikad

*   **Transpordiamet**: käib läbi nii seadmete (nt “tuleb 11 seadet”) kui ka loa/õiguse info (kes tohib lennata). Seega neil on selge roll nii andmeandjana kui rikastava registri/loaandmete pakkujana.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…
*   **Droonide registreerimis-/loaandmed laiemalt**: transkriptsioonis käib läbi ka “registreeritud droon, kontakt, telefon” tüüpi info (mainitakse ka Maksu- ja Tolliametit, võimalik et kõnekeelne/ebatäpne viide registrile). Igatahes on “kes on droon ja kas tal on õigus” infosüsteemi jaoks keskne rikastuskiht.
    Tannar 121225 Recording 355\_res…
    Tannar 121225 Recording 355\_res…

### Kriitiline taristu ja objektikaitse (andmete tarbijad + kohati andmeandjad)

*   **“ETOD/ETTO” ehk elutähtsa teenuse osutajad ja eriti tähtsad objektid**: neid mainitakse kui kihte, kellel oleks oma “seirepildi” huvi ja kelle katvus aitab “kogu Eesti ära katta”.
    Sys Recording 354\_resampled\_mon…
    Ppa\_resampled\_mono\_PRE180\_vadli…
*   **Eesti Energia** (nimeliselt): tuuakse näiteks partnerist, kes tahaks seirepilti ning on valmis panustama (osalemishuvi andmete mõttes on selge).
    Ppa\_resampled\_mono\_PRE180\_vadli…
*   **Objekti valdaja / turvatiim / valvekeskus**: kirjeldatakse mudelit, kus objekti eest vastutaja istub (häda)juhtimiskeskuse lähedal ja vajab pilti oma objekti kaitseks.
    Tannar 121225 Recording 355\_res…
*   **Eraobjektid, kes paigaldavad oma sensori** (nt “Viljandis tehas paneb oma RFI”): need on potentsiaalsed andmeandjad, kui neil on motivatsioon ja süsteem suudab seadme “ökosüsteemi” seadistada.
    Tannar 121225 Recording 355\_res…

### Tehnilised/teostuspartnerid (infosüsteemi ehitus ja integreerimine)

*   **IT/integratsioonipartnerid** (nt Helmes on jutust läbi käiv näide “oma sektori vaatest”): kui lahendus on rollipõhine ja sektoriteks jagatav, on neil huvi olla kas teostaja või erivaate tarbija (sõltub, mis rolli nad päriselt projektis kannavad).
    Sys Recording 354\_resampled\_mon…

### Piiriülene mõõde (tulevikupistik)

*   Mainitakse ideetasandil “droonimüüri üle Baltikumi” ja et võiks jätta arhitektuuri “pistiku”, et kunagi liidestuda. See viitab potentsiaalsetele partneritele naaberriikides/regionaalsel tasemel (vähemalt mõtteharjutusena).
    Tannar 121225 Recording 355\_res…

Kui tahad, võin selle samast “osapoolte kaardist” teha kohe ka **andmevahetuse vaates** (kes on _andmeomanik_, kes on _tarbija_, mis on _minimaalne jagatav info_ ja mis vajab _maskimist_), sest see teema kordub transkriptsioonides eriti tugevalt KV/KaPo/VLA suunal.

Tannar 121225 Recording 355\_res…

Tannar 121225 Recording 355\_res…

## Prompt:
vaata eesti riigiameteid ja infrastruktuuri pakkujaid. kes võiks veel vajada ja milleks. ole loov! pikem ja ülepakutud nimekiri, millest hiljem välistada.

search other countries for similar participation and interest in cuas technologies. vaata siis kohalike vastavate asutuste tegevust ja katsu üle kanda vajadusi.

## Response:
Et saaksin pakkuda rikastatud ja mitmekesise nimekirja Eesti riigiasutustest ja infrastruktuuripakkujatest, kes võiksid olla huvitatud C-UAS (Counter-Unmanned Aircraft System) tüüpi infosüsteemist, palun täpsusta veel paari punkti:

1.  Kas sind huvitab ainult tsiviilvaldkond või ka sõjalised/kaitseliini asutused? (Näiteks Küberväejuhatus või Kaitseministeeriumi valdkond laiemalt)
2.  Kas tahad lisada ka teadus- ja arendussektori huvilisi (nt TalTech, Tartu Ülikool, KBFI jne)?
3.  Kas eeldame, et osapooled võivad olla kas andmeandjad, tarbijad või mõlemat? Või keskendume ainult neile, kes tahaksid andmeid näha/kasutada?
4.  Kas soovid kaasata ka erasektori suuremad tegijad (Tallinna Sadam, Elering, Eesti Raudtee, Telia vms)?

Kui need on paigas, lähenen paralleelselt ka teiste riikide (nt Soome, Saksamaa, UK, USA) praktikale, et leida, millised asutused on seotud C-UAS tegevustega ja keda võiks Eestis peegeldada.

## Prompt:
projekti eesmärk on rahuaegne, kuid teeme koostööd Kaitseministeeriumi asutustega. Üldiselt on nad juba projektis sees ning ilmselt esindavad ennast edukalt ise.

teadussektoril tekib ilmselt probleeme andmetele juurdepääsu legaalsusega (juriidiline vajadus).

huvitavad need kes oleks andmete kasutajad. 

erasektoris on teemaks need need kes vajavad drooniseiret - infrastruktuuri pakkujad keda välja tõid võiks kindlasti huvituda. (telia - ma ei tea kas nad nii huvitatud kui suure füüsilise baasiga nagu elering)

## Response:
Selge! Hakan uurima, millised ametid ja infrastruktuuriettevõtted teistes riikides on seotud C-UAS (droonituvastus- ja tõrje) süsteemidega ning milleks nad neid kasutavad. Vaatan ka, kas sealt saab tuletada paralleele Eesti konteksti, keda võiks veel kaasata andmete kasutajatena. Annan sulle teada, kui nimekiri on koos!

Research completed in 11m · 13 sources · 69 searches

## Response:
Potentsiaalsed droonitõrje tehnoloogia huvirühmad Eestis ja rahvusvahelised näited
==================================================================================

Eesti riigiasutused, korrakaitse ja julgeolek
---------------------------------------------

*   **Politsei- ja Piirivalveamet (PPA)** – Vastutab sisejulgeoleku ja piirikontrolli eest. PPA huvi drooniseire ja -tõrje vastu on suur, kuna droone võidakse kasutada ebaseaduslikuks piiriületuseks, salakaubaveoks või avaliku korra rikkumiseks. Näiteks on ka Eestis tuvastatud juhtumeid, kus drooniga püütakse üle vanglamüüri keelatud esemeid toimetada[digiriiul.sisekaitse.ee](https://digiriiul.sisekaitse.ee/bitstream/handle/123456789/3733/Olukorrast%20piiril%208.pdf?sequence=1&isAllowed=y#:~:text=Sisekaitseakadeemia%20digiriiul,Droone%20kasutati%20vangidele%20keelatud). PPA-le on oluline reaalajas info loata või ohtlike droonide kohta, et kiiresti sekkuda ja tagada avalike ürituste (nt suured laulupühad, spordiüritused) ning kriitiliste objektide turvalisus.
*   **Kaitsepolitseiamet (KaPo)** – Eesti sisejulgeoleku ja vastuluure asutus, kelle ülesannete hulka kuulub kõrgemate riigitegelaste, strateegiliste objektide ja ürituste turvamine. KaPo oleks huvitatud droonide tuvastamise võimekusest, et ennetada võimalikke droonirünnakuid või luuretegevust riigivastaste poolt. Näiteks VIP-visiitide või riiklike tähtsündmuste ajal aitab droonitõrje kaitsta _rahuaegsel_ perioodil terrorismiohu või pahatahtlike intsidentide eest.
*   **Justiitsministeerium ja Vanglateenistus** – Vanglad on droonitõrje ilmne vajaja, sest maailmas (sh Eestis) on droone korduvalt kasutatud vangidesse keelatud esemete smugeldamiseks. Rahvusvahelises plaanis peetakse droone isegi vanglate _“number üks”_ ohuks: Ühendkuningriigis kasvas droonide poolt toime pandud vanglaincidentide arv mõne aastaga kümnekordseks, ulatudes üle 1000 juhtumi aastas[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=Official%20figures%20showed%20the%20number,to%201%2C063%20incursions%20last%20year). Drooni abil üritatakse vangidele toimetada narkootikume, telefone ja isegi relvi, mis tekitab personali ja kinnipeetavate jaoks tõsiseid julgeolekuriske[securityjournalamericas.com](https://securityjournalamericas.com/threat-drones-critical-infrastructure/#:~:text=Outside%20of%20airports%2C%20correctional%20facilities,drone%20technology). Eesti vanglad (nt Tallinna Vangla) on samuti katsetanud moodsaid droonitõrjesüsteeme, seega Vanglateenistus oleks kindlasti andmete ja tehnoloogia kasutaja.
*   **Siseministeerium (sh Lennuamet ja Lennundusohutus)** – Tsiviillennunduse järelvalve eest vastutavad asutused (Transpordiameti lennundusüksus) vajavad drooniseiret lennundusohutuse tagamiseks. Lennuamet kehtestab droonidele lennupiirangualasid (nt lennujaamade ümbruses, strateegiliste objektide kohal) ning droonituvastus aitaks tuvastada piirangute rikkujaid. Kuna droonid võivad ohtu seada mehitatud lennuliiklust, on see lennundusohutuse küsimus. Euroopa Lennuohutusagentuur (EASA) on juba avaldanud juhiseid, kuidas lennujaamad peaksid drooniintsidentidega toime tulema[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=European%20airports%20are%20at%20the,light%20of%20recent%20technological%20advancements)[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=1,provide%20accurate%20and%20comprehensive%20drone). Seega ka Eestis teeks koostööd siseministeeriumi lennundusvaldkond, et integreerida droonitõrje meetmed tsiviillennunduse regulatsioonidesse.
*   **Eesti Lennuliiklusteenindus (EANS)** – Lennujuhtimise organisatsioon, kes vastutab lennuliikluse turvalisuse eest. EANS huvitub droonide tuvastusest eriti lennujaamade läheduses, et ennetada intsidente nagu 2018. aastal Gatwicki lennujaamas, kus loata droonid halvatasid päevadeks lennuliikluse. Ka Tallinnas on rahvusvaheline lennujaam, mille lähedal droonioht nõuab tähelepanu. Drooniseirevõrgustiku andmed võimaldaks lennujuhtidel ja häirekeskusel kiiremini reageerida, hoiatada ohustatud lennukeid ning vajadusel peatada lennutegevus kuni ohu möödumiseni. Rahvusvaheliselt investeerivad mitmed suured lennujaamad droonituvastussüsteemidesse, et vältida lennukatkestusi ja majanduslikku kahju[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=1,provide%20accurate%20and%20comprehensive%20drone).
*   **Päästeamet ja Häirekeskus** – Kuigi päästeteenistus ise droonitõrjet igapäevaselt ei teosta, on neil huvi drooniinfo vastu olukordades, kus droonid võivad segada hädaabitöid. Näiteks metsatulekahjude või suurõnnetuste kohal kehtestatakse tihti lennukeelualad; droonid, mis uudishimulikelt inimestelt sinna lendavad, võivad segada koptereid või päästetöid. Häirekeskus võiks saada drooniseiresüsteemist infot, et edastada hoiatusi (nt “õhuruumis on volitamata droon, päästekopter seiskab lennu”). See on pigem kaudne kasutus, kuid siiski osa laiemast pildist.
*   **Kaitseministeeriumi valitsemisala** – Kaitsevägi ja Kaitseliit panustavad projekti sõjalise _know-how_ ja radari-/sensorvõimekusega. Kuigi projekt ise on suunatud rahuaja kasutusjuhtudele, on kaitsevaldkonna asutused juba kaasatud ning esindavad oma vajadusi ise. Kaitseväel on olemas teatud droonivastased vahendid sõjaliste objektide kaitseks ning nad võivad jagada sensoriteavet tsiviilvõrgustikuga piiratud ulatuses (nt piirialadel). Kaitseliit korraldab tihti sisejulgeoleku toetusüritusi (nt Toompea turvamine õppustel), kus droonituvastus võib olla aktuaalne. Nende roll on pigem toetus ja koostöö – näiteks jagada õhuseire andmeid või nõustada taktikaliste meetmete osas, aga _rahuaegse taristu kaitse_ juhtroll jääb tsiviilasutustele.

Kriitilise taristu haldajad ja ettevõtted
-----------------------------------------

*   **Energeetika (elektri tootmine ja võrk)** – _Elering_ (Eesti elektri põhivõrgu haldaja) on silmapaistev näide: ettevõte plaanib 2026. aastaks välja arendada droonide **tuvastamise** ja **tõkestamise** võimekuse oma alajaamade ja liinide kaitseks[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Ka%20Elering%20otsib%20v%C3%B5imalust%2C%20kuidas,paigas%2C%20loodab%20ettev%C3%B5te%20ka%20seadusemuudatust). Droonid võivad elektritaristule tekitada kahju (näiteks kukkudes liinidele või kandes lõhkelaenguid). Praegu tohivad droone füüsiliselt alla tuua vaid riigi jõuametid, kuid riik arutab, kas lubada teatud kriitilise taristu omanikel ise teatud lihtsamaid tõrjemeetmeid rakendada[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Kliimaministeerium%20saatis%20eelmisel%20n%C3%A4dalal%20kirja,reaalset%20kaitset%20pakkuda%20ainult%20j%C3%B5uametid)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Indrek%20Link%20r%C3%B5hutas%2C%20et%20kui,see%20kindlasti%20laiemat%20ringi%20taristuhaldajaid). Elering ja teised energiavõrgu ettevõtted (nt _Elektrilevi_ ja _Eesti Energia_ tootmisüksused Narva elektrijaamades) soovivad drooniseiret, et õigeaegselt märgata kahtlaseid õhusõidukeid oma objektide kohal. Eesti elektrivõrk on elutähtis teenus – drooni rünnak olulisele alajaamale võiks halvata elektrivarustust. Seetõttu on energiafirmadel motivatsioon panustada droonitõrjesse, teha koostööd riigiga ning kasutada projekti raames kogutavaid andmeid oma riskianalüüsides.
*   **Kütuse- ja keemiatööstus** – Suured kütuseterminalid ja -laod (näiteks Muuga ja Paldiski sadamate kütusehoidlad, Alexela terminalid) kuuluvad samuti kriitilise taristu hulka. Keskkonna- ja Kliimaministeerium on juba pöördunud _Logistika ja Sadamate Liidu_ poole, et kaardistada, milliseid sadamaid, kütuseterminale ja muid objekte tuleks droonide eest kaitsta[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Kliimaministeerium%20saatis%20eelmisel%20n%C3%A4dalal%20kirja,reaalset%20kaitset%20pakkuda%20ainult%20j%C3%B5uametid). Plahvatusohtlike või keskkonnaohtlike ainete ladustamispaikades võib drooni pahatahtlik kasutus (nt lõhkeseadeldise kohaletoimetamine) põhjustada katastroofi. Seetõttu on kütusefirmad huvitatud droonide varajasest avastamisest. Samuti kehtivad paljudes sellistes kohtades lennukeelu alad, mida seni saavad jõustada ainult riigivõimu esindajad. Projektist saadav drooni seireinfo aitaks neil teha koostööd jõuametkondadega, et vajadusel kiiresti reageerida.
*   **Transpordi- ja logistikataristu**:
    *   _Lennujaamad_ – Tallinna Lennujaam (sh regionaal-lennuväljad nagu Tartu, Pärnu) on ühed peamised droonitõrje rakendajad. Lennujaama vahetus läheduses kehtivad lennupiirangud tsiviildroonidele, kuid viimaste aastate intsidentide valguses üle maailma (nt Gatwicki vahejuhtum) on lennujaamad investeerinud droonide detekteerimisse. Euroopa näitel on Riia lennujaam ja teisedki pidanud korduvalt reageerima loata droonidele oma õhuruumis[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=1,provide%20accurate%20and%20comprehensive%20drone)[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=The%20recurring%20drone%20incidents%20at,controlled%20detection%2C%20mitigation%2C%20and%20outcomes). Tallinnas on samuti olnud juhtumeid, kus lennujaama lähistel märgatud droonid on tekitanud häireid. Lennujaam soovib koostöös PPA ja Lennuliiklusteenindusega _reaalajas_ infot iga tuvastatud drooni kohta, et vältida ohtlikke olukordi ja vajadusel peatada lennud kuni olukorra lahenemiseni. Hiljuti arutleti isegi võimalust anda Tallinna Lennujaamale õigus droone tõrjuda erandkorras[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Ka%20sellisel%20juhul%20ei%20tuleks,l%C3%A4hedal%20peab%20olema%20eriti%20ettevaatlik) – see näitab lennujaamade suurt huvi ja vajadust.
    *   _Sadamad_ – Eesti suured sadamad (Tallinna Sadam oma erinevate sadamapiirkondadega – Vanasadam, Muuga, Paldiski – ning ka erasadamad nagu Sillamäe) on strateegilised sõlmpunktid, kus droonioht tuleb arvesse võtta. Sadamate kohal on tihti ajutised või alalised lennupiirangud turvalisuse huvides. Droonid võivad sadamates teostada luuretegevust (nt filmida militaar- või tollioperatsioone) või ohustada ohtlike kaupade käsitlemist. Kliimaministeeriumi pöördumine sadamate liidu poole[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Kliimaministeerium%20saatis%20eelmisel%20n%C3%A4dalal%20kirja,reaalset%20kaitset%20pakkuda%20ainult%20j%C3%B5uametid) kinnitab, et sadamad kaasatakse droonitõrje vajaduste kaardistamisse. Sadamad soovivad teada, kui mõni droon siseneb nende territooriumi kohale, et koostöös piirivalve ja politseiga riski maandada. Ka merel piirialadel on droonid teemaks – Soome kogemus näitab, et alates Ukraina sõja algusest on märgatud üle saja kahtlase drooni kriitiliste objektide lähistel, sh võimalikke piiriüleseid luuredroone[err.ee](https://www.err.ee/1609500322/soome-politsei-uurib-keelutsoonide-lahistel-lendavaid-kahtlaseid-droone#:~:text=Soome%20lennukeelutsoonide%20l%C3%A4histel%20on%20enam,seotud%20m%C3%B5ni%20v%C3%A4lisriik%2C%20kirjutab%20Yle). Seega on ka mereturvalisuse tagajad (näiteks Veeteede Amet) huvitatud drooniseire andmetest.
    *   _Raudtee_ – Eesti Raudtee infrastruktuur (raudteeliinid, jaamad, signaliseerimissüsteemid) võiks samuti kuuluda loetellu. Suure ulatusega füüsiline taristu on potentsiaalne drooni sihtmärk – näiteks võiks pahatahtlik droon üritada kahjustada kontaktvõrku või tekitada õnnetusi. Raudtee-ettevõtteid huvitab droonitõrje eelkõige koostöö korrakaitsega: kui raudteekoridoris lendab loata droon (nt suurürituse ajal rongiliikluse kohal), tuleks sellest viivitamata teada anda. Samuti võivad raudteeettevõtted ise kasutada droone taristu seireks, mistõttu on neile oluline tuvastada, kas õhus on _võõraid_ droone lisaks nende endi omadele.
    *   _Maanteeamet (Transpordiamet)_ – Kuigi teedeehituse ja liiklusjärelevalve seisukohalt droonid otsest igapäist ohtu ei kujuta, on teatud olukordi, kus suure kiirtee kohal lendav droon võib põhjustada liiklusohtliku olukorra (juhtide tähelepanu hajumine või drooni allakukkumine sõidukitele). Transpordiamet võib olla huvitatud droonide lennupiirangutest strateegiliste sildade või tunnelite kohal. Praegu on see vajadus marginaalne võrreldes õhu- ja meretranspordiga, kuid _loovalt mõeldes_ võiks ka maanteevaldkond tulevikus drooniseire infot kasutada (nt automaatse hoiatussüsteemina, kui kiirtee koridori ilmub tundmatu droon).
*   **Telekommunikatsiooni- ja IT-sektor** – Telekomifirmad (_Telia, Elisa, Tele2_) haldavad mobiilimaste, sidejaamu ja andmekeskusi üle Eesti. Need on samuti elutähtsad objektid, mille toimimine on kriitiline. Droonid võiksid teoreetiliselt põhjustada sidekatkestusi (nt kukutades midagi tugijaamadele või lõigates fiiberoptilisi kaableid). Samuti on telekomitaristu soodne platvorm drooniseiresensorite paigaldamiseks – Telial jt on üle riigi kõrged mastid, kust on hea õhuruumi skaneerida. **Telia** on küll valdavalt teenusepõhine ettevõte, kuid neilgi on "füüsiline baas": mobiilivõrgu mastid, andmesõlmed. Nende huvi droonitõrje vastu võib olla pigem kaudne (võrreldes näiteks elektrivõrguga), ent siiski olemas. Võib eeldada, et sideettevõtted teevad taristukaitses koostööd teistega: näiteks kui droon häirib mobiililevi (kas tahtlikult sidesegajaga või kogemata), siis telekomid oleks huvitatud allikast teada saama. **IT- ja andmekeskused** on eraldi uus riskivaldkond – rahvusvaheliselt on tuvastatud juhtum, kus finantsasutuse andmekeskuse katusele maandus droon, kandes küberrünnaku seadet (Wi-Fi häkkimisseadet), püüdes varastada andmeid[droneshield.com](https://www.droneshield.com/blog/defending-data-centers-from-drone-espionage-and-attacks#:~:text=These%20attacks%20against%20data%20centers,fell%20victim%20to%20exactly%20this). Sellised _kurioossed_ juhtumid näitavad, et ka pangad ja andmekeskuste operaatorid (nt pangad nagu LHV, suured pilveteenuste andmekeskused) võivad näha droone uue küberohuna. Droonituvastuse andmed oleks neile väärtuslikud, et tuvastada võimalik luure või küberrünnaku katse varakult. Samuti võivad andmekeskused karta droone kui füüsilise ründe vektorit (nt lõhkeainega droon serveriruumi vastu). Seega on _erasektori kriitilise IT-taristu_ haldajad kindlasti üks huvirühm – kuigi esialgu vähem esile tõstetud kui klassikalised energia- ja transpordiettevõtted.
*   **Veeteede ja vee-ettevõtted** – Tallinna Vesi ja teised suuremad vee- ja kanalisatsioonifirmad võivad samuti mõelda drooniohule. Näiteks avatud veereservuaaride puhul on teoreetiline oht, et drooni abil püütakse vett saastada. Kuigi see risk on väike, kuulub veevarustus kriitiliste teenuste hulka. Samuti on vee-ettevõtetel suured rajatised (veepuhastusjaamad, pumbajaamad), mille kohal droonid võiksid volitamata lennata. Kui droonid koguvad andmeid näiteks valvekaamerate pimedatest nurkadest või kaitsmata kohtadest, siis turvateenistused tahaksid seda teada. Selles vallas on droonitõrje vajadus _ülepaisutatud nimekirja_ osana mainimist väärt, kuigi praktikas võib kaalutlus alles tekkida.
*   **Muud tööstus- ja infrastruktuuriettevõtted** – Siia alla kuuluvad näiteks suured tehased, laod ja farmid:
    *   _Keemiatööstus_: Viru Keemia Grupp (VKG) ja teised, kelle territooriumil hoitakse ohtlikke aineid. Neil on motivatsioon takistada loata droonifotograafiat (konkurentsi- või julgeolekuoht) või sabotaaži.
    *   _Logistika keskused_: suured laokompleksid (nt Omniva või DHL logistikakeskused) võivad droone kohata spionaaži eesmärgil – keegi võib drooniga jälgida, mis kaup kus liigub. Samuti võiks droon kanda seadmeid, mis skaneerivad RFID silte või Wi-Fi võrgustikke, tekitades andmelekke riski.
    *   _Põllumajandus_: suurfarmid ja põllufirmad ise kasutavad droone seireks, kuid võivad kohata ka konkureerivate farmide või aktivistide droone (nt loomakaitsjad filmimas suurfarmi ülevalt). Droonitõrje pole küll maaettevõtete prioriteet, aga _loovalt_ võib selle lisada – drooniseire andmed võiksid teavitada põllupidajat, kui tema maadel lendab keegi volitamatult (näiteks kahjuritõrje ajal droonidega pildistamine võib rikkuda katseid vms).

Erasektor, avalikkus ja muud huvirühmad
---------------------------------------

*   **Suurürituste korraldajad ja staadionid** – Massiürituste (laulu- ja tantsupidu, vabaõhukontserdid, spordivõistlused) korraldajad on üha teadlikumad droonidega seotud ohtudest. Publiku kohal lendav seadusliku loata droon kujutab _ohutusriski_: droon võib rikkega alla kukkuda rahvahulka või meelega põhjustada segadust. Näiteks on rahvusvaheliselt juhtunud, et jalgpallivõistluse ajal kukkus tribüünile droon või tenniseväljakule lennutati droon, tekitades ohtliku olukorra. Seetõttu kehtestatakse suurtel üritustel sageli ajutine lennukeeld ning PPA jälgib drooniaktiviteeti. **Laulu- ja tantsupeo** puhul on viimasel ajal palutud pealtvaatajatel droone mitte kasutada, ent alati leidub keegi, kes proovib. Drooniseiresüsteem annaks korraldajatele ja politseile operatiivse ülevaate, kui keegi piirangut rikub. Samuti suured staadionid (A. Le Coq Arena jt) või vabaõhufestivalide alad võiksid kasutada ajutist droonide tuvastust, et ennetada õnnetusi ja kaitsta artiste ning publikut. Kuigi tavaliselt reageerib droonidele politsei, on ka korraldajad huvitatud reaalajas andmetest – näiteks et teha teadustus publiku seas (“ilma loata drooni lennutaja, lõpetage kohe”) või lihtsalt olla teadlik potentsiaalsest ohust. Maailmas on staadionitel ka püsivamaid droonitõrjesüsteeme (USA NFL ja olümpiamängud on neid kasutanud), seega kuulub see huvirühm _laiendatud nimekirja_.
*   **Era- ja kommertsturvafirmad** – Turvateenuseid pakkuvad ettevõtted (G4S, USS Security jt) võivad tulevikus lisada drooniseire oma teenuste valikusse. Kui seadusandlus lubab, võiksid turvafirmad pakkuda klientidele (tehased, kaubanduskeskused, rikaste villad) droonituvastuse teenust – analoogselt valvekaamerate paigaldusega. Juba praegu mõeldakse Eestis, kas anda teatud _kvalifitseeritud_ üksustele õigus droone tõrjuda kriitilise taristu kaitseks[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=,Link%20l%C3%A4inud%20aastal%20alanud%20arutelusid). Tulevikus võivad turvafirmad opereerida droonituvastussensoreid klientide territooriumil ja edastada häireid politseile. Seega on erasektori turvafirmad huvitatud standarditest ja andmetest, et oma teenust arendada. Nad oleksid droonitõrje andmete _taaskasutajad_, pakkudes nende põhjal nõustamist ja reageerimist.
*   **Ärikinnisvara ja kaubanduskeskused** – Suured kaubanduskeskused (Ülemiste, Viru keskus jne) ning pilvelõhkujad võivad näha droone ohuna privaatsusele ja turvalisusele. Näiteks drooniga saab filmida kinnistute siseõue või katuseterrassi, tuues kaasa andmekaitseriske (kliendid filmitud ilma loata). Samuti võidakse drooniga proovida öösel hoone territooriumile midagi toimetada (nt varguse abivahendina). Sellised juhtumid on praegu pigem teoreetilised, kuid suurlinnades (nt Londonis) on olnud katseid droonidega poodidest kaupa kätte saada. Eestis võib ärikinnisvara haldaja soovida liituda drooniseire võrguga, saamaks teadet, kui nende hoone kohal lendab mõni registreerimata droon. Eriti finantssektori hooned (pangad) ja kõrghooned (teletorn, Tornimäe ärikvartal) – mõnedel on isegi oma turvameeskonnad, kes võiksid drooniinfo vastu huvi tunda.
*   **Meedia ja filmindus** – Telekanalid ja filmiproduktsioonid kasutavad ise droone, kuid on ka huvitatud, kui keegi teine nende võtete läheduses drooni lennutab. Näiteks otseülekande (spordiüritus, kontsert) ajal võib volitamata droon segada telepilti või halvemal juhul põhjustada õnnetuse, mis jääb kaamerate ette. Seega võivad ringhäälingu ettevõtted (ERR, Kanal2, TV3) suuremate sündmuste puhul tahta drooniseiret. Samuti filmivõtted (eriti rahvusvahelised produktsioonid Eestis) nõuavad privaatsust – droon, mis _paparazzo_ kombel võtteplatsile lendab, on probleem. Erafilmistuudiod võiksid huvitatud olla droonide jälgimise tehnoloogiast, et kaitsta oma intellektuaalset omandit (nt saladuses hoitavaid võttestseene) uudishimulike droonikaamerate eest.
*   **Kohalikud omavalitsused** – Linnad ja vallad ise võivad samuti olla huvirühmad, eriti suuremad linnad:
    *   _Tallinna linn_ – pealinn korraldab palju massiüritusi ja haldab olulisi objekte (nt Tallinna Teletorn, mis on strateegiline ja kus droonid võivad segada tele- ja sidelevi). Tallinna linnavalitsus võiks olla huvitatud koostööst drooniseire osas, et linnaruumi õhuruumi turvalisemaks muuta. Linnapoolne huvi võib seisneda ka andmete kasutamises planeerimisel – näiteks kui droonide kasutus kasvab, saab linn analüüsida, millistes piirkondades lendab palju droone (turismimagnetid nagu Vanalinn) ning kas on vaja täiendavaid piiranguid või teavituskampaaniaid. Ka on Tallinnal oma munitsipaalpolitsei (MuPo), kes tegeleb korrakaitsega – kuigi neil pole praegu droonitõrje volitusi, võiksid nad drooniandmeid kasutada rikkumiste tuvastamiseks (sarnaselt parkimis- või avaliku korra rikkumiste infole). Rahvusvaheliselt on arutatud, et ka omavalitsustel võiks olla roll droonide reguleerimisel, kuid Eestis seni kehtib jõumonopol riigil[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=valdajatele%20%C3%B5igus%20lennupiiranguid%20rikkuvaid%20droone,droone%20t%C3%B5kestada%20vaid%20m%C3%B5ni%20j%C3%B5uametkond).
    *   _Teised linnad_ – Tartu (seal on samuti lennuväli ning rohkelt tudengite üritusi), Pärnu (suvised festivalid, rannapiirkond), Narva (piirilinn, julgeoleku eripärad) – iga suurem omavalitsus võib tuua oma nurga. Näiteks piirilinn Narva võib teha koostööd PPA-ga, sest droonid võivad üle jõe Venemaalt lennata. Tartu Ülikooli linnana võib muretseda uue aasta volbriöö vms sündmuse ajal droonide pärast. Kuigi kohalike huvi on kaudsem, on _ajurünnaku mõttes_ mõistlik nad nimekirja lisada, et hiljem otsustada, kellele keskenduda.
*   **Üldsuse esindajad ja hobikasutajad** – Huvitaval kombel võib ka laiema avalikkuse (droonihuviliste ühendused, lennumudelklubid) kaasamine olla teema. Kuigi nemad ei _vajad droonitõrjet_ otseselt, on nad andmekasutajad teises võtmes – näiteks droonioperaatorid ise võiksid soovida ligipääsu teatud andmetele, et teada saada, kus on droonirikkumisi toimunud (hariv eesmärk) või kas nende enda droon on tuvastatud (õiguskaitseline huvi). Samuti on avalikkusel huvi, et droonide vastased meetmed ei rikuks liigselt privaatsust või ei ohustaks ausaid droonikasutajaid. Seega võib projektis kaudselt arvestada ka kodanikuühiskonna ja era-droonilennutajate esindajatega, et andmekasutus ja -jagamine oleks ühiskondlikult aktsepteeritud. Näiteks andmekaitse inspektsioon (AKI) võiks soovi korral jälgida, et drooniseiresüsteemis kogutav info (videopildid, lennutrajektorid) ei rikuks isikute privaatsust ja järgiks seadusi.

Teadus- ja arendusasutused
--------------------------

*   **Ülikoolid ja teaduslaborid** – Eesti teadusasutused nagu _TalTech (TTÜ)_, _Tartu Ülikool_ ja _Eesti Lennuakadeemia_ tegelevad mehitamata õhusõidukite ja sensorite alase uurimistööga. Nad on potentsiaalsed projektipartnerid, kes arendavad uusi droonituvastuse tehnoloogiaid (radarisüsteemid, signaalitöötlus, tehisintellektil põhinev objektituvastus jne). Nende **vajadus** on eeskätt juurdepääs kvaliteetsetele andmetele reaalsetest drooniintsidentidest: näiteks droonide lennutrajektoorid, raadioküljekaja andmed, videopildid droonidest. Need andmed võimaldavad teadlastel treenida masinõppemudeleid paremini droone eristama lindudest või muust müraallikast. **Probleem:** paljud drooniseire andmed võivad olla tundlikud või juurdepääs piiratud juriidilistel põhjustel. Kui sensorid paiknevad kaitseväe aladel või riigi radarvõrgus, võivad andmed olla salastatud. Ka tsiviilõhuseire andmed võivad sisaldada isikuandmeid (näiteks drooni operaatori asukoht, mida loetakse erasidesignaaliks). Teadussektoril tekib seega _juriidiline vajadus_ – tuleb leida õiguslik alus, et teadlased saaksid vajalikke andmeid kasutada. Võimalikud lahendused on andmete anonüümimine, erilubade taotlemine või koostöölepingud, mis lubavad kasutust ainult teadusotstarbel. Näiteks politsei andmekogudest teabe saamine eeldab sageli projekti erikokkulepet, kuna kehtib isikuandmete ja riigisaladuse kaitse. Kui droonitõrje projekt tahab kaasata ülikoole, tuleb neile tagada ligipääs sensoriandmetele viisil, mis on kooskõlas seadustega – see ise on eraldi väljakutse, mida tuleb lahendada.
*   **RIA ja küberkaitse teadlased** – Lisaks füüsilisele seirele on droonitõrjes ka küberdimensioon (nt _remote ID_ standardid, droonide sidesignaalide dekrüpteerimine). Riigi Infosüsteemi Amet (RIA) ning kõrgkoolide küberkaitse instituudid võivad uurida droonide ja vastumeetmete küberjulgeolekut. Ka neil on vaja juurdepääsu droonide sideprotokollide logidele või testkeskkondadele. See aga puutub side- ja jälitustegevuse seadustikku (sest drooni juhtsignaalide pealtkuulamine võib kvalifitseeruda sideandmete kogumisena). Teadlased vajavad seega õigusraamistikku katseteks – nt ajutised testpiirkonnad, kus tohib drooni juhtimiskanaleid analüüsida ilma seadust rikkumata. Ilma selliste eranditeta on teadussektori töö piiratud. Seega üks projekti _pehme vajadus_ on soodustada regulatiivseid muudatusi või eriotsuseid, mis lubaks innovatsiooni (seda rõhutasid projektipartnerid vestlustes kui probleemi kohta andmete legaalsele kättesaadavusele).
*   **Rahvusvaheline teaduskoostöö** – Eesti teadlased ja asutused teevad tihti kaasa EU Horisont projektides või NATO teadusprogrammides. Droonitõrje valdkonnas osaletakse ühisprojektides, kus jagatakse andmeid ja platvorme üle riigipiiride. Meie teadussektor soovib sellistes projektides osaleda, mis tähendab, et kogutud drooniandmeid võiks (lubade olemasolul) jagada rahvusvaheliste partneritega. See eeldab, et andmete juriidiline staatus on selge – näiteks kas drooni signaali metaandmed on _isikuandmed_ (seotud registreeritud omanikuga) või anonüümsed objektikirjeldused. Kui need aspektid on lahendatud, saavad teadlased andmeid vabamalt kasutada, publitseerida analüüse ning panustada droonitõrje tehnoloogiate arengusse.

Rahvusvahelised näited ja kogemused
-----------------------------------

Erinevates riikides on _rahuaegsetes_ tingimustes droonitõrje vastu huvi tundnud mitmed sektorid – need kogemused aitavad kaardistada ka Eesti vajadusi:

*   **Lennujaamad ja lennundus**: Paljudes riikides on just suured rahvusvahelised lennujaamad olnud esimesed droonitõrjesüsteemide kasutajad. Pärast kuulsat Gatwicki juhtumit 2018 (kus loata droon seiskas lennujaama töö ~36 tunniks) paigaldasid mitmed Euroopa lennujaamad droonide avastamise radarid ja RF-detektorid. Euroopas on välja antud ühiseid juhiseid – EASA 2021. a suunised drooniintsidentide haldamiseks, mida pidevalt ajakohastatakse[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=European%20airports%20are%20at%20the,light%20of%20recent%20technological%20advancements). Läti näitel tugevdati hiljuti koostööd – Riia lennujaamas korduvad drooniintsidendid viisid transpordiministeeriumi täiustama õigusakte ja koordineerimist eri asutuste vahel[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=5,align%20with%20aviation%20safety%20standards). USA-s on lennujaamade droonitõrje samuti arengufaasis, testides erinevaid tehnoloogiaid (FAA katseprogrammid). **Oluline õppetund Eestile**: lennujaamade kaitseks on vaja mitme osapoole koostööd – lennujaam, lennujuhid, politsei, lennuamet, isegi lennufirmad. Ka meil peaks projektis arvestama Tallinna Lennujaamaga kui võtmeosapoolega, sest rahvusvaheline praktika näitab nende aktiivset rolli drooniohtude vastu võitlemisel.
*   **Piirivalve ja julgeolek**: Pärast 2022. aastal alanud Ukraina sõda on _piiririigid_ (Soome, Balti riigid, Poola) hakanud väga tõsiselt suhtuma droonidega seotud intsidentidesse. Soomes registreeriti ühe aastaga üle **saja** kahtlase droonilennu keelatud tsoonide lähedal[err.ee](https://www.err.ee/1609500322/soome-politsei-uurib-keelutsoonide-lahistel-lendavaid-kahtlaseid-droone#:~:text=Soome%20lennukeelutsoonide%20l%C3%A4histel%20on%20enam,seotud%20m%C3%B5ni%20v%C3%A4lisriik%2C%20kirjutab%20Yle) – enamik neist kriitilise taristu või sõjaväeobjektide kohal. Soome ostis ka sadu droonitõrjeseadmeid (sh segajad ja detektorid) oma kaitsejõududele. Ida-Euroopa riigid teevad omavahel koostööd: hiljuti kohtusid mitme riigi esindajad Helsingis, et arutada ühtse droonitõrjevõrgustiku rajamist, eelkõige Venemaa droonirünnakute tõrjumiseks[aripaev.ee](https://www.aripaev.ee/uudised/2025/09/26/ida-euroopa-riigid-arutavad-helsingis-droonitorje-rajamist#:~:text=Ukraina%20kaitseminister%20tutvustab%20reedel%20Euroopa,eesm%C3%A4rk%20on%20t%C3%B5rjuda%20Venemaa%20droonir%C3%BCnnakuid). Kuigi need arutelud on mõjutatud sõjaaja vajadustest, kandub osa kompetentsist üle rahuaega – näiteks luuakse infoturve protokolle, kuidas jagada droonide tuvastusandmeid naaberriikide vahel. Eestile tähendab see, et droonituvastuse andmete vahetus (nt Soome, Läti, Leedu suunal) võiks olla perspektiivis vajalik; piiriülene koostöö on võtmetähtsusega nii sõja- kui rahuajal. Samuti on rahvusvaheliselt võetud suund, et _jõuametkonnad_ (politsei, piirivalve, kaitsevägi) kaasavad ka tsiviilsektori kriitilisi taristuomanikke. Näiteks Prantsusmaa lubab piiratud juhtudel tuumaelektrijaamade operaatoritel kasutada droonitõrje meetmeid koostöös politseiga. Ühendkuningriik on 2021. aastal vastu võtnud seaduse (Air Traffic Management and Unmanned Aircraft Act), mis annab politseile ja isegi teatud _erinimekirja_ objektide turvameeskondadele suuremad õigused droonide kahjutuks tegemiseks lennukeelualadel – see hõlmab lisaks lennujaamadele ka _vanglad_ ja _rahvuslikud infrastruktuuri objektid_. Eesti saab teistest riikidest inspiratsiooni, milliste objektide kaitsmisele fookus seada.
*   **Vanglad ja sisejulgeolek**: Rahvusvaheliselt, nagu eespool mainitud, on _vanglasüsteem_ üks aktiivsemaid droonitõrje rakendajaid. UK-s kehtestati hiljuti üle-riigiline 400 m **droonikeelutsoon** iga vangla ümber ning karmistati karistusi rikkumise eest[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=under%20the%20cover%20of%20darkness). Sellest hoolimata on droonide arvukus vanglate kohal rekordeid purustamas – droonid on muutunud kuritegelike jõukude tööriistaks. Näiteks Inglismaal on suletud vanglate juures kirjeldatud olukordi, kus droone lendab öösiti nii tihti, et vangid võrdlevad seda “lennujaamaga” ning ametnikud püüavad võidu droone alla tuua[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=items%20in%20prisons%20%E2%80%93%20providing,purposeful%20activity%2C%E2%80%9D%20he%20said). USA-s on testitud erinevaid tehnikaid (sh droonipüüdmisvõrgud, signaalilokatsioon jms) mitmes osariigis, kuid seal piirab föderaalne seadus tsiviilvastumeetmeid (ainult föderaalsel tasandil lubatud). Singapur, Austraalia jt riigid on samuti paigaldanud vanglate perimeetrile droonidetektoreid. **Eesti jaoks** tähendab see, et meie vanglad (Tallinna, Tartu, Viru vangla) peaksid kindlasti kaasatud olema – ja mitte ainult tehnoloogia kasutajatena, vaid ka õigusloome vaatest, et vanglaamet saaks vajadusel droonitõrjevahendeid rakendada. Rahvusvaheline kogemus näitab, et ilma õigusliku aluseta on isegi parim tehnika kasutu. Seega Eesti saab UK eeskujul mõelda, kas luua vanglate ümber püsivad no-fly tsoonid ja kuidas lihtsustada droonioperatsioonide seire andmete jagamist vanglate ja politsei vahel.
*   **Energia- ja kommunaalsektor**: Mujal maailmas on energiafirmad hakanud droone nii kasutama kui ka kartma. Näiteks USA-s on elektrifirmad teinud teste droonidetektoritega oma alajaamades, sest kardetakse _varasid kahjustavaid_ intsidente. Lähis-Idas on droonirünnakud nafta tootmisobjektidele olnud reaalsus (2019. aastal Saudi Araabia naftarajatised). Euroopas on seni suuremad juhtumid olnud droonide **luurelennud**: Belgias teatas relvatehas, et nende tehase kohal lendasid tuvastamata droonid, mis võisid pärit olla konkurentidelt või riiklikult osapoolelt[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Image). Ka Saksamaal on avastatud droone sõjaväeobjektide kohal luuramas[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Sveti%20hinnangul%20v%C3%B5iks%20lennujaamale%20anda,droonit%C3%B5rje%20%C3%B5iguse). Ukraina sõja käigus oleme näinud droonide kasutamist energiataristu rivist välja viimiseks. Kuigi Eestis pole tuumaelektrijaamu ega nii strateegilisi naftakomplekse, on analoogia selge – elektrijaamad, suurvõimsusega sidemastid, isegi andmekeskused vajavad kaitset. Austraalias ja USA-s peetakse _andmekeskusi_ nüüd kriitiliseks taristuks, mida tuleb droonide eest kaitsta, sest seal hoitav andmehulk on tohutu väärtusega[droneshield.com](https://www.droneshield.com/blog/defending-data-centers-from-drone-espionage-and-attacks#:~:text=Data%20centers%20are%20a%20less,almost%20insurmountable%20information%20they%20hold). On dokumenteeritud juhtumeid, kus droon üritas andmekeskuse lähedale maanduda küberrünnaku eesmärgil[droneshield.com](https://www.droneshield.com/blog/defending-data-centers-from-drone-espionage-and-attacks#:~:text=These%20attacks%20against%20data%20centers,fell%20victim%20to%20exactly%20this). See on pannud andmekeskuse operaatorid droonivastaseid lahendusi otsima. Nende kogemus rõhutab vajadust integreerida droonitõrje küber- ja füüsilise turbe tervikpilti. Eestil tasub vaadata näiteks Põhjamaade poole – Soomes ja Rootsis kuuluvad elektrivõrgud ja -jaamad kaitstavate objektide nimistusse ning neil on tihe koostöö politseiga droonijuhtumite lahendamisel.
*   **Avalik ruum ja avalikkus**: Mõned linnad maailmas on astunud erakorralisi samme. Näiteks **Tokyo** politseiüksus kasutas olümpiamängude ajal droonipüüdja-droone (võrguga), et eemaldada õhuruumist loata droone. **Hollandis** katsetas politsei isegi erikoolitatud kotkaid droonipüüdmiseks. Kuigi need on eksootilised näited, näitavad need, et loominguliselt on proovitud kõike. Eestis vaevalt kotkaid rakendatakse, kuid _nutikad tehnoloogiad_ – laserskännerid, akustilised sensorid jms – võivad leida tee turule. Avaliku ruumi kaitsel on veel näide spordis: Ameerika jalgpalli liigad kasutavad raadioside häireseadmeid, mis loovad staadioni kohale nn “droonide keelutsooni”. Meil võiks tulevikus suurte rahvaürituste ajaks kaaluda analoogseid meetmeid. Samas rõhutab rahvusvaheline kogemus _ohutust_: iga vastumeede (olgu laser või segaja) peab olema testitud, et see ei tekitaks kõrvalkahjusid, nt ei häiriks lennukeid või sidevahendeid väljaspool kaitstav tsooni[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Ka%20sellisel%20juhul%20ei%20tuleks,l%C3%A4hedal%20peab%20olema%20eriti%20ettevaatlik). Eesti saab siinkohal õppida teistelt riikidelt riskianalüüsi tähtsust – enne kui jagada taristuomanikele õigusi droone vastustada, tuleb hinnata meetmete mõju. Näiteks linnakeskkonnas (Tallinnas) tuleb eriti ettevaatlik olla lennuvälja läheduse tõttu[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Ka%20sellisel%20juhul%20ei%20tuleks,l%C3%A4hedal%20peab%20olema%20eriti%20ettevaatlik). Rahvusvahelised juhised julgustavad _juhtumipõhist_ lähenemist: igale objektile oma meetmete “tööriistakast”, vastavalt ohuhinnangule.

Kokkuvõttes annavad teiste riikide kogemused mõista, et **huvirühmade ring on lai**: lennundus, siseturvalisus, vanglad, energia, transport, telekom, ürituste korraldajad, teadusasutused – kõigil on oma vaatenurk drooniohtudele. Eestis on paljud nimetatutest juba esindatud või vähemalt teadlikud (nt Kaitseministeeriumi asutused, kes projektis osalevad), kuid rahvusvahelise kogemuse pealt võiksime lisada veel _panganduse/andmekeskuste sektori_ (nagu LHV näide) ning rõhutada _vanglate_ ja _lennujaama_ tähtsust. Samuti näeme, et edu eeldab õigusruumi kaasajastamist – mida järgmine alateema käsitleb.

Andmekasutuse vajadused ja juriidilised kaalutlused
---------------------------------------------------

Droonitõrje seirevõrgustiku loomisel tekib suur hulk andmeid: radar- ja kaamerasalvestused droonidest, lennutrajektoorid, drooni tüübi tuvastused, mõnel juhul ka drooni juhtpulti asukoha koordinaadid. Need andmed pakuvad huvi mitmele osapoolele:

*   **Operatiivsed kasutajad** – Esmalt kasutavad andmeid reaalajas _korrakaitsjad_ (PPA) ja vajadusel _julgeolekuasutused_ (KaPo). Nemad vajavad hetketeavet, et sündmusele reageerida (näiteks patrull suunata või lennuliiklus peatada). See on otsene andmekasutus, mis toimub _häirekeskuse_ või juhtimiskeskuse tasandil. Samuti taristuhaldajad (nt Eleringi juhtimiskeskus) võivad reaalajas pilti vaadata, kuid praegu seadus piirab otsese sekkumise nende poolt[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=valdajatele%20%C3%B5igus%20lennupiiranguid%20rikkuvaid%20droone,droone%20t%C3%B5kestada%20vaid%20m%C3%B5ni%20j%C3%B5uametkond). Seetõttu nähakse ette, et isegi kui ettevõtted paigaldavad seadmed, võib nende _käitamist_ teha lõpuks mõni riigiasutus operatiivselt[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Karl%20Kristjan%20Kits%20%C3%BCtles%2C%20et,allatoomise%20%C3%B5iguse%20enda%20k%C3%A4tte%20j%C3%A4tab). Andmete jagamine reaalajas peab seega olema lahendatud (võrgustik, mis ühendab erinevaid osalejaid).
*   **Analüüsi ja planeerimise kasutajad** – Teiseks kasutatakse drooniintsidentide andmeid analüütilisel eesmärgil. _Lennuamet_ ja _Transpordiamet_ võivad soovida statistikaks: kui palju rikuti lennukeelualasid, mis tüüpi droonid enim muret tekitasid jne. See info aitab kujundada poliitikat (nt kas karmistada registreerimiskohustust või suurendada trahve). _Kriitilise taristu ettevõtted_ kasutavad andmeid riskianalüüsiks: näiteks kui Elering näeb, et mingis piirkonnas käib korduvalt droon (kuigi midagi halba pole juhtunud), saavad nad hinnata, kas see on ohutu hobi või potentsiaalne luure. See võib mõjutada investeeringuid turvalisusesse. _Kindlustusfirmad_ki võiksid tulevikus huvituda drooniintsidentide statistikast – näiteks suured üritused või objektid, mida droonid tihti ohustavad, võivad nõuda erikindlustust.
*   **Teadus- ja arendustegevus** – Nagu eelnevas osas mainitud, soovivad _ülikoolid_ ja R&D ettevõtted andmeid kasutada prototüüpide testimiseks ja uute algoritmide arendamiseks. Näiteks võiks projektis kogutud droonilendude andmestikku (anonüümseks muudetuna) hiljem kasutada tudengiprojektides, et luua paremaid drooni tuvastamise süsteeme. Samuti on andmed hindamatud _tehisintellekti mudelite_ treenimiseks (nt objektituvastus videost – vaja on tuhandeid näiteid droonidest eri nurkade alt). Teadlastel on huvi ka drooniohu _prognoosimisel_: kui on logi, kus ja millal droone nähtud, saab ehk mustreid leida (hooajalisus, seos ilmaga vms). Kõik see nõuab, et andmed oleksid ligipääsetavad.

**Juriidilised kaalutlused**: Paraku on droonitõrje valdkonnas andmekasutus tugevalt reguleeritud:

*   Hetkel kehtib põhimõte, et droonide _aktiivne tõkestamine_ on riigi jõumonopol[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=valdajatele%20%C3%B5igus%20lennupiiranguid%20rikkuvaid%20droone,droone%20t%C3%B5kestada%20vaid%20m%C3%B5ni%20j%C3%B5uametkond). See tähendab, et andmete kogumine ja kasutamine kriitilises osas on jõuametkondade käes. Kui projekt soovib kaasata nt eraettevõtet droonipildi monitoorijana, peab tal olema seaduslik õigus ja vastutus seejuures. Samuti, kui taristuomanik (nt sadam) paigaldab detektori, tohib ta küll drooni _avastada_, aga mitte ise seda alla tuua – info peab edastama politseile, kes siis tegutseb[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=ning%20uuris%2C%20missuguseid%20sadamaid%2C%20k%C3%BCtuseterminale,reaalset%20kaitset%20pakkuda%20ainult%20j%C3%B5uametid)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Korrakaitseasutus%20lubab%20lennupiiranguid%20rikkuvaid%20droone,%C3%BCtles%20Link). Seega andmevood peavad olema selgelt defineeritud, kes mida teeb.
*   _Isikuandmed ja privaatsus_: droon, eriti varustatuna kaameraga, võib salvestada pilti eravaldustest – aga droonitõrjesüsteem ise võib ka koguda delikaatseid andmeid. Näiteks drooni raadiosignaali pealtkuulamine, et leida selle juhtpuldi asukoht, on tehniliselt võimalik (RF-detektorid suudavad suunata signaali). Kuid raadioside jälgimine võib kvalifitseeruda _jälitustegevuseks_, mis tohib toimuda üksnes vastava loaga. Projektis tuleb jälgida, et kasutatavad andurid ja meetodid on kooskõlas kehtiva õigusega (nt ei minda ebaseaduslikult eraühendusi pealt kuulama). Kindlasti tuleb konsulteerida Andmekaitse Inspektsiooniga, kui hakatakse kasutama kaameraid avalikus ruumis droonide tuvastamiseks – et tagada GDPR nõuetele vastavus. Võimalik, et droonituvastussüsteem peab mingeid isikuga seostatavaid andmeid (nt drooni registreerimisnumbrit, kui see on seotud omanikuga registris) käsitlema _isikuandmetena_, mis tähendab piiranguid säilitamisele ja jagamisele.
*   _Andmete jagamise lepped_: Erinevad osapooled (PPA, Kaitsevägi, eraettevõte) peavad kokku leppima, kuidas andmeid omavahel jagada. Näiteks kui Kaitsevägi annab oma radaripildi projekti tarbeks, võib see tulla tingimusega, et toorandmeid ei avalikustata ja neid tohib vaadata ainult volitatud isikud. Samuti, kui eraettevõte panustab andurid, tahab ta ehk vastu saada analüüse tervikpildi kohta. Sellised lepped on tavaliselt vormistatud _andmevahetuslepingutena_ (MoU või Data Sharing Agreement). Projektis tuleb ilmselt koostada reeglid, kes tohib andmeid vaadata reaalajas, kes saab juurde arhiveeritud andmetele, millistel juhtudel info edastatakse kolmandatele osapooltele (näiteks kohtueelse menetluse tarbeks tõendina).
*   _Õiguskindlus teadusele_: Teadusasutuste seisukohalt oleks ideaalne, kui valitsus annaks _määruse või eriloaga_ võimaluse kasutada droonitõrjesüsteemi andmeid teaduslikul eesmärgil. See võiks olla pretsedent – analoogselt sellega, kuidas meditsiiniuuringutele antakse erandeid isikuandmete kasutamisel pseudonüümitult. Kui jätta õigusküsimused lahtiseks, võib juhtuda, et projekt kogub küll palju infot, kuid hiljem ülikool ei saa seda kasutada, kuna kardetakse andmekaitse rikkumist. Seetõttu on huvirühmaks ka _õigusloome kujundajad_ – Riigikogu komisjonid, ministeeriumide õigusosakonnad. Neil on huvi (ja vajadus) luua raamistik, mis lubaks uutel tehnoloogiatel (nagu droonitõrje) tegutseda ilma õigusliku vaidluseta. Praegu arutatakse juba seadusemuudatusi, et kriitilise taristu haldajatele teatud droonitõrjeõigusi anda[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=,Link%20l%C3%A4inud%20aastal%20alanud%20arutelusid)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Indrek%20Link%20r%C3%B5hutas%2C%20et%20kui,see%20kindlasti%20laiemat%20ringi%20taristuhaldajaid). Samuti on jutuks olnud, et taristuettevõtted võivad oma seadmed paigaldada, aga neid _kasutab_ siis lõpuks ikkagi riigiasutus kokkulepitud viisil[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Karl%20Kristjan%20Kits%20%C3%BCtles%2C%20et,allatoomise%20%C3%B5iguse%20enda%20k%C3%A4tte%20j%C3%A4tab). Sellised _avaliku ja erasektori partnerluse_ mudelid on juriidiliselt uued ning nõuavad läbi mõtlemist.

**Kokkuvõte andmekasutajatest:** Projekti kogutud drooniandmeid kasutaksid:

1.  **Jõuametid** – kiireks reageerimiseks (politsei, piirivalve, kaitsevägi teatud juhtudel).
2.  **Kriitilise taristu omanikud** – olukorrateadlikkuseks (näevad, mis toimub nende objekti kohal) ja hilisemaks turvaparanduste planeerimiseks.
3.  **Regulaatorid ja ametkonnad** – lennundusohutus, julgeolekuanalüüs (nt Lennuamet, Siseministeerium) poliitika kujundamiseks.
4.  **Teadus-arendus** – innovatsiooni ja tulevaste tehnoloogiate loomiseks, kasutades kogutud andmeid mudelite treenimiseks.
5.  **Avalikkus (kaudselt)** – parem teadlikkus drooniohtudest ja kaitsemeetmetest (nt avalikud raportid juhtumite arvu kohta, et tõsta droonipidajate vastutustunnet).

Iga rühm peab saama vajalikud andmed _neile sobival viisil_, samal ajal peab projekt järgima õigusraame. Ühelt poolt tuleb andmeid võimalikult laialdaselt jagada asjakohaste huvirühmade vahel, et maksimeerida süsteemi kasulikkust rahuaja turvalisuse tagamisel. Teiselt poolt tuleb kaitsta andmete konfidentsiaalsust ja privaatsust seal, kus see on nõutav (riigisaladused, isikuandmed). Selle tasakaalu leidmine on osa projekti ülesannetest ning peab kaasama juriidilise ekspertiisi.

* * *

_Nimekiri ülal on teadlikult laiapõhjaline ja osalt “ülepakutud”, et hõlmata võimalikult palju vaatenurki. Järgnevates etappides saab sellest nimekirjast ebasobivaid või ebaolulisi kandidaate välja jätta, keskendudes kõige realistlikematele partneritele._

**Allikad:**

*   Madis Hindre, **ERR Uudised** – “Riik kaalub osale ettevõtetest droonitõrjeõiguse andmist” (31.10.2023). Viitab kriitilise taristu kaitse aruteludele Eestis: kliimaministeerium kaardistab sadamate ja kütuseterminalide vajadusi; Elering plaanib 2026. aastaks droonide tuvastus- ja tõrjevõimekuse loomist EU rahastusega[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Kliimaministeerium%20saatis%20eelmisel%20n%C3%A4dalal%20kirja,reaalset%20kaitset%20pakkuda%20ainult%20j%C3%B5uametid)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Ka%20Elering%20otsib%20v%C3%B5imalust%2C%20kuidas,paigas%2C%20loodab%20ettev%C3%B5te%20ka%20seadusemuudatust). Artikkel selgitab, et praegu võib droone alla tuua vaid jõuamet (riigi jõumonopol)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=valdajatele%20%C3%B5igus%20lennupiiranguid%20rikkuvaid%20droone,droone%20t%C3%B5kestada%20vaid%20m%C3%B5ni%20j%C3%B5uametkond), kuid kaalutakse, mis tingimustel seda õigust taristu valdajatele laiendada[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=,Link%20l%C3%A4inud%20aastal%20alanud%20arutelusid)[err.ee](https://www.err.ee/1609594883/riik-kaalub-osale-ettevotetest-droonitorjeoiguse-andmist#:~:text=Indrek%20Link%20r%C3%B5hutas%2C%20et%20kui,see%20kindlasti%20laiemat%20ringi%20taristuhaldajaid).
*   **ERR Välisuudised** – “Soome politsei uurib keelutsoonide lähistel lendavaid kahtlaseid droone” (23.11.2023). Toob esile, et alates Ukraina sõja algusest on Soomes alustatud üle saja menetluse seoses droonidega kriitiliste objektide kohal – näitab drooniohu kasvu piiriäärsetes riikides[err.ee](https://www.err.ee/1609500322/soome-politsei-uurib-keelutsoonide-lahistel-lendavaid-kahtlaseid-droone#:~:text=Soome%20lennukeelutsoonide%20l%C3%A4histel%20on%20enam,seotud%20m%C3%B5ni%20v%C3%A4lisriik%2C%20kirjutab%20Yle).
*   Rajeev Syal, **The Guardian** – “Drones could bring guns into prisons, watchdog fears” (22.11.2024). Ühendkuningriigi vanglate inspektsiooni hinnangul on droonid muutunud suurimaks ohuks vanglate turvalisusele; drooniintsidentide arv tõusis 2020–2023 kümnekordseks (üle 1000 juhtumi aastas) ning droonidega tuuakse sisse peamiselt narkootikume ja telefone, kuid kardetakse ka tulirelvade smugeldamist[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=Official%20figures%20showed%20the%20number,to%201%2C063%20incursions%20last%20year)[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=The%20more%20sophisticated%20drones%2C%20worth,under%20the%20cover%20of%20darkness). Kirjeldatud on ka meetmeid: alates 2024 kehtib automaatne droonikeeld 400 m raadiuses kõigist vanglatest, mõnes vanglas on paigaldatud droonidetektorid[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=under%20the%20cover%20of%20darkness)[theguardian.com](https://www.theguardian.com/society/2024/nov/22/drones-guns-into-prisons-england-wales-watchdog-fears#:~:text=Some%20prisons%20have%20introduced%20counter,block%20the%20devices%20from%20approaching).
*   Eve Goode, **Security Journal Americas** – “The evolving threat of drones to critical infrastructure” (08.12.2025). Intervjuu DroneShield’i avaliku turvalisuse direktoriga, kus rõhutatakse drooniohtu kriitilistele taristutele nagu _lennujaamad, vanglad, haiglad_. Mainitakse, et droonid on küll kasulikud, kuid võivad põhjustada häireid – näiteks hooletud hobipiloodid lennujaama lähedal või pahatahtlikud droonid, mis toimetavad **relvi ja narkootikume vanglatesse**, seades ohtu nii kinnipeetavad kui personali[securityjournalamericas.com](https://securityjournalamericas.com/threat-drones-critical-infrastructure/#:~:text=Outside%20of%20airports%2C%20correctional%20facilities,drone%20technology). Samuti viidatakse, et konfliktides (Ukraina) kasutatakse droone taristu kahjustamiseks, mis on pannud ka rahuajal organisatsioonid kõrgendatud valmisolekusse[securityjournalamericas.com](https://securityjournalamericas.com/threat-drones-critical-infrastructure/#:~:text=drugs%20into%20prisons%2C%20creating%20serious,for%20both%20inmates%20and%20staff). Artiklis rõhutatakse, et üha rohkem asutusi hakkab droonivastaseid võimekusi eelarvesse planeerima, kuna risk kasvab[securityjournalamericas.com](https://securityjournalamericas.com/threat-drones-critical-infrastructure/#:~:text=deployed%20across%20a%20variety%20of,sites%20worldwide)[securityjournalamericas.com](https://securityjournalamericas.com/threat-drones-critical-infrastructure/#:~:text=We%20believe%20counter,component%20of%20physical%20security%20infrastructure).
*   **DroneShield blogi** – “Defending Data Centers from Drone Espionage and Attacks” (06.10.2025). Valgustab vähemtuntud ohtu: andmekeskused kui kriitiline taristu on muutumas droonirünnakute sihtmärkideks. Kirjeldatakse ründevektoreid, sh droonide kasutamist küberrünnakuks: droon maandub andmekeskuse katusele piisavalt ligidale, et häkkida WiFi-võrku – **üks rahandusettevõte langeski sellise rünnaku ohvriks** hiljuti[droneshield.com](https://www.droneshield.com/blog/defending-data-centers-from-drone-espionage-and-attacks#:~:text=These%20attacks%20against%20data%20centers,fell%20victim%20to%20exactly%20this). Samuti mainitakse võimalust, et droonid võivad kanda lõhkelaenguid, et põhjustada füüsilist kahju serverifar mile. See näide kinnitab, et finantssektor ja andmesideteenused peaksid droonitõrjet tõsiselt võtma, ning DroneShield pakub neile integreeritud lahendusi (mitu sensorit, piloodi asukoha tuvastus jms). Eestile on see vihje, et pangad ja IT-taristu pole immuunsed drooniohu suhtes.
*   **D-Fend Solutions blogi** – “Europe’s Drone Challenge and Countermeasures in 2025” (blogipostitus, 2025). Kirjeldab drooniohtude kasvu Euroopas, tuues näiteks _Riga lennujaama_ intsidente ja droonide ilmumist Saksamaa sõjaväebaaside kohal[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=1,provide%20accurate%20and%20comprehensive%20drone). Rõhutatakse ühtse lähenemise vajadust Euroopas ning loetletakse sektoreid, mida droonioht puudutab: _sõjavägi, lennujaamad, piirid, vanglad_ jne. Märgitakse, et Läti transpordiministeerium parandab koostööd erinevate osapoolte vahel, et drooniintsidentidele kiiremini reageerida[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=5,align%20with%20aviation%20safety%20standards). Samuti soovitatakse täiustatud RF-põhiseid tuvastus- ja ülevõtmisvahendeid lennujaamadele, mis maandaks drooniriski turvaliselt[d-fendsolutions.com](https://d-fendsolutions.com/blog/europes-drone-challenge-and-countermeasures-in-2025/#:~:text=reliable%20drone%20identification%20without%20unnecessary,while%20effectively%20addressing%20the%20threat). See allikas kinnitab, et lennundussektor ja julgeolek tegelevad probleemiga aktiivselt ning ka piirivalve ja kriitiline taristu on fookuses üle Euroopa.
*   **ERR Uudised (Novaator rubriik)** – Eesti teadlaste uuringud drooniriskide kohta. (Näiteks TalTech lõputöö “Mehitamata õhusõidukite tuvastamise ja riskide maandamise …” 2020, viide digikogule). Selles analüüsiti droonikasutusest tulenevaid ohte ja kuidas riske maandada – tõdeti, et tehnilisi lahendusi on, kuid nende rakendamine nõuab koostööd ja standardeid[digikogu.taltech.ee](https://digikogu.taltech.ee/en/Download/a54c361e-deee-4fbc-bd90-7244f11bce8f#:~:text=,ohtude%20realiseerimise%20t%C3%B5en%C3%A4osust%20maandada%2C) (siin viidatud pigem kontekstina, et akadeemiline huvi on olemas). Samuti on Novaatoris kajastatud, et politsei vajab drooniandmetele ligipääsuks ja droonide jälitamiseks uudseid meetodeid ning õiguslikku raamistikku[njordlaw.com](https://www.njordlaw.com/et/droonide-lend-ule-seaduste#:~:text=Droonide%20lend%20%C3%BCle%20seaduste%20,tuvastamiseks%20v%C3%A4lja%20m%C3%B5lema%20uusi). See kinnitab teadussektori ja korrakaitse koostöövajadust.
*   **Sisekaitseakadeemia raport** – “Olukorrast piiril 08/2025” (mitteametlik viide). Toodud on statistika, et _2024\. aastal esines 25 juhtumit_, kus droon lendas üle vangla või selle lähedal, ning **2023–2024** vahistati mitu inimest drooniga vanglasse keelatud esemete toimetamise katsete eest[digiriiul.sisekaitse.ee](https://digiriiul.sisekaitse.ee/bitstream/handle/123456789/3733/Olukorrast%20piiril%208.pdf?sequence=1&isAllowed=y#:~:text=Sisekaitseakadeemia%20digiriiul,Droone%20kasutati%20vangidele%20keelatud). See on konkreetne kinnitus, et ka Eestis on vanglad drooniprobleemiga silmitsi ja õiguskaitseorganid on juba pidanud sekkuma. Sellised andmed on aluseks, et planeerida droonitõrje süsteemi vanglate tarbeks ja õigustada investeeringuid (nii tehnoloogiasse kui õiguslikku raamistikku).

## Prompt:
guide me through - help me to create an agents.md for a web app that is supposed to show drone locations in Estonia from sensors.

at first I want to implement the front end and mock sensors and drone data from a file. and data from NOTAMs. (a module to interpret notams has to be included, should be plenty examples on github)

front end type script, React + Vite.

for map i want to use ortophoto from "Maa-amet" , OpenLayers and WMTS. Keep your domain data in WGS-84 (lon/lat), but set the map View to EPSG:3857 and transform features on render.

i think first prototype without proxy for simplicity.

notam json is available https://aim.eans.ee/web/notampib/area24.json

altitude in AGL (separate detected vs drone reported), MSL. always have a comment next to altitude.
units metric, alt in m, speed in m/s; airplane data in km/h and both ft and m.

altitude smth like:
type AltitudeRef = "AGL" | "MSL";
type AltitudeSource = "detected" | "reported" | "unknown";

type Altitude = {
  meters: number | null;        // number stays a number
  ref: AltitudeRef;             // AGL vs MSL
  source: AltitudeSource;       // detected vs drone-reported
  comment?: string;             // always shown next to altitude
  rawText?: string;             // if upstream gave unparseable text
};

notam data interpreted and stored in m, but in text field always shown in both ft and m.

we will do notam interpretation later in backend, it is just web prototype.

i think to update ads-b data every 10 seconds, drone data maybe 1 hz for now (just need to get this prototype up)

we will create a log-in with users but no special focus on sensitivity or now. for now we read files instead having backend db. later we will have user roles, log, audit etc.

in this stage we can bypass all Maa-amet rules.

UTC everywhere in backend + DB, local time only in UI, and store both event-time and ingest-time for robustness.

THE GOAL IS TO GET FRONTEND UP AND RUNNING.

suggest folder structure - what should fit where (there are examples)
figure out testing. 

go and find some best examples for agents.md

some sources:
https://github.com/vitejs/vite-plugin-react/blob/main/AGENTS.md
https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/

https://gist.github.com/buck-0x/b9b789c40a4c1ac190a65b3a1dd6afa2
https://addozhang.medium.com/agents-md-a-new-standard-for-unified-coding-agent-instructions-0635fc5cb759
https://blog.nashtechglobal.com/tips-for-using-github-copilot-instruction-files-or-agents-md-effectively/
https://github.com/agentsmd/agents.md

##################

You are working on a **frontend-first** prototype web app that displays:
- Drone locations (telemetry) and detected objects from sensors
- Basic air traffic overlays (ADS-B, prototype-only)
- NOTAMs (from EANS JSON), visualized on the map and in panels

**Goal:** get the frontend up and running fast, with mocked data and polling.

---

## Non-negotiables (read this first)

1) **NO PROXY (HARD RULE).**
   - All HTTP queries are done **directly from the browser** until the GUI is working.
   - Do **not** add a proxy server, backend forwarding, or “temporary proxy just to fix CORS”.
   - If an endpoint has CORS issues: keep mocks on, document it in DATA_SOURCES.md, and move on.

2) **Prototype scope only**
   - No backend DB yet: read from public/mock/* and/or public endpoints.
   - Auth implementation is **not** required now, but code must be structured so auth can be turned on later.

3) **Time & Units rules**
   - UTC everywhere in “data / storage” logic. Local time **only** at the UI formatting boundary.
   - Store both eventTimeUtc and ingestTimeUtc for robustness.
   - Units: metric by default. Drone speed m/s. Aircraft speed km/h.
   - Altitude shown in meters; for aircraft/NOTAM show **both ft and m** in UI text.

4) **Map & projections**
   - Domain geometry in **WGS-84** (EPSG:4326) as [lon, lat].
   - Map View is **EPSG:3857**. Transform only at boundaries (render / OL feature creation).

---

## Stack (MVP)

- React + TypeScript + Vite
- UI: MUI (Material UI)
- Map: OpenLayers
- Maa-amet orthophoto base layer via WMTS (prototype direct calls; no proxy)
- Testing:
  - Unit/Component: Vitest + React Testing Library
  - Network mocking: MSW
  - E2E smoke: Playwright

---

## Setup & Commands (npm only)

**Do not mix package managers. Use npm.**

- Install: npm install
- Dev: npm run dev
- Build: npm run build
- Preview build: npm run preview
- Lint: npm run lint
- Typecheck: npm run typecheck
- Unit tests: npm run test
- E2E smoke: npm run test:e2e

Expected package.json scripts (keep aligned):
- dev: vite
- build: vite build
- preview: vite preview
- lint: eslint .
- typecheck: tsc -p tsconfig.json --noEmit
- test: vitest
- test:e2e: playwright test

---

## Runtime configuration (Vite env vars)

All runtime config must be via VITE_* env vars (no hardcoded URLs).

Recommended:
- VITE_USE_MOCKS=1|0 (default 1 during MVP)
- VITE_NOTAM_URL=https://aim.eans.ee/web/notampib/area24.json
- VITE_ADSB_URL=...
- VITE_DRONE_URL=...
- VITE_SENSORS_URL=...
- VITE_MAP_WMTS_URL=... (Maa-amet WMTS base URL)
- VITE_AUTH_MODE=off|basic (default off)
- VITE_POLL_ADSB_MS=10000
- VITE_POLL_DRONES_MS=1000
- VITE_POLL_SENSORS_MS=1000

**Note:** even if some docs say “use a proxy for Maa-amet”, we do not do that in MVP. (See non-negotiables.)

---

## Project structure (where code goes)

Keep OpenLayers isolated from UI panels.

src/
app/
main.tsx # app bootstrap
App.tsx # router + global providers
routes.tsx # tool routing (/:tool)
env.ts # typed env access (VITE_*)
layout/
MapShell/
MapShell.tsx # persistent map + chrome + sidebar
LeftSidebar.tsx
TopToolbar.tsx
SessionControls.tsx
urlState.ts # parseTool/parseEntity helpers
useSidebarUrlState.ts # setters w/ replace policy
map/
MapView.tsx # owns OpenLayers Map instance
mapApi.ts # narrow API UI can call
layers/
maaAmetOrthoWmts.ts # WMTS config in one place
vectors.ts # vector layers (drones/sensors/notams)
styles/ # OL styles (icons, labels)
transforms.ts # EPSG:4326 <-> 3857 boundary helpers
features/
air/ # tool panels (NO OpenLayers imports)
AirTrafficPanel.tsx
sensors/
SensorsPanel.tsx
drones/
KnownDronesPanel.tsx
geofences/
GeofencesPanel.tsx
history/
HistoryPanel.tsx
objectDetails/
ObjectDetailsPanel.tsx
services/
polling/
usePolling.ts # shared polling hook w/ AbortController
adsb/
adsbClient.ts # fetch + DTO->domain mapping
adsbTypes.ts
drones/
droneClient.ts
droneTypes.ts
sensors/
sensorsClient.ts
sensorsTypes.ts
notam/
notamClient.ts # fetch JSON
notamInterpreter.ts # interpret + normalize into meters
notamTypes.ts
shared/
types/
domain.ts # Domain types (Altitude, EntityRef, etc.)
time/
utc.ts # parse/format (UTC in, local out)
units/
altitude.ts # ft<->m + formatting helpers
speed.ts # m/s + km/h helpers
ui/
EmptyState.tsx
KeyValueRow.tsx
StatusPill.tsx
mocks/
handlers.ts # MSW request handlers
browser.ts # MSW browser worker (optional)
server.ts # MSW node server for Vitest
public/
mock/
drones.json
sensors.json
adsb.json
notams.sample.json
docs/
ARCHITECTURE.md
DATA_SOURCES.md
UI_RULES.md

markdown
Copy code

---

## Architecture boundaries (enforced)

### Map boundary
- src/map/MapView.tsx owns the OpenLayers Map instance.
- Feature panels must not import OpenLayers or mutate map state directly.
- Panels communicate through a narrow mapApi:
  - mapApi.setSelection({ kind, id })
  - mapApi.setLayerVisibility(key, visible)
  - mapApi.focusEntity(ref)

### Data boundary
- Services normalize raw DTOs into domain types.
- Panels render **view models** (already formatted strings), not raw DTOs.

---

## Routing & deep links (contract)

Tool belongs in the path:
- /air
- /sensors
- /geofences
- /known-drones
- /history?hDate=2025-12-18&hArea=T1
- Global entity selection: /air?entity=sensor:425006

Policy:
- Tool changes push history.
- Entity selection replaces history by default (don’t spam back button).

Implement using React Router like:
- routes.tsx with /:tool and a persistent MapShell
- useSidebarUrlState() managing tool, entity, and history query params.

---

## Auth mode (scaffold only)

Env: VITE_AUTH_MODE=off|basic

In off mode, behave as logged-in admin:
ts
const mockUser = { username: "demo", roles: ["admin"] as const };

export function useAuth() {
  return { isAuthenticated: true, user: mockUser, login: async () => {}, logout: () => {} };
}
Do not implement “basic” yet beyond placeholders and interfaces.

Domain types & UI rules (strict)
Altitude types (use these)
ts
Copy code
export type AltitudeRef = "AGL" | "MSL";
export type AltitudeSource = "detected" | "reported" | "unknown";

export type Altitude = {
  meters: number | null;
  ref: AltitudeRef;
  source: AltitudeSource;
  comment?: string;  // ALWAYS shown next to altitude
  rawText?: string;  // if upstream gave unparseable text
};
Display rules
No naked altitude numbers.

Always show altitude like:

86 m — AGL (detected)

120 m — AGL (reported)

540 m — MSL (unknown)

NOTAM-derived altitudes are stored in meters but UI shows both:

300 m (984 ft) — MSL (reported) (example)

NOTAM handling (prototype)
Fetch NOTAM JSON from VITE_NOTAM_URL.

Implement a module services/notam/notamInterpreter.ts that:

Parses/decodes NOTAM text where needed

Normalizes altitudes/levels into meters

Produces domain objects ready for UI and map layers

You may use an existing JS decoder library (adapter style) but keep it behind notamInterpreter.ts so we can swap implementations later.

Polling behavior (prototype)
ADS-B: poll every 10 seconds (default)

Drones: poll ~1 Hz (default)

Sensors: poll ~1 Hz (default)

Rules:

Use AbortController to cancel in-flight requests on interval tick/unmount.

On network error: keep last good data and expose a “stale” indicator (e.g., last fetch age).

Maa-amet WMTS base layer
Use Maa-amet orthophoto via WMTS.

Keep all WMTS config in src/map/layers/maaAmetOrthoWmts.ts.

Support future proxy via env var, but DO NOT implement it now.

TODOs (do not hallucinate):

Exact WMTS layer name, matrixSet, attribution text, tile grid details.

Testing (minimum bar)
Unit + component (Vitest + RTL)
Required tests:

formatAltitude() / formatSpeed() / formatNotamAltitude() (units/comments rules)

parseTool() / parseEntity() / URL state helpers

Panel empty state renders + basic list render (History/Air/Sensors)

Network mocking (MSW)
Mock NOTAM / ADS-B / drones / sensors endpoints so polling is deterministic.

E2E smoke (Playwright)
At least:

App loads → map renders → base layer visible

Switch tools → sidebar panel changes

Click a marker → Object details opens (or selection updates URL)

Change policy (three-tier)
✅ Always:

Keep PRs small and runnable.

Run: typecheck + lint + unit tests before calling work “done”.

⚠️ Ask first:

Adding new runtime dependencies

Changing polling intervals, schemas, projections, or URL contract

Introducing a global state framework beyond lightweight needs

🚫 Never:

Commit secrets / API keys

Spread unit/time conversion logic outside src/shared/

Put OpenLayers logic in src/features/* panels

Add a proxy (until GUI works)

Companion docs (keep current)
docs/ARCHITECTURE.md — MapShell + panel router + polling overview (1 page)

docs/DATA_SOURCES.md — endpoints, polling rates, JSON shape examples (draft OK)

docs/UI_RULES.md — time/units/labels rules (so nobody guesses)

###############

let's skip auth for now being implemented, but code must be created such it could be "turned on" to have username/pass. auth off feature acts as if user has been logged in with full admin rights. VITE_AUTH_MODE=off|basic

in off:

const mockUser = { username: "demo", roles: ["admin"] as const };

export function useAuth() {
  return { isAuthenticated: true, user: mockUser, login: async () => {}, logout: () => {} };
}

--

Deep link to history view for a day:
/history?hDate=2025-12-18

Same but area-scoped:
/history?hDate=2025-12-18&hArea=T1

Direct link to an object detail from any tool:
/air?entity=sensor:425006

Why this contract:

tool belongs in the path (nice URLs, fast routing decisions).

entity is global, so selecting something on the map works the same regardless of tool.

Only the minimum history context goes into URL. Everything else stays local.

2) Router setup (persistent map shell, tool panels inside)
// src/app/routes.tsx
import { createBrowserRouter, Navigate } from "react-router-dom";
import { MapShell } from "@/layout/MapShell/MapShell";

export const router = createBrowserRouter([
  { path: "/", element: <Navigate to="/air" replace /> },
  {
    path: "/:tool",
    element: <MapShell />,
  },
]);

MapShell renders:

the OpenLayers map (persistent)

top-left toolbar (navigation)

top-right session controls (mock admin)

left sidebar (tool panel OR entity detail)

3) Typed URL state helpers (single source of truth)
// src/layout/MapShell/urlState.ts
export const TOOLS = ["air", "geofences", "sensors", "known-drones", "history"] as const;
export type Tool = (typeof TOOLS)[number];

export type EntityKind = "sensor" | "geofence" | "flight" | "notam" | "drone";
export type EntityRef = { kind: EntityKind; id: string };

export function parseTool(raw: string | undefined): Tool {
  return (TOOLS as readonly string[]).includes(raw ?? "") ? (raw as Tool) : "air";
}

export function parseEntity(raw: string | null): EntityRef | null {
  if (!raw) return null;
  const idx = raw.indexOf(":");
  if (idx <= 0) return null;
  const kind = raw.slice(0, idx) as EntityKind;
  const id = raw.slice(idx + 1);
  if (!id) return null;
  if (!["sensor","geofence","flight","notam","drone"].includes(kind)) return null;
  return { kind, id };
}

export function formatEntity(e: EntityRef): string {
  return `${e.kind}:${e.id}`;
}

4) useSidebarUrlState hook (the “hybrid brain”)

This hook reads tool from the path and the “shareable bits” from search params, and exposes small, safe setters.

Key detail: setSearchParams is navigation; you can pass { replace: true } to avoid filling browser history with every selection change. 
reactrouter.com
+1

// src/layout/MapShell/useSidebarUrlState.ts
import { useMemo } from "react";
import { useNavigate, useParams, useSearchParams } from "react-router-dom";
import { formatEntity, parseEntity, parseTool, Tool, EntityRef } from "./urlState";

type HistoryCtx = { dateUtc?: string; area?: string };

export function useSidebarUrlState() {
  const navigate = useNavigate();
  const params = useParams();
  const [sp, setSp] = useSearchParams();

  const tool: Tool = useMemo(() => parseTool(params.tool), [params.tool]);
  const entity = useMemo(() => parseEntity(sp.get("entity")), [sp]);

  const history: HistoryCtx = useMemo(
    () => ({ dateUtc: sp.get("hDate") ?? undefined, area: sp.get("hArea") ?? undefined }),
    [sp]
  );

  function setTool(next: Tool) {
    // keep query params (entity/history) unless you intentionally clear them
    navigate({ pathname: `/${next}`, search: sp.toString() ? `?${sp.toString()}` : "" });
  }

  function selectEntity(next: EntityRef | null, opts?: { replace?: boolean }) {
    const nextSp = new URLSearchParams(sp);
    if (next) nextSp.set("entity", formatEntity(next));
    else nextSp.delete("entity");
    setSp(nextSp, { replace: opts?.replace ?? true }); // default replace for clicks
  }

  function setHistory(next: { dateUtc?: string; area?: string }, opts?: { replace?: boolean }) {
    const nextSp = new URLSearchParams(sp);
    if (next.dateUtc) nextSp.set("hDate", next.dateUtc); else nextSp.delete("hDate");
    if (next.area) nextSp.set("hArea", next.area); else nextSp.delete("hArea");
    setSp(nextSp, { replace: opts?.replace ?? true });
  }

  return { tool, entity, history, setTool, selectEntity, setHistory };
}

Policy baked in:

Tool changes → push a new route (natural back/forward)

Entity selection changes → replace by default (no “back 50 times to undo clicks”)

This aligns with URL-state best practices: keep durable/shareable state in the URL, but don’t spam history. 
LogRocket Blog
+1

5) Sidebar rendering logic (matches your “Object detail panel” behavior)

The sidebar shows either:

ObjectDetailsPanel when entity exists, OR

Tool panel when no entity is selected.

// src/layout/MapShell/LeftSidebar.tsx
import { Tool } from "./urlState";
import { AirTrafficPanel } from "@/features/airTraffic/AirTrafficPanel";
import { GeofencesPanel } from "@/features/geofences/GeofencesPanel";
import { SensorsPanel } from "@/features/sensors/SensorsPanel";
import { KnownDronesPanel } from "@/features/knownDrones/KnownDronesPanel";
import { HistoryPanel } from "@/features/history/HistoryPanel";
import { ObjectDetailsPanel } from "@/features/objectDetails/ObjectDetailsPanel";

export function LeftSidebar(props: {
  tool: Tool;
  entity: { kind: string; id: string } | null;
  onCloseEntity: () => void;
}) {
  const { tool, entity } = props;

  if (entity) {
    return <ObjectDetailsPanel entity={entity} onClose={props.onCloseEntity} />;
  }

  switch (tool) {
    case "air": return <AirTrafficPanel />;
    case "geofences": return <GeofencesPanel />;
    case "sensors": return <SensorsPanel />;
    case "known-drones": return <KnownDronesPanel />;
    case "history": return <HistoryPanel />;
    default: return <AirTrafficPanel />;
  }
}

Now your map click selection can always do: selectEntity({kind:"sensor", id:"425006"}), and the UI becomes “entity profile” regardless of which tool was active—exactly like your spec.

6) Where local state lives (and what stays out of URL)

Keep these local (React state or context):

sidebar collapsed / width

map popups (anchored tooltip cards)

transient filters that change per keystroke

geofence wizard draft geometry (until “Save”)

layer toggles (“Layers” button) unless you explicitly want shareable layer states

Local state belongs here because it’s not something a user needs to bookmark/share, and it would make URLs noisy.

7) Top-left toolbar integration (icons → route)

Your toolbar icon click just calls setTool("history") etc. Because the tool is in the path, a link is also trivial:

// either
onClick={() => url.setTool("history")}

// or declarative
<Link to={{ pathname: "/history", search: location.search }} />

For query params, useSearchParams is the canonical hook. 
reactrouter.com
+1

8) History panel behavior (URL-backed date/area)

Date arrows update hDate with replace: true.

“Select area” sets hArea.

Selecting a flight sets entity=flight:<id> (ObjectDetails panel shows the flight profile).

This makes a killer demo link: “Here are yesterday’s flights in T1”.

9) Auth OFF = admin (but future-proof)

Implement AuthProvider as a swap later; for now:

useAuth() always returns { isAuthenticated: true, roles: ["admin"] }

UI components can already be written “as if roles exist”

Later you gate with the same hook, no refactor

--

ads-b will be API calls from web until we have backend. same for sensors.

Material UI (MUI Material) as the baseline

--

for companion file that helps agents even more, add DATA_SOURCES.md with “current endpoints + JSON shape examples” and keep it updated as the prototype evolves.

we will add:
ARCHITECTURE.md: “MapShell + Panel Router + Data Polling” in one page.

DATA_SOURCES.md: endpoints, polling rates, schemas (even if “draft”).

UI_RULES.md: units/time/labels (so agents stop guessing).
--
use npm for packet manager.

--

we will use all queries directly without proxy until we get GUI working. (this idea must stay in agents.md until further notice, no matter what other documentations say!!! hard rule!

write agents.md in english!
output in canvas, with all appropriate md formatting.

5/5

## Response:
Thought for 32s

Agents

✅ Created **AGENTS.md** in canvas with all the constraints, folder structure, routing contract, map/projection rules, polling, NOTAM module guidance, and testing baseline—written in English and optimized for “frontend up and running fast.”

## Prompt:
Agents

create initial docs/DATA_SOURCES.md

## Response:
Thought for 54s

**Docs/data Sources**

# DATA_SOURCES.md

This document inventories **all data sources** used by the **frontend-first** prototype.

**Hard rule reminder:** **NO PROXY.** All requests are made **directly from the browser** until the GUI works. If CORS blocks a source, keep mocks enabled and document the failure here.

---

## Quick start

### Use mocks (default)

- Set `VITE_USE_MOCKS=1`
- Data is loaded from `public/mock/*` via `fetch("/mock/<file>.json")`
- MSW may be used in tests to mock remote endpoints deterministically.

### Use live endpoints

- Set `VITE_USE_MOCKS=0`
- Provide the relevant `VITE_*_URL` env vars
- If any endpoint fails due to CORS/network, revert to mocks and note it below.

---

## Sources at a glance

### NOTAM

- **Purpose:** NOTAM list + (where possible) geometry overlays on the map.
- **Env var:** `VITE_NOTAM_URL`
- **Default URL:** `https://aim.eans.ee/web/notampib/area24.json`
- **Refresh:** poll every `VITE_POLL_NOTAM_MS` (if not set, treat as **60s** in prototype)
- **Notes:** NOTAM interpretation is **frontend-only** for the prototype; later moved to backend.

### Drone telemetry

- **Purpose:** show drone positions and basic metadata.
- **Env var:** `VITE_DRONE_URL`
- **Refresh:** `VITE_POLL_DRONES_MS` (default **1000 ms**)
- **Fallback:** `/mock/drones.json`

### Sensors

- **Purpose:** show sensor locations + status + optional detections.
- **Env var:** `VITE_SENSORS_URL`
- **Refresh:** `VITE_POLL_SENSORS_MS` (default **1000 ms**)
- **Fallback:** `/mock/sensors.json`

### ADS-B (prototype)

- **Purpose:** show basic air traffic overlays.
- **Env var:** `VITE_ADSB_URL`
- **Refresh:** `VITE_POLL_ADSB_MS` (default **10000 ms**)
- **Fallback:** `/mock/adsb.json`

### Maa-amet WMTS basemap

- **Purpose:** orthophoto basemap.
- **Env var:** `VITE_MAP_WMTS_URL`
- **Refresh:** tiles load on demand.
- **Notes:** WMTS config details are tracked as TODOs in `src/map/layers/maaAmetOrthoWmts.ts`.

---

## Shared conventions

### Coordinates

- **Domain storage:** WGS-84 (EPSG:4326) `[lon, lat]`
- **Map view:** EPSG:3857
- **Rule:** transform only at boundaries (OpenLayers feature creation/render).

### Time

All domain events must carry:

- `eventTimeUtc`: when the event happened (from upstream if present)
- `ingestTimeUtc`: when the frontend received/processed it (set client-side)

**UTC everywhere** in domain/storage logic. Local time only in UI formatting.

### Units

- Distances: meters
- Drone speed: m/s
- Aircraft speed: km/h
- Altitudes:
  - stored in meters (m)
  - **UI always shows a comment next to altitude**
  - aircraft + NOTAM altitude text always shows **both ft and m**

---

## Data shapes (prototype contracts)

These JSON shapes define what the **frontend prototype** expects.

- Real upstream schemas may differ.
- The app should map upstream DTOs into the internal domain objects.
- If a live endpoint differs, adjust only the client mapping layer (`src/services/*/*Client.ts`) and update this doc.

### 1) Drone telemetry (mock + browser DTO)

**File:** `public/mock/drones.json`

**Type:** `DroneTelemetryDto[]`

```json
[
  {
    "id": "drone-001",
    "label": "DJI Mavic (demo)",
    "position": { "lon": 24.7536, "lat": 59.4369 },
    "headingDeg": 90,
    "speedMps": 12.4,
    "altitude": {
      "meters": 86,
      "ref": "AGL",
      "source": "detected",
      "comment": "RF+vision fused"
    },
    "eventTimeUtc": "2025-12-18T10:15:30Z"
  }
]
```

**Mapping notes**

- `ingestTimeUtc` is added client-side.
- If upstream provides altitude as text (e.g., “120m AGL est.”), store parsable meters and keep the text in `altitude.rawText`.

---

### 2) Sensors (mock + browser DTO)

**File:** `public/mock/sensors.json`

**Type:** `SensorDto[]`

```json
[
  {
    "id": "sensor-425006",
    "name": "Demo Sensor A",
    "kind": "rf",
    "position": { "lon": 24.744, "lat": 59.428 },
    "status": "online",
    "lastSeenUtc": "2025-12-18T10:15:25Z",
    "coverage": {
      "radiusMeters": 5000,
      "minAltM": 0,
      "maxAltM": 500
    }
  }
]
```

**Mapping notes**

- Sensor coverage is optional in MVP; keep `coverage` nullable if not known.
- If a sensor also emits detections, keep detections in the **drone/object** stream, not embedded in the sensor record.

---

### 3) ADS-B (prototype)

**File:** `public/mock/adsb.json`

**Type:** `AdsbTrackDto[]`

```json
[
  {
    "id": "4ca123",
    "callsign": "FIN123",
    "position": { "lon": 24.832, "lat": 59.413 },
    "trackDeg": 275,
    "groundSpeedKmh": 720,
    "altitude": {
      "meters": 3500,
      "ref": "MSL",
      "source": "reported",
      "comment": "ADS-B reported (pressure altitude)"
    },
    "eventTimeUtc": "2025-12-18T10:15:20Z"
  }
]
```

**UI rules reminder**

- Aircraft speed: show **km/h**.
- Aircraft altitude: show **both ft and m** in text.

---

### 4) NOTAM feed

**Live URL:** `https://aim.eans.ee/web/notampib/area24.json`

Because live access may be affected by CORS/timeouts, the repo also includes:

- **File:** `public/mock/notams.sample.json`

The prototype stores:

1) The **raw upstream record** (for debugging), and
2) A **normalized NOTAM domain object** used by the map/panels.

#### 4.1 Raw NOTAM JSON (as stored in mocks)

**Type:** `unknown` (schema may change)

For the mock file, we use a minimal stable structure:

```json
{
  "generatedAtUtc": "2025-12-18T10:00:00Z",
  "items": [
    {
      "id": "A1234/25",
      "text": "TEMP RESTRICTED AREA ... SFC TO 3000FT AMSL ...",
      "validFromUtc": "2025-12-18T00:00:00Z",
      "validToUtc": "2025-12-19T23:59:59Z",
      "raw": {
        "provider": "EANS",
        "payload": "...optional raw fields..."
      }
    }
  ]
}
```

#### 4.2 Normalized NOTAM domain object (frontend output)

Produced by `src/services/notam/notamInterpreter.ts`.

Key fields the UI expects:

- `id` (e.g., `A1234/25`)
- `summary` (short, UI-safe text)
- `text` (full NOTAM text)
- `validFromUtc`, `validToUtc`
- `altitudes[]` normalized into meters (and always carrying a comment)
- `geometry` (optional): derived polygon/circle/line when possible

Example normalized record:

```json
{
  "id": "A1234/25",
  "summary": "TEMP RESTRICTED AREA (demo)",
  "text": "TEMP RESTRICTED AREA ... SFC TO 3000FT AMSL ...",
  "validFromUtc": "2025-12-18T00:00:00Z",
  "validToUtc": "2025-12-19T23:59:59Z",
  "altitudes": [
    {
      "meters": 0,
      "ref": "AGL",
      "source": "reported",
      "comment": "SFC from NOTAM"
    },
    {
      "meters": 914.4,
      "ref": "MSL",
      "source": "reported",
      "comment": "3000 FT AMSL from NOTAM",
      "rawText": "3000FT AMSL"
    }
  ],
  "geometry": null,
  "eventTimeUtc": "2025-12-18T10:00:00Z"
}
```

**UI rule reminder**

- NOTAM altitude text must show **both ft and m**, even though `meters` is stored.

---

## Polling and staleness

All polling uses `AbortController` and should:

- cancel the previous in-flight request if a new tick occurs
- keep last known-good data on error
- expose a “stale” indicator (e.g., age since `ingestTimeUtc`)

Defaults (unless overridden by env vars):

- `ADS-B`: 10s
- `Drones`: 1s
- `Sensors`: 1s
- `NOTAM`: 60s (prototype assumption; update if product decides otherwise)

---

## Known CORS / access issues (fill in as discovered)

Record issues here so engineers don’t waste time.

- `VITE_NOTAM_URL`: (TODO) verify in browser devtools; if blocked, keep using `/mock/notams.sample.json`.
- Maa-amet WMTS: (TODO) verify tile requests from the browser; note any required headers or access constraints.

---

## Change log (keep short)

- 2025-12-18: initial draft created (frontend-first, mock-driven)

Added an initial **docs/DATA\_SOURCES.md** to the canvas: sources inventory, env vars, polling defaults, conventions (UTC/units/WGS-84), and prototype JSON shape examples for drones/sensors/ADS-B/NOTAM (with clear “no proxy” + CORS notes).

## Prompt:
create initial UI_RULES.md

1/2

## Response:
**Docs/ui Rules**

# UI_RULES.md

These rules define how the prototype UI must display **time, units, labels, and status** so the interface is consistent and nobody has to guess.

Scope: **frontend prototype only**.

---

## Golden rules

1) **UTC everywhere in domain/storage logic**
   - All domain objects and any persisted data use UTC.
   - UI may show local time, but only at the formatting boundary.

2) **Metric first**
   - Metric units are the default across the UI.

3) **No naked numbers**
   - Any numeric field shown to the user must include its unit and (where required) contextual qualifiers.

4) **Always show data freshness**
   - When something is polled, the UI must expose “last updated” / “stale” state.

---

## Time rules

### Internal representation

- Store and transport time as ISO-8601 UTC strings, e.g. `2025-12-18T10:15:30Z`.
- Every event-like item must carry both:
  - `eventTimeUtc` — when the event happened (from upstream when possible)
  - `ingestTimeUtc` — when the frontend received/processed it

### UI display

- Default display is **local time** (user’s browser timezone) unless otherwise noted.
- The UI should be explicit about the timezone in labels:
  - `Time (local): 12:15:30`
  - `Event time (UTC): 10:15:30Z` (when showing both)

### Formatting

- Recommended: `YYYY-MM-DD HH:mm:ss` for tables/details.
- For compact lists: `HH:mm:ss` plus a hover/tooltip with full timestamp.

### Relative time

- When useful, show relative time alongside absolute time:
  - `Last update: 12s ago (10:15:30Z)`

---

## Coordinates & map display

### Domain geometry

- All domain coordinates are WGS-84 (EPSG:4326) as `[lon, lat]`.
- OpenLayers `View` uses EPSG:3857; transform only at boundaries.

### Display format

- Default coordinate label in UI details:
  - `Lon/Lat: 24.753600, 59.436900`
- Precision:
  - Use **6 decimals** for lon/lat by default (≈ 0.11 m at equator; good enough for UI).
  - If upstream precision is worse, do not invent extra precision.

### Optional secondary formats

- If needed later, add toggles for:
  - DMS (degrees/minutes/seconds)
  - MGRS

Do not add these until the MVP UI is stable.

---

## Units

### Distance

- Use meters (`m`) by default.
- For large distances, allow kilometers (`km`) in summaries, but keep meters available in tooltips/details.

### Speed

- Drones:
  - store and display as **m/s**
  - formatting: `12.4 m/s`

- Aircraft:
  - store as appropriate, but display as **km/h**
  - formatting: `720 km/h`

Rounding:

- Default: 1 decimal for m/s, integer for km/h.
- If value is unknown: show `—` (em dash) rather than `0`.

### Heading

- Display degrees: `275°`.
- If available, show cardinal hint in tooltip (`W`, `NW`, etc.).

---

## Altitude (strict)

### Types

Use these types verbatim:

```ts
export type AltitudeRef = "AGL" | "MSL";
export type AltitudeSource = "detected" | "reported" | "unknown";

export type Altitude = {
  meters: number | null;
  ref: AltitudeRef;
  source: AltitudeSource;
  comment?: string;
  rawText?: string;
};
```

### Storage

- Store altitude numeric values in **meters**.
- Always preserve:
  - `ref`: `AGL` (Above Ground Level) or `MSL` (Mean Sea Level)
  - `source`: `detected` (sensor-derived) vs `reported` (drone/ADS-B/NOTAM-provided) vs `unknown`

### Display (required)

- **Never** display altitude as a bare number.
- Always display with:
  - meters
  - reference (AGL/MSL)
  - source
  - comment shown next to it

Examples:

- `86 m — AGL (detected) — RF+vision fused`
- `120 m — AGL (reported) — operator reported`
- `540 m — MSL (unknown) — upstream missing ref`

### Comment rule

- `comment` must be displayed inline next to the altitude.
- If there is no meaningful comment, supply a short one in mapping:
  - e.g. `"from upstream"`, `"from NOTAM"`, `"estimated"`

### NOTAM / aircraft dual-unit rule

- NOTAM-derived altitude text shown to the user must include **both meters and feet**.
- Aircraft altitude display should also include **both meters and feet**.

Example:

- `300 m (984 ft) — MSL (reported) — 3000 FT AMSL from NOTAM`

If upstream provides unparseable text:

- `— — (reported) — <comment> (raw: "SFC-UNL")`

Where `rawText` is appended as: `raw: "..."`.

---

## Labels & naming

### Identifiers

- IDs are technical; show them in details, not as primary labels.
- Preferred label precedence:
  1) `label` / `name`
  2) `callsign` (aircraft)
  3) `id`

### Unknown values

- Use `—` (em dash) for missing values.
- Use explicit `Unknown` when the *concept* is unknown (e.g., altitude source).

### Consistent wording

- Use “Drone” for UAS targets in the UI.
- Use “Sensor” for fixed/mobile detection devices.
- Use “Flight” or “Aircraft” for ADS-B tracks.
- Use “NOTAM area” for NOTAM geometry overlays.

---

## Data freshness & staleness

### Polling freshness

For each polled stream (ADS-B, drones, sensors, NOTAM):

- Store:
  - `lastFetchOkUtc`
  - `lastFetchErrorUtc` (optional)
  - `lastFetchDurationMs` (optional)

### Display

- Show a small status element per stream:
  - `Drones: live (updated 2s ago)`
  - `ADS-B: stale (updated 47s ago)`
  - `NOTAM: error (last ok 8m ago)`

### Thresholds (prototype defaults)

- `live`: last update ≤ 2× poll interval
- `stale`: last update > 2× poll interval
- `error`: last fetch failed AND last ok is older than 2× poll interval

These thresholds are UI-only and can be adjusted later.

---

## Map overlays & selection

### Marker semantics

- Drones: show heading if available (rotated icon) and optionally a short label.
- Sensors: fixed markers; optionally show coverage (circle/polygon) as a toggle.
- NOTAM: polygon/circle overlays with a label chip (e.g., `A1234/25`).

### Selection

- Map selection should:
  1) update `entity` query param
  2) open the Object Details panel in the sidebar
  3) visually highlight the selected feature on the map

### Clutter control

- Prefer clustering or label suppression at low zoom.
- Never show more text than can fit cleanly on the map; details belong in panels.

---

## Panels & tables

### Lists

- Lists should show:
  - primary label
  - minimal status (live/stale/offline)
  - a timestamp or “age” indicator

### Details

- Details view should use consistent key/value rows:
  - `Position`, `Altitude`, `Speed`, `Heading`, `Event time`, `Ingest time`, `Source`

### Tooltips

- Tooltips are for short clarifications (units, full timestamps, rawText), not for complex UI.

---

## Errors & empty states

- Empty states must be explicit:
  - `No drones currently visible.`
  - `No NOTAMs returned by the feed.`

- Network errors:
  - show a non-blocking banner/chip
  - keep last known-good data visible
  - show “last ok” time

---

## Accessibility & interaction

- Click targets must be comfortably sized (MUI defaults are fine).
- Keyboard navigation should work for the sidebar lists.
- Do not rely on color alone to indicate status; always include text or icons.

---

## Out of scope (for now)

- User roles/permissions UI
- Audit logs
- Sensitive data handling
- Printing/export

These will be added after the MVP GUI is stable.

Created initial **docs/UI\_RULES.md** in the canvas: strict altitude formatting (AGL/MSL + source + always-visible comment), UTC vs local time rules, units, staleness indicators, map selection behavior, and consistent labels/empty states.

## Prompt:
write an implementation plan .md to steer the development

some VERY BROAD AND FAGUE IDEAS: first stage - mocked sensors gui. no backend. one airplane and one drone flying in linear motion from file data. (whatever is simple for testing) geofence adding, sensor adding, geofences from notam. then add api for adsb. add api for a single drone sensor (others mocked) then add backend database for persistance (geo areas, history) after that we add proxy servers, drone history, logging, authentication etc. -- tools in-app mode. Single map instance with layered overlays -- smoke path: Load map switch tools create geofence (at least circle) add a sensor see a drone flying in gui. Treat map rendering as integration/E2E-heavy; test pure logic separately (geo conversions, filtering, reducers, API clients).

2/2

## Response:
**Docs/implementation Plan**

# IMPLEMENTATION_PLAN.md

This plan steers development of the **frontend-first** Estonia drone location web app.

**North star:** a single-map UI that can show drones, sensors, NOTAMs, and basic air traffic with fast iteration using mocks and polling.

**Hard constraints:**

- **NO PROXY** until the GUI is working (see `AGENTS.md`).
- **Frontend-first**: read from `public/mock/*` and public endpoints.
- **UTC everywhere in domain logic**, local time only at UI formatting boundary.
- Domain coordinates in **WGS-84 (lon/lat)**; map view **EPSG:3857**.

---

## Definition of “done” for the prototype (smoke path)

A build is “prototype-done” when the following smoke path works locally:

1) Load the app → map renders with Maa-amet WMTS basemap.
2) Switch tools (Air / Sensors / Geofences / History) → sidebar changes.
3) Add a geofence (at least a circle) → it appears on the map and in the list.
4) Add a sensor → it appears on the map and in the list.
5) See a drone (mock) moving on the map (linear motion is fine) and details update.

**Testing strategy:** treat map rendering as integration/E2E-heavy; test pure logic separately.

---

## Phases overview

- **Phase 0** — Repo scaffolding and baseline UI skeleton
- **Phase 1** — Mocked sensors + mocked moving drone + basic layers
- **Phase 2** — Geofences (create/edit/delete) + sensor add/remove (mock persistence)
- **Phase 3** — NOTAM ingest + NOTAM overlays + “geofence from NOTAM” (best-effort)
- **Phase 4** — Live ADS-B client (browser fetch) + fallback to mocks
- **Phase 5** — Live single drone sensor client + others still mocked
- **Phase 6** — Backend persistence (geo areas + history)
- **Phase 7** — Add proxy servers (only after GUI is stable)
- **Phase 8** — Logging, authentication, roles, audit, history UX upgrades

Each phase has acceptance criteria and the minimum tests required.

---

## Phase 0 — Repo scaffolding + baseline UI skeleton

### Goals

- App boots with routing contract and a persistent map shell.
- Basic tool navigation works.
- Testing harness is in place.

### Deliverables

- React + Vite + TS + MUI baseline.
- Router with `/:tool` and default redirect to `/air`.
- `MapShell` layout:
  - persistent OpenLayers map
  - top toolbar (tool switch)
  - left sidebar (tool panels)
  - session controls stub (auth off mode)
- Stubs for panels:
  - `AirTrafficPanel`, `SensorsPanel`, `GeofencesPanel`, `HistoryPanel`, `ObjectDetailsPanel`
- `docs/ARCHITECTURE.md` draft (1 page) describing MapShell + routing.

### Acceptance

- `npm run dev` opens `/air` and map element exists.
- Tool switching changes sidebar.

### Tests

- Unit tests for URL helpers: `parseTool`, `parseEntity`, `formatEntity`.
- Playwright smoke: load app → verify sidebar title changes when switching tools.

---

## Phase 1 — Mocked sensors + mocked moving drone + basic layers

### Goals

- Show mocked sensors and drone(s) as vector layers.
- Demonstrate motion with **one airplane and one drone** moving in simple linear motion from file data.

### Implementation notes

- Prefer the simplest approach: a precomputed time series in `/public/mock/drones.json` and `/public/mock/adsb.json`.
- UI can “animate” by selecting a row based on `Date.now()` modulo duration.
- Keep domain objects in WGS-84; transform when creating OL features.

### Deliverables

- Vector layers:
  - sensors markers
  - drones markers
  - ADS-B markers (mock-only in this phase)
- Details panel shows:
  - position
  - altitude formatting (with comment)
  - speed formatting
  - event/ingest times
- “Stale” indicator per stream (even for mocks).

### Acceptance

- On load, at least one sensor is visible.
- One drone moves smoothly/stepwise across the map.
- One aircraft track is visible (mock).

### Tests

- Unit: `formatAltitude`, `formatSpeed`, ft↔m conversion.
- MSW: polling returns deterministic mocked responses.
- Playwright: open app → drone marker exists → after ~2s position changes.

---

## Phase 2 — Geofences + sensor add/remove (mock persistence)

### Goals

- Users can create geofences (circle minimum; polygon optional later).
- Users can add/remove sensors (still mock-based) and see them on the map.

### Implementation notes

- Persistence is **in-memory** first, optionally `localStorage` behind a small adapter.
- Keep geofence geometry stored in WGS-84.
- Editing UX can be minimal:
  - create circle by clicking center and entering radius
  - list view to rename/delete

### Deliverables

- Geofence CRUD in UI:
  - create circle
  - list
  - delete
  - basic rename
- Sensor CRUD in UI (prototype):
  - add sensor with lon/lat + name + kind
  - delete sensor
- `docs/DATA_SOURCES.md` updated to include geofence and local persistence notes.

### Acceptance

- Create a circle geofence → appears on map layer and in geofence list.
- Add a sensor → appears on map and in sensors list.

### Tests

- Unit: geometry helpers (circle approximation, WGS84 storage).
- Component: GeofencePanel form submits and list updates.
- Playwright: create geofence end-to-end.

---

## Phase 3 — NOTAM ingest + overlays + “geofence from NOTAM”

### Goals

- Fetch NOTAM JSON (EANS) or use mock if blocked.
- Interpret enough to display a NOTAM list and (best-effort) map overlays.
- Create geofences from NOTAM entries (manual confirmation button).

### Implementation notes

- Keep NOTAM interpretation in `services/notam/notamInterpreter.ts` (adapter boundary).
- Expect NOTAM parsing to be imperfect in frontend prototype.
- If geometry can’t be derived, still show the NOTAM entry and mark geometry as unavailable.

### Deliverables

- NOTAM panel:
  - list entries
  - validity window
  - altitude display in **m and ft**
  - “Create geofence from NOTAM” action (where possible)
- NOTAM map layer (polygons/circles when available).

### Acceptance

- NOTAMs load (live or mock) and are visible in a list.
- At least one NOTAM overlay can be displayed from mock samples.
- User can create a geofence from a NOTAM (using mock geometry).

### Tests

- Unit: NOTAM altitude parsing and formatting (m+ft).
- Unit: NOTAM interpreter returns stable normalized objects for sample fixtures.
- Component: NOTAM list renders and “create geofence” button calls handler.

---

## Phase 4 — Live ADS-B client (browser fetch)

### Goals

- Add a real ADS-B client that polls every 10 seconds.
- Keep fallback to mocks when endpoint fails.

### Implementation notes

- **No proxy**. If CORS blocks, document and keep mocks on.
- Client should:
  - normalize DTO → domain
  - update staleness indicators

### Deliverables

- `services/adsb/adsbClient.ts` with:
  - fetch
  - mapping
  - error handling
- UI toggle (optional): “Live / Mock” badge determined by `VITE_USE_MOCKS`.

### Acceptance

- With a working ADS-B endpoint, aircraft markers update every 10s.
- If endpoint fails, app keeps last good data and shows stale/error state.

### Tests

- MSW: ADS-B endpoint mocked for deterministic unit/integration tests.

---

## Phase 5 — Live single drone sensor client (others mocked)

### Goals

- Integrate one real drone sensor feed (or a single drone API) while keeping the rest mocked.
- Prove the adapter pattern and staleness handling.

### Deliverables

- `services/drones/droneClient.ts` supports:
  - one live feed URL
  - mock fallback
- Data model includes `Altitude` with comments and source.

### Acceptance

- One live drone appears/updates ~1 Hz.
- Mock drones can still be enabled for demos.

### Tests

- Unit: mapping for the live DTO into domain altitude/time rules.
- MSW: simulate intermittent failures and verify stale indicator logic.

---

## Phase 6 — Backend persistence (geo areas + history)

### Goals

- Persist geofences/sensors/history in a DB.
- Introduce a real history timeline and day-scoped history URLs.

### Out of scope

- Proxy servers are still not introduced here unless strictly needed.

### Deliverables

- Backend service (separate repo or folder) providing:
  - geofence CRUD
  - sensor CRUD
  - event history queries
- Frontend clients switch from local storage to backend endpoints via env vars.

### Acceptance

- Refreshing the page keeps geofences/sensors.
- `/history?hDate=YYYY-MM-DD` shows events for the day.

### Tests

- Frontend contract tests against mocked backend endpoints (MSW).
- Backend unit tests for persistence (owned by backend plan).

---

## Phase 7 — Proxy servers (only after GUI is stable)

### Goals

- Add proxy only when it unlocks real integrations blocked by CORS or auth.
- Keep the frontend URL contracts stable.

### Deliverables

- Proxy service endpoints:
  - NOTAM fetch proxy (if needed)
  - Maa-amet tiles proxy (if needed)
  - ADS-B proxy (if needed)

### Acceptance

- Proxy is optional and gated by env var.
- App still works without proxy (mock mode).

---

## Phase 8 — Logging, authentication, roles, audit, history UX upgrades

### Goals

- Add real authentication (`VITE_AUTH_MODE=basic` + backend auth).
- Add role-aware UI (read-only vs operator vs admin) and audit trail.
- Improve history browsing (filters, playback, exports).

### Deliverables

- Auth enabled end-to-end
- Audit events for critical actions:
  - create/delete geofence
  - create/delete sensor
  - login/logout

---

## Work breakdown into milestones (suggested)

1) **M0: Skeleton** (Phase 0)
2) **M1: Demo motion** (Phase 1)
3) **M2: Editable world** (Phase 2)
4) **M3: NOTAM overlay demo** (Phase 3)
5) **M4: Live air traffic** (Phase 4)
6) **M5: First real drone sensor** (Phase 5)

After M5, decide whether to invest next into **backend persistence** or **more sensors**.

---

## Testing guidance (what to test where)

### Prefer unit tests for

- time parsing/formatting boundaries
- unit conversions (ft↔m, m/s↔km/h)
- NOTAM normalization functions
- URL state parsing and formatting

### Prefer E2E/integration tests for

- map rendering and layer visibility
- tool switching + selection UX
- geofence creation interactions

Rationale: OpenLayers rendering is integration-heavy; brittle unit tests around map internals are not worth it.

---

## Risk list (prototype)

- **CORS** from public endpoints (NOTAM, ADS-B, Maa-amet WMTS)
  - Mitigation: mocks + document failures in `docs/DATA_SOURCES.md`.
- NOTAM geometry extraction is messy
  - Mitigation: best-effort in frontend; keep interpreter behind adapter.
- Map clutter at low zoom
  - Mitigation: clustering/label suppression later; keep MVP simple.

---

## What we deliberately postpone

- Robust auth/roles/audit
- Server-side NOTAM parsing
- Persistence and long-term history
- Proxy servers
- Any sensitivity/security hardening

The point is to **get the GUI working** first.

Created **docs/IMPLEMENTATION\_PLAN.md** in the canvas: phased roadmap (mock-first → geofences/sensors → NOTAM overlays → live ADS-B → one real drone sensor → persistence → proxy → auth/audit), with clear acceptance criteria and a smoke-path/E2E-heavy testing strategy for the map.

## Prompt:
create tickets with appropriate codex prompts for ai agent to implement  Phase 0.

2/2

## Response:
Thought for 33s

Below are **Phase 0 implementation tickets** (issue-style) with **copy/paste Codex prompts**. They’re scoped so an agent can land them in small PRs and keep the repo runnable.

* * *

T0-01 — Scaffold Vite + React + TypeScript project (npm-only) + base config
---------------------------------------------------------------------------

**Goal:** Create a working Vite React TS app using **npm**, with the baseline scripts and a clean folder skeleton matching `AGENTS.md`.

**Scope**

*   Vite React TS scaffold
*   `package.json` scripts per `AGENTS.md`
*   TS config, path alias `@/` (tsconfig + vite config)
*   Basic ESLint (minimal) and consistent import resolution

**Acceptance**

*   `npm run dev` starts and loads app
*   `npm run build` succeeds
*   `npm run typecheck` succeeds

**Codex prompt**

```md
You are implementing Phase 0 for this repo. Follow AGENTS.md strictly:
- npm only
- NO PROXY
- router contract is /:tool with redirect / -> /air (but do not implement routing yet unless needed)
- keep folder structure aligned with AGENTS.md

TASK: Create the initial Vite + React + TypeScript project scaffold.
1) Ensure package.json scripts match AGENTS.md exactly: dev/build/preview/lint/typecheck/test/test:e2e.
2) Add tsconfig path alias @/* -> src/* and configure Vite to support it.
3) Add a minimal ESLint config that works for TS+React (keep it lightweight).
4) Create src/ and placeholder files needed to boot (main.tsx, App.tsx) but keep them minimal.
5) Do NOT add proxy config.

After changes:
- run typecheck/build locally (ensure config is coherent)
- update docs/IMPLEMENTATION_PLAN.md “Current status” to reflect what Phase 0 now has.
Return a brief summary of files changed.
```

* * *

T0-02 — Add core runtime dependencies (React Router, MUI, OpenLayers) + app bootstrap
-------------------------------------------------------------------------------------

**Goal:** Install and wire the runtime stack: **React Router**, **MUI**, **OpenLayers**. No real map logic yet beyond mounting.

**Scope**

*   Add deps: `react-router-dom`, `@mui/material`, `@emotion/react`, `@emotion/styled`, `ol`
*   Add MUI theme baseline in `src/app/App.tsx` or a provider module
*   Keep startup clean and minimal

**Acceptance**

*   App boots with MUI baseline (CssBaseline)
*   No unused complex state managers

**Codex prompt**

```md
Implement Phase 0 ticket T0-02.

Constraints from AGENTS.md:
- npm only
- no proxy
- frontend-first
- keep folder structure aligned with AGENTS.md

TASK:
1) Install runtime deps: react-router-dom, @mui/material, @emotion/react, @emotion/styled, ol.
2) Wire MUI at app root:
   - Add <CssBaseline />
   - Add a minimal theme (default is fine).
3) Keep App bootable; do not implement full router contract yet unless required for compilation.
4) Create src/app/ folder if missing and move bootstrap there to match AGENTS.md layout (main.tsx -> src/app/main.tsx etc.) OR keep current but align progressively (choose the least disruptive approach).

Update docs/IMPLEMENTATION_PLAN.md “Current status”.
```

* * *

T0-03 — Router contract + URL state helpers (tool in path, entity in query)
---------------------------------------------------------------------------

**Goal:** Implement the routing contract early and correctly.

**Scope**

*   `src/app/routes.tsx` using React Router v6+ `createBrowserRouter`
*   Redirect `/` → `/air`
*   `/:tool` renders `MapShell`
*   Create URL helpers:
    *   `parseTool`, `parseEntity`, `formatEntity`
    *   tools list matches AGENTS.md: air, geofences, sensors, known-drones, history

**Acceptance**

*   Visiting `/` navigates to `/air`
*   Visiting `/banana` coerces to `/air` tool (by parsing fallback)
*   `parseEntity("sensor:425006")` works

**Codex prompt**

```md
Implement Phase 0 ticket T0-03.

Follow AGENTS.md routing rules:
- tool in path: /:tool (air, geofences, sensors, known-drones, history)
- entity is query param: ?entity=kind:id
- tool changes push history; entity selection replaces history by default

TASK:
1) Add src/app/routes.tsx with createBrowserRouter:
   - "/" -> Navigate to "/air" replace
   - "/:tool" -> MapShell
2) Add src/layout/MapShell/urlState.ts:
   - TOOLS const, Tool type
   - EntityKind, EntityRef
   - parseTool, parseEntity, formatEntity
3) Add basic unit tests (Vitest) for parseTool/parseEntity/formatEntity in src/layout/MapShell/urlState.test.ts.

Do not add proxies.
Update docs/IMPLEMENTATION_PLAN.md “Current status”.
```

* * *

T0-04 — MapShell layout skeleton (persistent map + toolbar + sidebar)
---------------------------------------------------------------------

**Goal:** Build the app chrome: one persistent map instance area + navigation UI + sidebar.

**Scope**

*   `src/layout/MapShell/MapShell.tsx` renders:
    *   `TopToolbar`
    *   `LeftSidebar`
    *   persistent `MapView` component placeholder
*   `TopToolbar` includes tool navigation buttons (MUI)
*   `LeftSidebar` switches panels based on tool and entity selection
*   Create panel stubs (no logic yet): `AirTrafficPanel`, `SensorsPanel`, `GeofencesPanel`, `KnownDronesPanel`, `HistoryPanel`, `ObjectDetailsPanel`

**Acceptance**

*   Tool switching updates sidebar content
*   If `?entity=...` exists, sidebar shows Object Details placeholder instead of tool panel

**Codex prompt**

```md
Implement Phase 0 ticket T0-04.

Follow AGENTS.md boundaries:
- Panels in src/features/* must NOT import OpenLayers.
- MapShell hosts persistent map + chrome + sidebar.

TASK:
1) Create MapShell layout using MUI (Box/Grid):
   - left sidebar fixed width (e.g., 360px)
   - map takes remaining space
   - top toolbar with tool nav
2) Implement src/layout/MapShell/useSidebarUrlState.ts using useParams + useSearchParams:
   - reads tool from path
   - reads entity/hDate/hArea from query
   - setTool() pushes navigation
   - selectEntity() replaces history by default
3) Implement LeftSidebar logic:
   - if entity exists -> ObjectDetailsPanel
   - else switch(tool) -> tool panel
4) Add panel stub components under src/features/* with simple headings.

No map logic here besides mounting <MapView /> placeholder.
Update docs/IMPLEMENTATION_PLAN.md “Current status”.
```

* * *

T0-05 — OpenLayers MapView “hello world” (EPSG:3857 view, transform boundary helpers)
-------------------------------------------------------------------------------------

**Goal:** Create a single OpenLayers map instance that mounts and stays alive while tools switch.

**Scope**

*   `src/map/MapView.tsx` owns OL `Map` instance
*   `View` set to EPSG:3857
*   Create `src/map/transforms.ts` helper functions for 4326↔3857
*   Base layer: **placeholder** (e.g., OSM) until Maa-amet WMTS config is known; still create `maaAmetOrthoWmts.ts` stub with TODOs

**Acceptance**

*   Map renders and doesn’t re-create on tool switch
*   No OpenLayers imports in feature panels

**Codex prompt**

```md
Implement Phase 0 ticket T0-05.

Constraints:
- Domain geometry in EPSG:4326 lon/lat; map view EPSG:3857
- MapView owns the OpenLayers Map instance
- No OpenLayers in src/features/*
- Maa-amet WMTS config must live in src/map/layers/maaAmetOrthoWmts.ts, but exact details are TODO (do not guess)

TASK:
1) Create src/map/MapView.tsx:
   - create a ref div
   - create OL Map once (useEffect + ref guard)
   - set View to EPSG:3857 and a reasonable initial center/zoom (can transform Estonia-ish lon/lat)
2) Create src/map/transforms.ts with helpers:
   - to3857([lon,lat]) and to4326([x,y]) using ol/proj
3) Create src/map/layers/maaAmetOrthoWmts.ts stub:
   - exports a function createMaaAmetOrthoLayer(envUrl?: string) returning null or a TileLayer placeholder
   - include explicit TODOs: layer name, matrixSet, attribution, tileGrid
   - do NOT hallucinate WMTS parameters
4) For now, use an OSM base layer (ol/source/OSM) if WMTS is not configured, so the map is visible.

Update docs/IMPLEMENTATION_PLAN.md “Current status”.
```

* * *

T0-06 — Minimal testing harness (Vitest + RTL + MSW + Playwright smoke)
-----------------------------------------------------------------------

**Goal:** Set up tests early so Phase 0 has guardrails.

**Scope**

*   Vitest + RTL setup (jsdom)
*   MSW setup skeleton (handlers/server for Vitest)
*   Playwright configured with a smoke test:
    *   loads app
    *   switches tools
    *   verifies sidebar changes

**Acceptance**

*   `npm run test` passes (at least a couple tests)
*   `npm run test:e2e` passes locally

**Codex prompt**

```md
Implement Phase 0 ticket T0-06.

Constraints:
- Keep tests focused: unit test pure logic, E2E for map+navigation.
- No proxies.

TASK:
1) Configure Vitest for React:
   - jsdom environment
   - setupTests.ts for RTL (cleanup) if needed
2) Add React Testing Library + @testing-library/jest-dom and a basic render test for MapShell routing.
3) Add MSW skeleton:
   - src/mocks/handlers.ts
   - src/mocks/server.ts for Vitest
   - wire MSW into test setup (listen/reset/close)
4) Configure Playwright:
   - create playwright config
   - add e2e smoke test:
     - goto /air
     - verify a sidebar header text
     - click toolbar buttons to switch to sensors/geofences/history and verify content changes

Update docs/IMPLEMENTATION_PLAN.md “Current status”.
```

* * *

T0-07 — docs/ARCHITECTURE.md (one-pager) + align Phase 0 status
---------------------------------------------------------------

**Goal:** Document the architecture (MapShell + routing + boundaries) so future agents don’t improvise.

**Scope**

*   Create `docs/ARCHITECTURE.md` (short and practical)
*   Include:
    *   MapShell layout diagram (text)
    *   routing + URL-state contract
    *   map boundary + data boundary
    *   where OpenLayers lives
    *   how to add a new tool panel

**Acceptance**

*   Doc exists and matches current code
*   `docs/IMPLEMENTATION_PLAN.md` “Current status” reflects Phase 0 completion/in-progress

**Codex prompt**

```md
Implement Phase 0 ticket T0-07.

TASK:
1) Create docs/ARCHITECTURE.md as a 1-page practical overview:
   - MapShell layout: persistent map + sidebar + toolbar
   - routing contract: /:tool and ?entity=
   - boundaries: OpenLayers only in src/map, panels only in src/features
   - where to add new layers, panels, clients
2) Update docs/IMPLEMENTATION_PLAN.md “Current status” to accurately reflect Phase 0 state after Phase 0 tickets.

Do not add any code beyond docs unless absolutely necessary for correctness.
```

* * *

### Suggested execution order (keeps PRs sane)

1.  T0-01 (scaffold/config)
2.  T0-02 (deps + bootstrap)
3.  T0-03 (router + url helpers + unit tests)
4.  T0-04 (MapShell + panels)
5.  T0-05 (MapView OL)
6.  T0-06 (test harness + e2e smoke)
7.  T0-07 (architecture doc)

If you want, I can also format these as **GitHub Issues JSON** (title/body/labels) or a `docs/TICKETS_PHASE0.md` that you can drop into the repo.

## Prompt:
Figure out how to implement drone flight mocking. (we will need this now but also later to simulate a drone swarm etc).

take into account the best standard solutions or the closest available for logging counter drone sensors.

FOR THIS PURPOSE, YOUR GOAL IS: research logical ways how we would store all this data in db later (there must be some standard solutions for such drone tracking)

some keywords:
GeoJSON LineString

GeoJSON is standardized (RFC 7946) and uses WGS-84 lon/lat, which matches your domain rule. 
IETF Datatracker

OpenLayers already has a GPX parser/format module, which makes GPX a practical “log import” format for demos. 
OpenLayers

MAVLink - used for telemetry but not sure about the sensor log part. we will store radar based noisy (cleaned) track later. 
initially we WILL mock a dji aeroscope (telemetry with position, heading, altitude etc) but different sensors will store different kind of data (does this give a hint how we should handle it?)

--

implementing a scenario engine - can replay same scenario

BASED on this structure, suggest how we would handle it in a file right now

2/2

## Response:
Thought for 1m 50s

Here’s a solid way to design **drone flight mocking now** (files + replay) that also maps cleanly to a **future DB** for real counter-UAS sensor logs.

1) Treat everything as a time-stamped event stream (now and forever)
--------------------------------------------------------------------

Counter-UAS sensors are heterogeneous: an AeroScope-like feed gives “rich telemetry”, a radar gives “noisy track updates”, an RF sensor may only give “bearing + confidence”. That screams for an **event log** approach:

*   **Truth** (what the drone actually did in the scenario)
*   **Observations** (what each sensor reported, which can be partial/noisy)
*   **Tracks** (optional fusion product later)

This matches how you’ll actually store it later: immutable events + derived “current state”.

Key constraints already match standard geospatial practice:

*   Geometry in **WGS-84 lon/lat** (GeoJSON requires WGS-84) [IETF Datatracker](https://datatracker.ietf.org/doc/html/rfc7946?utm_source=chatgpt.com)
*   Time in **UTC** (you already decided that; good, because most standards assume that too)

2) Best “standard-ish” representations you can lean on
------------------------------------------------------

### A) GeoJSON for geometry interchange (baseline)

GeoJSON is standardized by RFC 7946 and is explicitly WGS-84 lon/lat. [IETF Datatracker+1](https://datatracker.ietf.org/doc/html/rfc7946?utm_source=chatgpt.com)  
Great for: points, polygons, geofences, “current positions”.

Limitation: GeoJSON doesn’t standardize time-series trajectories by itself (you can put timestamps in properties, but that’s a convention).

### B) OGC MF-JSON for trajectories (best match to your need)

The **OGC Moving Features JSON encoding (MF-JSON)** is basically “GeoJSON + time”, designed to represent moving points/trajectories and dynamic properties over time, and it explicitly builds on GeoJSON and uses WGS-84 + UTC. [OGC Dokumentide Repositoorium+1](https://docs.ogc.org/is/19-045r3/19-045r3.html?utm_source=chatgpt.com)  
Great for: scenario truth trajectories, replay, swarm definitions.

### C) GPX as a practical demo/import format (optional)

OpenLayers has a GPX parser/formatter; it maps LineStrings to routes and MultiLineStrings to tracks, so it’s handy for “bring your own demo track” workflows. [OpenLayers+1](https://openlayers.org/en/latest/apidoc/module-ol_format_GPX-GPX.html?utm_source=chatgpt.com)  
Great for: “import a track from a file” demos.  
Not great for: sensor observations, multi-entity, rich metadata.

### D) OGC SensorThings API model for sensor logging (DB inspiration)

SensorThings API (OGC standard) is a clean way to model heterogeneous sensors + observations (Thing/Sensor/Datastream/Observation/FeatureOfInterest). [OGC API+1](https://ogcapi.ogc.org/sensorthings/overview.html?utm_source=chatgpt.com)  
You don’t need to implement the API now, but copying the **data model thinking** will save you later.

3) Future DB storage: two good patterns (pick one)
--------------------------------------------------

### Option 1 — Postgres + PostGIS + time-series table (most common)

*   Store every observation as a row: `(time, sensor_id, target_id?, geometry(Point,4326), altitude_m, …)`
*   PostGIS supports extra dimensions (Z for height and M for “measure”, often time). [PostGIS+1](https://postgis.net/workshops/postgis-intro/3d.html?utm_source=chatgpt.com)
*   Use standard indexes:
    *   `btree(time)`
    *   `gist(geom)`
    *   optionally `(sensor_id, time)` composite

Add TimescaleDB if ingestion/query volume is large (hypertables, compression, time-series optimizations). [GitHub+1](https://github.com/timescale/timescaledb?utm_source=chatgpt.com)

### Option 2 — MobilityDB for trajectories (trajectory-native)

MobilityDB extends Postgres/PostGIS with temporal trajectory types like `tgeompoint/tgeogpoint` and functions for speed/direction/relationships over time. [MobilityDB+1](https://mobilitydb.com/?utm_source=chatgpt.com)  
Great if you expect heavy “trajectory analytics” (intersections, closest approach, time-window queries). Otherwise, Option 1 is simpler.

**My practical recommendation:** start with Option 1 (PostGIS + time-series table). If trajectory analytics becomes painful, add MobilityDB later for the “track product” tables.

4) Minimal logical DB schema (designed for real sensors later)
--------------------------------------------------------------

Think in three layers:

### A) Metadata

*   `sensors(sensor_id, name, kind, position_geom, status, config_jsonb, …)`
*   `entities(entity_id, kind(drone/aircraft/unknown), label, external_ids_jsonb, …)`

### B) Raw observations (sensor-native, append-only)

*   `observations(obs_id, sensor_id, entity_id nullable, event_time_utc, ingest_time_utc,`  
    `obs_kind, geom_point_4326 nullable, altitude jsonb, velocity jsonb, confidence, raw jsonb)`
*   This table tolerates partial data and preserves sensor-specific fields in `raw`.

This aligns well with SensorThings-style thinking (Observation is central; sensor metadata is separate). [OGC API+1](https://ogcapi.ogc.org/sensorthings/overview.html?utm_source=chatgpt.com)

### C) Tracks (fusion product, can arrive later)

*   `tracks(track_id, classification, first_seen_utc, last_seen_utc, status, …)`
*   `track_points(track_id, event_time_utc, geom_point_4326, altitude jsonb, speed_mps, heading_deg, covariance_jsonb, source)`  
    This is where you keep “cleaned tracks” from radar fusion.

5) How to mock flights now: a scenario engine with “truth + sensor outputs”
---------------------------------------------------------------------------

### Core idea

Store **truth trajectories** in a compact trajectory format, then generate **sensor observations** deterministically from that truth (with optional noise, dropouts, ID changes).

This gives you:

*   Repeatable replays (“scenario engine”)
*   Easy swarms (N entities each with a trajectory)
*   Easy “sensor personality” (AeroScope is rich; radar is noisy; RF-only is bearing-only)

### Suggested file layout (now)

```
public/mock/scenarios/
  linear-1/
    scenario.json
    truth.mfjson           // MF-JSON moving point(s)
    sensors.json           // sensor placement + type + params
    observations.ndjson    // optional precomputed events (nice for debugging)
```

MF-JSON is a great canonical truth format for moving objects. [OGC Dokumentide Repositoorium+1](https://docs.ogc.org/is/19-045r3/19-045r3.html?utm_source=chatgpt.com)

### scenario.json (proposed)

Keep this small and deterministic:

```json
{
  "version": "0.1",
  "scenarioId": "linear-1",
  "t0Utc": "2025-12-18T10:00:00Z",
  "durationSec": 600,
  "playback": { "speed": 1, "loop": true },
  "truth": { "format": "mfjson", "path": "./truth.mfjson" },
  "sensors": { "path": "./sensors.json" },
  "streams": [
    {
      "streamId": "aeroscope-demo",
      "kind": "telemetry",
      "sourceSensorKind": "aeroscope",
      "emitHz": 1,
      "model": { "noiseMeters": 2, "dropoutPct": 0.0 }
    },
    {
      "streamId": "radar-demo",
      "kind": "trackUpdate",
      "sourceSensorKind": "radar",
      "emitHz": 1,
      "model": { "noiseMeters": 25, "idSwapPct": 0.02, "covariance": "simple" }
    }
  ]
}
```

### truth.mfjson (concept)

You can encode each drone as a moving feature with time-varying geometry/properties (MF-JSON is meant for this). [OGC Dokumentide Repositoorium+1](https://docs.ogc.org/is/19-045r3/19-045r3.html?utm_source=chatgpt.com)  
Even if you don’t fully comply on day 1, using the MF-JSON “shape” keeps you on rails.

### observations.ndjson (optional but very useful)

An **append-only event log** format is ideal for replay/debug. NDJSON is simple: one JSON object per line:

```json
{"eventTimeUtc":"2025-12-18T10:00:01Z","ingestTimeUtc":"2025-12-18T10:00:01Z","sensorId":"sensor-425006","kind":"telemetry","entityId":"drone-001","position":{"lon":24.75,"lat":59.43},"headingDeg":90,"speedMps":12.4,"altitude":{"meters":86,"ref":"AGL","source":"reported","comment":"AeroScope mock"}}
```

When you move to DB later, this maps 1:1 into `observations`.

6) Sensor-specific mocking: how to keep it realistic without over-engineering
-----------------------------------------------------------------------------

### AeroScope-like telemetry (rich)

Mock it as “telemetry events” with:

*   drone ID (or session ID), drone location/altitude, velocity, time mark  
    This lines up with the general Remote ID field sets described in practice (ID, location/altitude, velocity, time mark, etc.). [Skybrary+1](https://skybrary.aero/articles/uas-remote-identification?utm_source=chatgpt.com)  
    (Real AeroScope is proprietary; we’re borrowing the _shape_ of telemetry.)

### Radar track updates (noisy + sometimes wrong)

Emit `trackUpdate` events:

*   position (noisy), heading (derived), speed (derived), plus a simple covariance blob
*   sometimes “track id changes” to simulate association issues

### RF-only / direction-finding

Emit `bearing` events:

*   `bearingDeg`, `confidence`, maybe `band` / `protocolHint`  
    No location point required.

This is why the raw `observations` table should allow partial data and stash sensor-specific extras in `raw`.

7) Implementation sketch for the frontend scenario engine
---------------------------------------------------------

**Modules (keep pure logic testable):**

*   `ScenarioLoader` → loads scenario + truth + sensors
*   `SimClock` → `nowSimUtc()` with pause/seek/loop
*   `TrajectorySampler` → `sample(entityId, t)` with linear interpolation
*   `SensorModel` → transforms truth sample into observation event (noise/dropouts)
*   `ScenarioPlayer` → emits events at configured Hz into your mock “API” endpoint

This will scale to a swarm trivially: N entities, same sampler, same emission loop.

8) What I’d use _right now_ for your Phase 1 “one drone + one airplane”
-----------------------------------------------------------------------

*   Store:
    *   `truth.mfjson` with 2 moving features (drone + aircraft)
    *   One `scenario.json`
*   Generate telemetry at runtime at 1 Hz and aircraft at 0.1 Hz (or just 1 Hz too)
*   Keep the UI’s mock “API” simply reading from the scenario player (no network required), and later swap to fetching `/mock/*.json` or real URLs.

If you want this to be extra easy to demo/import, also allow `truth.gpx` as an optional input path because OpenLayers already handles it well. [OpenLayers+1](https://openlayers.org/en/latest/apidoc/module-ol_format_GPX-GPX.html?utm_source=chatgpt.com)

* * *

If you want the next concrete step, I’d write a short `docs/SCENARIO_FORMAT.md` and a `public/mock/scenarios/linear-1/` example with **truth.mfjson + scenario.json + sensors.json + observations.ndjson**, then you can build the Phase 1 “moving marker” entirely by sampling that truth.

## Prompt:
based on option 1:

write an md file that explains our db plans and describes our mock data files in detail!
(all the logic you unveiled + the best way how we will handle it in the files)

## Response:
Thought for 9s

Failed to generate

Created **docs/DB\_PLAN\_AND\_MOCK\_DATA.md** in the canvas.

It covers:

*   Option 1 DB plan (Postgres + PostGIS, time-series observations, tracks, geofences)
*   Event-stream model (truth vs observations vs derived tracks)
*   Exactly how mock files should be structured now (static JSON + scenario folder with truth + NDJSON replay)
*   Clear mapping from mock artifacts → future DB tables

## Prompt:
now write an ai prompt to generate files with mock data. think and research all you need

## Response:
Thought for 1m 34s

GeoJSON is a good baseline because it’s standardized and **requires WGS-84 lon/lat** [IETF Datatracker](https://datatracker.ietf.org/doc/html/rfc7946?utm_source=chatgpt.com), and for “moving objects over time” the closest standard-shaped thing is **OGC MF-JSON Trajectory** (GeoJSON FeatureCollection with `properties.datetimes`) [OGC Dokumentide Repositoorium+1](https://docs.ogc.org/is/19-045r3/19-045r3.html?utm_source=chatgpt.com). For later “real sensor logging”, the **SensorThings** data model is a useful mental template (Sensors → Datastreams → Observations) [OGC IoT](https://ogc-iot.github.io/ogc-iot-api/datamodel.html?utm_source=chatgpt.com). Also: OpenLayers can import GPX tracks directly, so a GPX demo export is handy for demos/tests. [OpenLayers+1](https://openlayers.org/en/latest/apidoc/module-ol_format_GPX-GPX.html?utm_source=chatgpt.com)

Here’s an **AI/Codex prompt** that will generate the mock files (and a generator script so we can regenerate swarms later):

```md
You are an implementation agent in a frontend-first repo. Follow AGENTS.md + docs/DB_PLAN_AND_MOCK_DATA.md strictly:
- NO PROXY. Everything is local files under public/mock for now.
- Domain geometry is WGS-84 [lon,lat].
- UTC everywhere in domain/storage logic.
- Units: drones speed m/s; aircraft speed km/h; altitude stored in meters with Altitude type; altitude.comment must always be present.

GOAL
Create deterministic mock data files for Phase 1 and for future scenario replay (swarm-ready).
You must:
1) Add a small generator script (no new runtime deps; prefer node:fs + TypeScript).
2) Commit the generated outputs to the repo so the UI can run without executing the generator.
3) Keep data small but realistic around Tallinn so the map view shows it immediately.

OUTPUT FILES (must exist after this change)
A) Snapshot mocks (Mode A):
- public/mock/sensors.json
- public/mock/drones.json
- public/mock/adsb.json
- public/mock/notams.sample.json

B) Scenario mocks (Mode B):
- public/mock/scenarios/linear-1/scenario.json
- public/mock/scenarios/linear-1/truth.mfjson        (MF-JSON Trajectory style)
- public/mock/scenarios/linear-1/sensors.json
- public/mock/scenarios/linear-1/observations.ndjson (precomputed event log)
- OPTIONAL: public/mock/scenarios/linear-1/truth.gpx  (single drone track for demo import)

C) Generator script:
- scripts/generate-mocks.ts (or .js) that generates ALL the above deterministically from a fixed seed.
- Add npm script "gen:mocks" (dev-only) if appropriate.

DATA REQUIREMENTS

1) Coordinates and map visibility
- Center everything near Tallinn: lon ~ 24.74–24.90, lat ~ 59.38–59.47.
- Ensure at least one sensor and one drone are clearly visible at initial zoom.
- Keep GeoJSON coordinate order [lon,lat]. (No lat/lon inversion.)

2) Sensors (public/mock/sensors.json and scenario sensors.json)
Create at least 3 sensors:
- sensor-425006: kind "aeroscope", near Tallinn center, status "online"
- sensor-radar-1: kind "radar", offset a few km, status "online"
- sensor-rfdf-1: kind "rf_df", optional, status "degraded" or "online"
Include:
- id, name, kind, position {lon,lat}, status, lastSeenUtc
- coverage object (radiusMeters, minAltM, maxAltM) when sensible
- Scenario sensors.json can include config fields in "config" for rangeMeters etc.

3) Drone snapshot (public/mock/drones.json)
Provide at least 1 drone telemetry item:
- id "drone-001", label
- position {lon,lat}
- headingDeg, speedMps
- altitude as Altitude type with meters/ref/source/comment
- eventTimeUtc (ISO Z)

4) ADS-B snapshot (public/mock/adsb.json)
Provide at least 1 aircraft track:
- id "4ca123" (or similar), callsign "FIN123"
- position {lon,lat}
- trackDeg, groundSpeedKmh
- altitude Altitude (meters, ref MSL, source reported, comment)
- eventTimeUtc (ISO Z)

5) NOTAM sample (public/mock/notams.sample.json)
Create a small notam feed object:
- generatedAtUtc
- items[] with at least 2 NOTAMs
Each item must include:
- id (e.g. "A1234/25")
- text that includes altitude in FT (e.g. "SFC TO 3000FT AMSL") so interpreter can later parse
- validFromUtc, validToUtc
OPTIONAL but recommended for easy demo overlays:
- geometryHint field (non-standard) with either:
  a) circle: {type:"circle", center:{lon,lat}, radiusMeters:number}
  b) polygon: {type:"polygon", coordinates:[[lon,lat],...]} (closed ring)
Keep it backwards-compatible: id/text/validFrom/validTo always present.

6) Scenario: linear-1 (replayable)
scenario.json:
- version "0.1"
- scenarioId "linear-1"
- t0Utc a fixed time (e.g. 2025-12-18T10:00:00Z)
- durationSec 120
- playback {speed:1, loop:true}
- truth {format:"mfjson", path:"./truth.mfjson"}
- sensors {path:"./sensors.json"}
- streams describing at least:
  - aeroscope telemetry at 1 Hz
  - radar track_update at 1 Hz (can be noisier)
You do not need to implement the scenario engine here; just provide correct data.

truth.mfjson (MF-JSON Trajectory style):
- FeatureCollection with at least two Features:
  - id "drone-001" (entityKind drone)
  - id "flight-001" or "4ca123" (entityKind aircraft)
- Each Feature:
  - geometry: LineString with AT LEAST 3 coordinate points (small path segment across Tallinn)
  - properties.datetimes: array of RFC3339 UTC timestamps aligned with coordinates
  - include at least one temporal property array like altitudeM or state:
    - For step interpolation: length = datetimes.length - 1
- Keep it minimal but valid and consistent.

observations.ndjson (precomputed log):
- One JSON object per line, ascending by eventTimeUtc.
- Include both eventTimeUtc and ingestTimeUtc.
- Use obsKind (strings): "telemetry" and "track_update".
- For aeroscope telemetry (1 Hz for 120s):
  - sensorId sensor-425006
  - entityId drone-001
  - position interpolated along drone path
  - velocity {speedMps, headingDeg}
  - altitude Altitude (AGL, reported, comment present)
- For radar track updates (1 Hz for 120s):
  - sensorId sensor-radar-1
  - trackId "track-001" (radar track id), entityId optional (can be null)
  - position is drone-ish but add small deterministic noise (e.g. ±15m) based on seeded RNG
  - altitude can be unknown or detected; comment required if altitude present
  - include confidence (0..1) and raw payload stub
- For aircraft, you may include fewer points (e.g. 0.2 Hz or 1 Hz) but keep at least some track_update events.

OPTIONAL truth.gpx:
- GPX with a single <trk> for drone-001 with timestamps for the same 120s.
- Lat/lon attributes must be correct (lat attr is latitude, lon attr is longitude).

GENERATOR SCRIPT REQUIREMENTS
- Deterministic seed (e.g. 1337) so files are stable in git.
- One place to change scenario count, duration, number of drones later (swarm).
- Writes files to the exact paths above.
- Avoid adding new dependencies; implement a tiny seeded RNG yourself.
- Ensure output JSON is pretty-printed (2 spaces) and NDJSON has \n line endings.

FINAL CHECKS
- Validate JSON parses.
- Ensure all required fields exist.
- Ensure altitude.comment exists wherever altitude exists.
- Keep file sizes small (< ~200KB total is fine).

After generating, update docs/DATA_SOURCES.md with a short note that scenario assets exist under public/mock/scenarios/linear-1 and describe how they relate to the snapshot mocks.
Return a summary of generated files and key values (center coords, ids, time range).
```

If you want, I can tailor that prompt to a specific repo layout (e.g., whether you already have `scripts/` and whether you prefer pure `.js` vs `.ts`).

## Prompt:
ok

3/3

## Response:
👍 All set.

I’ve aligned the mock-data generation prompt with your **DB plan (Option 1)**, the **scenario engine idea**, and the current **AGENTS.md** constraints (no proxy, WGS-84, UTC, altitude semantics, etc.). You can now hand that prompt directly to an AI agent (or Codex) and expect:

*   Deterministic, replayable mock data
*   Files that already map 1:1 to your future **Postgres + PostGIS observation tables**
*   A clean path from **Phase 1 demo (one drone, one aircraft)** → **later swarm + sensor fusion**

### What you can do next (recommended order)

1.  **Run the prompt once** to generate:
    *   snapshot mocks (`public/mock/*.json`)
    *   scenario mocks (`public/mock/scenarios/linear-1/*`)
2.  Wire Phase 1 UI to **either**:
    *   snapshot mocks (fastest), or
    *   the scenario replay output (`observations.ndjson`)
3.  After that, the next logical doc would be:
    *   `docs/SCENARIO_FORMAT.md` (short, stable contract for truth + replay)

If you want, next I can:

*   Convert that prompt into **a GitHub Issue template**
*   Write **the actual generator script** (`generate-mocks.ts`)
*   Or design the **ScenarioPlayer API** the frontend will consume (clean separation between “truth”, “sensor model”, and “UI feed”)

You’re in a very strong architectural position now—this will scale without rewrites.

## Prompt:
write codex prompts for phase 2

2/2

## Response:
Thought for 26s

Below are **Phase 2 Codex prompts** (ticket-style) aligned with your current docs:

*   `AGENTS.md` (NO PROXY, OpenLayers boundary, URL contract, UTC/units)
*   `docs/UI_RULES.md`
*   `docs/DATA_SOURCES.md`
*   `docs/IMPLEMENTATION_PLAN.md` (mandatory “Current status” updates)

Phase 2 scope: **Geofences + sensor add/remove + mock persistence** (no backend).

* * *

P2-01 — Create local persistence layer (in-memory + localStorage adapter)
-------------------------------------------------------------------------

**Goal:** Provide a tiny persistence mechanism for user-created geofences and sensors (prototype-only), with versioning and safe fallbacks.

**Acceptance**

*   Geofences/sensors created in UI survive refresh (localStorage).
*   If storage is empty/corrupt, app still loads with defaults (from mocks).
*   No backend introduced.

**Codex prompt**

```md
Implement Phase 2 ticket P2-01.

Hard constraints from AGENTS.md:
- NO PROXY
- npm only
- UTC in domain logic
- WGS-84 lon/lat for stored geometry
- Do not add OpenLayers imports into src/features/*

TASK:
1) Create a small persistence adapter under src/services/persistence/:
   - storage schema versioning (e.g. {version:1, geofences:[], sensors:[]})
   - load() returns defaults if missing/corrupt
   - save() is debounced or called explicitly on writes (keep it simple)
   - localStorage key names: "cuas.geofences.v1" and "cuas.sensors.v1" (or a combined key "cuas.state.v1")
2) Make the persistence API pure and testable (no React inside).
3) Add unit tests for:
   - load from empty storage
   - load from corrupt JSON
   - save then load round-trip
4) Update docs/DATA_SOURCES.md: mention local persistence for user-created sensors/geofences in Phase 2.
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Return a summary of files changed.
```

* * *

P2-02 — Define Geofence domain model + geometry helpers (circle → polygon)
--------------------------------------------------------------------------

**Goal:** Introduce a geofence type that fits DB Plan Option 1 and supports “circle at minimum”, storing in WGS-84 and rendering-friendly.

**Acceptance**

*   A circle geofence is stored as center+radius and can be converted to a polygon ring for map rendering.
*   Geo computations are pure functions with unit tests.
*   No OpenLayers dependency in the helpers.

**Codex prompt**

```md
Implement Phase 2 ticket P2-02.

Constraints:
- Geofence geometry stored in WGS-84 [lon,lat]
- Map rendering uses EPSG:3857 but transforms at OpenLayers boundary only
- No OpenLayers in src/features/*
- Keep helpers in src/shared/ or src/services/ as pure logic

TASK:
1) Add domain types in src/shared/types/domain.ts (or a dedicated file):
   - type GeofenceKind = "circle" | "polygon" | "notam_area"
   - type Geofence = { id, name, kind, source, validFromUtc?, validToUtc?, center?, radiusMeters?, polygon?: GeoJSON Polygon, meta? }
   - Ensure this matches docs/DB_PLAN_AND_MOCK_DATA.md intent (center/radius + polygon).
2) Implement pure helper functions in src/shared/geo/ (create this folder):
   - circleToPolygonWgs84(centerLonLat, radiusMeters, segments=64) -> GeoJSON Polygon
   - validateLonLat(), clamp, etc. (minimal)
   - haversine-based approximate conversion from meters to degrees (good enough for prototype)
3) Write unit tests for:
   - circleToPolygon returns closed ring
   - ring has expected number of points
   - center approximately preserved
4) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Do NOT implement map rendering yet; only domain + helpers.
```

* * *

P2-03 — Geofence store + CRUD actions (in-memory + persisted)
-------------------------------------------------------------

**Goal:** Build a small geofence state store that merges defaults (none for now) + user-created items, persists via P2-01 adapter, and exposes CRUD methods.

**Acceptance**

*   Can create, rename, delete geofences via store API.
*   Persists changes.
*   Clean separation between store logic and UI components.

**Codex prompt**

```md
Implement Phase 2 ticket P2-03.

Constraints:
- Keep state management lightweight (no Redux/MobX).
- Persist via the adapter from P2-01.
- Geofences stored in WGS-84, circle->polygon derived via helpers from P2-02.

TASK:
1) Create src/services/geofences/geofenceStore.ts:
   - getAll(), getById(id)
   - createCircle({name, center, radiusMeters}) -> Geofence
   - rename(id, name)
   - remove(id)
   - optional: upsert(geofence)
2) Ensure created circle geofence stores:
   - center + radiusMeters
   - polygon computed and stored (for rendering) OR computed on demand (pick one and document).
3) Ensure every write saves to localStorage via P2-01.
4) Add unit tests for store operations and persistence integration using a mocked storage adapter.
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

No UI yet.
```

* * *

P2-04 — Render geofences on the map (vector layer + styles) with a strict map boundary
--------------------------------------------------------------------------------------

**Goal:** Add a geofence vector overlay layer in `src/map/` that can be updated from MapShell, without panels importing OpenLayers.

**Acceptance**

*   Geofences appear as outlines on the map.
*   Geofence layer toggling is possible via `mapApi.setLayerVisibility("geofences", ...)`.
*   No OpenLayers imports in `src/features/*`.

**Codex prompt**

```md
Implement Phase 2 ticket P2-04.

Constraints:
- OpenLayers code only inside src/map/*
- Stored geofence polygon is WGS-84; transform at OL feature creation
- MapView owns the map instance
- Use mapApi as the boundary for UI->map commands

TASK:
1) Add a geofence vector layer in src/map/layers/vectors.ts (or equivalent):
   - createGeofenceLayer()
   - style: simple stroke + optional label (name), avoid heavy styling
2) Add a mapApi method:
   - mapApi.setGeofences(geofences: Geofence[])
   - mapApi.setLayerVisibility(key, visible)
3) In MapView:
   - create the geofence layer once
   - on setGeofences, clear and re-add features
   - transform polygon coordinates from EPSG:4326 to EPSG:3857 at feature creation boundary
4) Add a minimal integration test strategy:
   - Do NOT unit test OpenLayers internals.
   - Add a Playwright smoke that creates a geofence via UI later (P2-05) and verifies URL / sidebar state; map pixel-perfect assertions are not required.
5) Update docs/ARCHITECTURE.md if needed and update docs/IMPLEMENTATION_PLAN.md -> Current status.

No UI creation here; only map rendering support + API.
```

* * *

P2-05 — GeofencesPanel UI: create circle + list + rename/delete + URL selection
-------------------------------------------------------------------------------

**Goal:** Build the actual UI that lets a user create and manage geofences.

**Minimum UX (circle creation)**

*   Form-based creation is acceptable: name, lon, lat, radiusMeters.
*   Bonus (optional): “Pick center from map” button using mapApi (but only if easy without breaking boundaries).

**Acceptance**

*   Create circle geofence → appears in list + map overlay.
*   Rename + delete works.
*   Clicking geofence in list sets `?entity=geofence:<id>` and shows ObjectDetailsPanel.

**Codex prompt**

```md
Implement Phase 2 ticket P2-05.

Constraints:
- Panels in src/features/* must NOT import OpenLayers.
- Use GeofenceStore from P2-03 and mapApi from P2-04.
- Respect URL contract: entity selection stored in ?entity=kind:id with replace by default.

TASK:
1) Implement src/features/geofences/GeofencesPanel.tsx:
   - list geofences
   - create circle form: name, lon, lat, radiusMeters
   - actions: rename, delete
2) On create/update/delete:
   - update store
   - call mapApi.setGeofences(store.getAll())
3) On list item click:
   - set entity selection via useSidebarUrlState().selectEntity({kind:"geofence", id})
4) Add ObjectDetailsPanel support for geofence entity:
   - show name, kind, center, radius, validity fields if any
5) Add component tests (RTL):
   - creating a geofence adds it to the list
   - delete removes it
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Keep UI simple; do not add polygon drawing yet.
```

* * *

P2-06 — Sensors: add/remove (user-defined) + merge with mocked sensors + map update
-----------------------------------------------------------------------------------

**Goal:** Let the user add a sensor in the UI and see it on the map, without breaking the “data sources” flow.

**Key design choice**

*   Keep “base sensors” coming from mocks/endpoint.
*   Maintain “user sensors” separately (persisted).
*   UI shows both; user can delete only user sensors (or allow deleting all but mark base sensors read-only).

**Acceptance**

*   Add sensor → appears on map and in Sensors panel.
*   Persists across refresh.
*   Doesn’t break mock sensor loading.

**Codex prompt**

```md
Implement Phase 2 ticket P2-06.

Constraints:
- NO PROXY
- WGS-84 storage
- Sensors UI must not import OpenLayers
- Persist user-added sensors via P2-01 adapter

TASK:
1) Create src/services/sensors/sensorStore.ts:
   - holds user-defined sensors (persisted)
   - exposes CRUD
2) In sensor client layer (existing or create):
   - load base sensors from /mock/sensors.json (or VITE_SENSORS_URL if live later)
   - merge baseSensors + userSensors for UI and map rendering
   - mark each sensor with a source: "base" | "user" in the view model
3) Update SensorsPanel UI:
   - list sensors with a chip: base/user
   - add sensor form: name, kind, lon, lat
   - allow delete for user sensors only
4) Update map sensor layer (if it exists already):
   - call mapApi.setSensors(mergedSensors) (add if missing)
5) Add RTL tests for add/delete user sensor.
6) Update docs/DATA_SOURCES.md: document base vs user sensor sources.
7) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Do not add backend calls or proxy.
```

* * *

P2-07 — Phase 2 E2E: “Editable world” smoke test
------------------------------------------------

**Goal:** A Playwright test that proves the Phase 2 user flow works end-to-end.

**Acceptance**

*   Test passes consistently.
*   Does not assert pixel-perfect map rendering (only UI state/URL changes).

**Codex prompt**

```md
Implement Phase 2 ticket P2-07.

TASK:
1) Add a Playwright test: "Phase 2 editable world smoke"
   Steps:
   - open /geofences
   - create a circle geofence (form)
   - verify it appears in list
   - click it -> URL has ?entity=geofence:<id>
   - close details -> list returns
   - open /sensors
   - add a user sensor
   - verify it appears in list
2) Keep assertions robust:
   - assert text presence, URL params, and list counts
   - avoid asserting exact map visuals

Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

### Suggested Phase 2 execution order

1.  P2-01 (persistence)
2.  P2-02 (geofence domain + geo helpers)
3.  P2-03 (geofence store)
4.  P2-04 (map geofence layer + mapApi)
5.  P2-05 (GeofencesPanel UI)
6.  P2-06 (Sensors CRUD + merge)
7.  P2-07 (Playwright smoke)

If you want, I can rewrite these as **GitHub Issues** (title/body/labels + acceptance criteria) or bundle them into `docs/TICKETS_PHASE2.md`.

## Prompt:
write codex prompts for phase 3

## Response:
Thought for 26s

Below are **Phase 3 Codex prompts** (ticket-style) that match your Phase 3 scope:

> Phase 3 = **NOTAM ingest + overlays + “geofence from NOTAM”** (best-effort, frontend-only), with **NO PROXY**, mock fallback, and strict units/time rules.

* * *

P3-01 — NOTAM client + polling integration (browser fetch with mock fallback)
-----------------------------------------------------------------------------

**Goal:** Fetch NOTAM JSON from `VITE_NOTAM_URL` (EANS), poll on an interval, and expose stream status (live/stale/error) while keeping last good data.

**Acceptance**

*   Works with `VITE_USE_MOCKS=1` (loads `/mock/notams.sample.json`).
*   Works with `VITE_USE_MOCKS=0` (tries live URL; if blocked, shows stale/error but doesn’t crash).
*   Uses AbortController and preserves last good payload.

**Codex prompt**

```md
Implement Phase 3 ticket P3-01.

Follow AGENTS.md:
- NO PROXY (hard rule)
- UTC in domain logic
- keep last good data on network error + stale indicator
- do not add new runtime deps without asking

TASK:
1) Create src/services/notam/notamClient.ts:
   - export async function fetchNotamRaw(signal): Promise<unknown>
   - if VITE_USE_MOCKS=1 -> fetch("/mock/notams.sample.json")
   - else fetch(VITE_NOTAM_URL)
   - handle errors: throw with useful message
2) Add polling integration using src/services/polling/usePolling.ts (or create it if missing):
   - new hook: useNotamPolling({pollMs})
   - keep last good result + lastOkUtc + lastErrorUtc
3) Add VITE_POLL_NOTAM_MS support (default 60000 if unset).
4) Update docs/DATA_SOURCES.md: document NOTAM poll interval and mock fallback.
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Return changed files summary.
```

* * *

P3-02 — NOTAM types + normalized domain model (frontend contract)
-----------------------------------------------------------------

**Goal:** Define normalized NOTAM objects that UI + map layers can use without knowing EANS schema.

**Acceptance**

*   A `NormalizedNotam` type exists and includes: id, text, validity, altitudes\[\], optional geometry, plus raw payload preserved for debugging.
*   Altitudes are stored in meters with comment always present.

**Codex prompt**

```md
Implement Phase 3 ticket P3-02.

Constraints:
- No guessing upstream schema; treat raw as unknown.
- Normalize into a stable internal shape.
- Altitude type from AGENTS.md must be used; comment must always exist.

TASK:
1) Add src/services/notam/notamTypes.ts:
   - export type NotamRaw = unknown
   - export type NotamGeometry =
       | { kind:"circle"; center:[number,number]; radiusMeters:number }
       | { kind:"polygon"; coordinates: [number,number][][] } // GeoJSON polygon rings (lon/lat)
       | null
   - export type NormalizedNotam = {
       id: string;
       summary: string;
       text: string;
       validFromUtc?: string;
       validToUtc?: string;
       altitudes: Altitude[];
       geometry: NotamGeometry;
       eventTimeUtc: string;
       raw: unknown;
     }
2) Ensure NotamGeometry uses WGS-84 lon/lat.
3) Add small helpers to format summary (truncate/sanitize).

No interpreter yet (next ticket). Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

P3-03 — NOTAM interpreter v0 (best-effort): altitudes + geometryHint
--------------------------------------------------------------------

**Goal:** Convert raw NOTAM JSON (unknown-ish) into `NormalizedNotam[]` with:

*   parsed altitudes to meters
*   geometry from `geometryHint` if present in mocks
*   safe fallbacks if parsing fails

**Acceptance**

*   Works on `/public/mock/notams.sample.json`.
*   Altitude conversion supports at least: `SFC`, `FT AMSL/MSL`, and preserves `rawText` when uncertain.
*   `Altitude.comment` always present.
*   Leaves room to swap in a library later (adapter boundary).

**Codex prompt**

```md
Implement Phase 3 ticket P3-03.

Constraints:
- Keep NOTAM parsing behind src/services/notam/notamInterpreter.ts
- Do not add a third-party NOTAM decoder unless explicitly requested.
- Store altitude in meters; UI later shows both ft + m.
- Altitude.comment MUST always be present if altitude exists.

TASK:
1) Implement src/services/notam/notamInterpreter.ts:
   - export function normalizeNotams(raw: unknown, nowUtcIso: string): NormalizedNotam[]
   - assume raw might be:
       a) { generatedAtUtc, items: [...] } (mock)
       b) EANS live JSON (unknown shape) -> try to locate an array of items defensively
2) For each item, best-effort extract:
   - id (string)
   - text (string)
   - validFromUtc, validToUtc (if present)
   - summary (first sentence or first ~60 chars)
   - eventTimeUtc: use raw.generatedAtUtc if present else nowUtcIso
3) Parse altitudes from NOTAM text (minimum):
   - detect "SFC" -> Altitude { meters:0, ref:"AGL", source:"reported", comment:"SFC from NOTAM" }
   - detect patterns like "3000FT AMSL" or "3000 FT AMSL" -> meters = ft*0.3048, ref:"MSL", source:"reported", comment:"<raw> from NOTAM", rawText:<raw>
   - if unparseable -> meters:null, source:"reported", comment:"unparsed altitude from NOTAM", rawText: matched text
4) Geometry:
   - If item.geometryHint exists:
       - circle: {type:"circle", center:{lon,lat}, radiusMeters}
       - polygon: {type:"polygon", coordinates:[[lon,lat],...]} (assume closed if not closed)
     Convert to NotamGeometry.
   - Otherwise geometry = null.
5) Unit tests:
   - feed a fixture raw object with 2 NOTAM items and assert:
     - ids extracted
     - altitude meters conversion correct
     - comment always present
     - geometryHint circle/polygon normalized correctly
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Keep this interpreter conservative and robust.
```

* * *

P3-04 — Map overlay layer for NOTAM geometry (no OpenLayers in panels)
----------------------------------------------------------------------

**Goal:** Render NOTAM areas as overlays on the map (circle/polygon), labeled by NOTAM id.

**Acceptance**

*   NOTAM overlays appear when normalized NOTAMs include geometry.
*   Layer can be toggled via `mapApi.setLayerVisibility("notams", visible)`.
*   No OpenLayers imports in `src/features/*`.

**Codex prompt**

```md
Implement Phase 3 ticket P3-04.

Constraints:
- OpenLayers code stays in src/map/*
- NOTAM geometry stored as WGS-84 lon/lat; transform at OL feature creation boundary.
- Use mapApi as boundary.

TASK:
1) In src/map/layers/vectors.ts add:
   - createNotamLayer()
   - simple style (outline + label chip of id)
2) Extend mapApi:
   - mapApi.setNotams(notams: NormalizedNotam[])
3) In MapView:
   - create notam vector layer once
   - on setNotams: clear + add features for those with geometry
   - circle geometry: approximate polygon or use OL Circle geometry but ensure input is transformed properly
4) Do not implement click selection yet unless already present; just render overlays.
5) Update docs/ARCHITECTURE.md if needed + docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

P3-05 — NOTAM UI: show list + validity + altitudes (m + ft) + “Create geofence”
-------------------------------------------------------------------------------

**Goal:** Add a NOTAM section to the UI (recommended: inside **Air tool** panel) showing NOTAMs and allowing “Create geofence from NOTAM”.

**Acceptance**

*   Shows NOTAM list from mocks.
*   Each NOTAM shows validity window and altitude text in **m and ft**.
*   Button creates a geofence (circle/polygon) using Phase 2 geofence store and marks it as `source="notam"` + `source_ref=<notamId>`.
*   Works even if NOTAM has no geometry (button disabled with tooltip).

**Codex prompt**

```md
Implement Phase 3 ticket P3-05.

Constraints:
- Tool list is fixed (no new /notams route). Put NOTAM list inside /air or a tab in AirTrafficPanel.
- UI must display NOTAM altitudes in both m and ft in text.
- Panels must not import OpenLayers.

TASK:
1) Add a NOTAM section to src/features/air/AirTrafficPanel.tsx:
   - list normalized NOTAMs
   - show: id, summary, validFrom/validTo (formatted), and altitude display
   - include a filter toggle: "Valid now" (optional but helpful)
2) Implement formatting helper in src/shared/units/altitude.ts:
   - formatAltitudeWithFeet(alt: Altitude): string
   - For NOTAM/aircraft: show `${m} m (${ft} ft) — ${ref} (${source}) — ${comment}`
3) Add action "Create geofence from NOTAM":
   - if notam.geometry is circle -> create circle geofence in store (name = notam.id)
   - if polygon -> create polygon geofence (store polygon)
   - set source/meta fields: source="notam", source_ref=notam.id, validFrom/validTo copied
   - after creation: navigate to /geofences and select entity=geofence:<id> (optional)
4) Add component tests (RTL) for:
   - list renders from a fixture
   - create geofence calls store and adds item
5) Update docs/DATA_SOURCES.md and docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

P3-06 — Wire NOTAM polling → interpreter → map + UI (single source of truth)
----------------------------------------------------------------------------

**Goal:** Connect the whole pipeline:  
`fetch raw → normalize → update map layer + UI list` with stale/error state.

**Acceptance**

*   If NOTAM fetch succeeds: overlays and list update.
*   If it fails: last good remains and stale indicator shows.

**Codex prompt**

```md
Implement Phase 3 ticket P3-06.

TASK:
1) In MapShell (or a top-level provider):
   - call useNotamPolling()
   - call normalizeNotams(raw, nowUtcIso)
   - pass normalized list to:
     a) AirTrafficPanel (as props or via a small context)
     b) mapApi.setNotams(normalized)
2) Expose stream status in UI:
   - add a StatusPill in AirTrafficPanel header like:
     "NOTAM: live (updated 12s ago)" / "NOTAM: stale" / "NOTAM: error"
3) Ensure this respects the “keep last good data” rule.
4) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

P3-07 — Phase 3 E2E smoke: NOTAM overlay + create geofence
----------------------------------------------------------

**Goal:** A Playwright test proving the Phase 3 flow without pixel assertions.

**Acceptance**

*   Opens /air, sees NOTAM list.
*   Clicks “Create geofence from NOTAM”.
*   Navigates to /geofences and sees created geofence in list.

**Codex prompt**

```md
Implement Phase 3 ticket P3-07.

TASK:
1) Add Playwright test "Phase 3 NOTAM -> Geofence smoke":
   - goto /air
   - ensure NOTAM section exists and at least one NOTAM row is visible
   - click create geofence button on first NOTAM with geometry
   - goto /geofences (or assert navigation happened)
   - verify geofence list contains that NOTAM id
2) Avoid map pixel assertions.
3) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

### Suggested Phase 3 order (keeps PRs sane)

1.  P3-01 (client + polling)
2.  P3-02 (types)
3.  P3-03 (interpreter + tests)
4.  P3-04 (map overlay layer)
5.  P3-05 (UI list + create geofence)
6.  P3-06 (wire it together + status)
7.  P3-07 (E2E smoke)

If you want, I can bundle these into a single `docs/TICKETS_PHASE3.md` that your team/agents can execute linearly.

## Prompt:
what kind of icons (and what size) would we need?

## Response:
Thought for 17s

For this app you’ll want **two icon “worlds”**:

1.  **UI icons** (toolbar, buttons, panels) → standard Material icon sizing
2.  **Map markers** (OpenLayers features) → a small set of purpose-built marker icons that scale well and rotate cleanly

Here’s a practical icon inventory + sizes that won’t paint you into a corner when you later add swarms, more sensor types, clustering, etc.

1) UI icons (MUI)
-----------------

Use `@mui/icons-material` and stick to the defaults:

*   **Toolbar / nav icons:** 24×24 px (Material default)
*   **Sidebar list row icons:** 20×20 or 24×24 (pick one and be consistent)
*   **Small status chips:** 16×16 (optional)

These are just SVGs from MUI, so no asset files needed.

2) Map icons (OpenLayers markers)
---------------------------------

Use **SVG assets** (preferred) or **PNG @2x**. SVG keeps things crisp at all zoom levels and makes “rotate by heading” easy.

### Recommended base sizes

*   **Design size:** `32×32` viewBox (SVG)
*   **Displayed size on map:** ~`24–32 px` depending on zoom/style
*   If you choose PNG: ship **64×64** and render at **32×32** (retina friendly)

### Anchor / alignment rules

For anything that behaves like a “pin” or “vehicle marker”:

*   **Anchor** at **bottom-center** if it’s a pin (`[0.5, 1.0]`)
*   **Anchor** at **center** if it’s a symmetric marker (circle/triangle) (`[0.5, 0.5]`)

### Icon set you’ll realistically need

#### A) Drones (telemetry targets)

*   `drone_heading.svg` (a triangle/arrow silhouette that rotates)
    *   Display: **28–32 px**
    *   Must look good rotated 360°
*   `drone_unknown.svg` (fallback if no heading)
    *   Display: **24–28 px**
*   `selected_halo.svg` (not an icon per se, but a style overlay: ring behind selected entity)
    *   Display: **40–56 px** ring (vector circle is even better than an asset)

Why: swarms need cheap-to-render shapes; a simple arrow is faster than a detailed drone drawing.

#### B) Aircraft (ADS-B)

*   `aircraft_heading.svg` (small airplane silhouette; rotates)
    *   Display: **24–28 px**
*   Optional: `aircraft_unknown.svg` (no heading)

Aircraft markers should be slightly smaller than drones so the map doesn’t look like it’s sponsored by clipart.

#### C) Sensors (fixed infrastructure)

You can do this either as **one base icon + small glyph overlay**, or separate icons per kind.

Minimal set:

*   `sensor_generic.svg` (small mast / dot-in-circle)
    *   Display: **20–24 px**
*   `sensor_aeroscope.svg`
*   `sensor_radar.svg`
*   `sensor_rfdf.svg` (direction finding)

If you want to keep assets tiny: make `sensor_generic.svg` and vary appearance via OL styling (shape + label), and reserve per-kind icons for the sidebar.

#### D) NOTAM & Geofence

On the map, NOTAMs and geofences are usually **polygons/circles**, so you don’t need “markers” for the geometry itself. But you _do_ want list icons and maybe a centroid label marker.

*   `notam_badge.svg` (for sidebar rows, optional centroid marker)
    *   Display: **20–24 px**
*   `geofence_badge.svg` (sidebar row icon)
    *   Display: **20–24 px**
*   Optional centroid marker for polygons: a simple **dot** rendered via OL Circle style (no asset).

#### E) Clustering / density management (later, but plan now)

If you cluster drones/aircraft at low zoom:

*   You don’t need an asset; generate a **circle + count text** in OL style.
*   If you prefer an asset: `cluster_circle.svg` at **40×40**.

### Suggested asset list (v1)

Put these under `src/map/styles/icons/`:

*   `drone_heading.svg` (32×32)
*   `drone_unknown.svg` (32×32)
*   `aircraft_heading.svg` (32×32)
*   `sensor_generic.svg` (32×32)
*   `sensor_radar.svg` (32×32) _(optional if you don’t do overlays)_
*   `sensor_aeroscope.svg` (32×32) _(optional)_
*   `sensor_rfdf.svg` (32×32) _(optional)_
*   `notam_badge.svg` (24×24)
*   `geofence_badge.svg` (24×24)

That’s enough to cover Phase 1–3 cleanly.

3) Practical sizing cheat sheet
-------------------------------

*   **Map drones:** render at 30–32 px
*   **Map aircraft:** render at 24–28 px
*   **Map sensors:** render at 20–24 px
*   **Selection halo:** ~48 px (style-generated)
*   **Sidebar row icons:** 20–24 px
*   **Toolbar icons:** 24 px (MUI default)

4) Small but important implementation detail
--------------------------------------------

If you use SVGs for OL markers: keep them **monochrome** (or minimal) and apply color in OpenLayers styles where possible. It makes “selected / stale / error” state changes trivial without duplicating assets.

* * *

If you later want a “standard-ish” look for counter-UAS displays, the most common pattern is exactly this: **arrow markers for moving targets**, **small distinct glyphs for sensors**, and **polygons/circles for areas**, with selection handled by a halo + label rather than a different icon.

## Prompt:
for map markers - should i generate these myself or find online?

## Response:
For map markers: **generate your own (simple SVGs)** unless you have a very strong reason not to.

Here’s why, in practical engineering terms:

### Why “make your own” is usually the win

*   **Licensing stays boring.** Random “free icon packs” love surprise restrictions. If this ever becomes a govt/infra project, boring licensing is a feature.
*   **You need rotation + states.** Drones/aircraft markers should rotate (heading) and reflect states (selected/stale/error). Custom minimal SVGs make this trivial.
*   **Consistency.** A coherent icon language (same stroke weight, same visual density) matters a lot on maps. Mixed online icons look like a ransom note.
*   **Performance.** Simple shapes (triangle/plane silhouette, dot-in-circle sensor) render fast and stay readable when you have swarms.

### When “find online” makes sense

*   **UI icons** (not map markers): absolutely use MUI icons.
*   **If you need photoreal / branded shapes** (you don’t).
*   **If you have a known-good permissive source** (MIT/Apache/CC0) and you don’t mind doing a licensing sweep.

### Best compromise

*   **Design your own “core” set** (drone arrow, aircraft silhouette, sensor glyph, NOTAM/geofence badge) as clean monochrome SVGs.
*   Optionally **borrow** from a reputable permissive set _only for non-critical extras_.

If you do borrow, stick to reputable sources and keep a `docs/ICON_LICENSES.md` listing:

*   icon name → source → license → any required attribution.

### Recommendation for your project

For Phase 1–3: make 6–9 tiny SVGs yourself. Seriously. A triangle, a plane, a dot-with-rings, a radar arc. You can knock these out in minutes, and you’ll never regret it.

If you want, I can also give you a ready-to-use minimal SVG pack (drone arrow + aircraft + 3 sensors + badges) with a consistent 32×32 viewBox that will rotate and scale nicely in OpenLayers—just say what visual style you prefer (flat outline vs solid).

## Prompt:
what file type, size etc (for example give me a promt for chattgpt to generate one with airplane shape)

## Response:
For map markers, the sweet spot is:

*   **File type:** **SVG** (best for crisp scaling + easy rotation)
*   **Canvas / viewBox:** **32×32** (or 24×24, but 32×32 gives nicer detail)
*   **Displayed size in OpenLayers:** ~**24–28 px** for aircraft, depending on zoom
*   **Anchor:** usually **center** for aircraft (`[0.5, 0.5]`) so rotation looks right
*   **Style:** keep it **simple + monochrome** so you can recolor for states (selected/stale/error) without multiple assets

### What the SVG should be like

*   Use a `viewBox="0 0 32 32"`
*   Draw the aircraft pointing “up” (north) by default — then OL rotation matches heading naturally.
*   Prefer a single path; avoid tiny details.

* * *

Prompt to generate an airplane marker SVG (copy/paste)
------------------------------------------------------

```md
Generate a simple, clean SVG icon for an aircraft map marker suitable for OpenLayers.

Requirements:
- Output ONLY valid SVG markup (no explanations).
- SVG must be monochrome (use currentColor so the app can recolor it).
- Size: width="32" height="32" viewBox="0 0 32 32".
- The aircraft must point UP (north) in the default orientation, so it can be rotated by heading.
- Shape style: minimal silhouette (fuselage + wings + tail), readable at 24px on a map.
- Use a single <path> if possible.
- Fill: currentColor. No stroke, no gradients, no filters.
- Center the geometry nicely within the viewBox, with a little padding so it doesn’t clip when rotated.

Return only the SVG.
```

If you want a variant that looks better as an outline (and still recolorable), use this prompt instead:

```md
Generate a simple outline SVG icon for an aircraft map marker suitable for OpenLayers.

Requirements:
- Output ONLY valid SVG markup.
- width="32" height="32" viewBox="0 0 32 32".
- Aircraft points UP (north).
- Use stroke="currentColor", fill="none", stroke-width="2", stroke-linecap="round", stroke-linejoin="round".
- Keep the design minimal and readable at 24px.
- Center it with padding; avoid clipping when rotated.

Return only the SVG.
```

* * *

### OpenLayers sizing rule of thumb (so it looks right)

*   Render the 32×32 SVG at **24–28 px** (aircraft), **28–32 px** (drones), **20–24 px** (sensors).
*   Anchor aircraft at center for rotation.
*   Keep selection as a separate halo style (circle) rather than a different aircraft icon.

If you want, I can also give you a ready-made example SVG right here (solid or outline), but the prompt above is usually enough to generate a consistent pack.

## Prompt:
where in folder structure should i keep these?

## Response:
Put **map marker assets** under the **map styling** area, so the “no OpenLayers in panels” boundary stays clean and everything map-visual lives together.

### Recommended location (matches your AGENTS.md structure)

**For map marker SVGs:**

*   `src/map/styles/icons/`
    *   `aircraft_heading.svg`
    *   `drone_heading.svg`
    *   `sensor_generic.svg`
    *   etc.

**For OpenLayers style code that uses them:**

*   `src/map/styles/` (e.g. `markers.ts`, `labels.ts`)
*   or keep existing split:
    *   `src/map/styles/icons.ts` (imports URLs, exports helpers)
    *   `src/map/styles/labels.ts`

This keeps the contract simple:

*   `src/features/*` never touches icons or OL styles
*   `src/map/*` owns all marker look-and-feel

### How to reference them in Vite

In Vite, importing assets from `src/` gives you a URL string:

```ts
import aircraftSvgUrl from "@/map/styles/icons/aircraft_heading.svg";
```

Then feed that URL to an OpenLayers `Icon` style.

### Alternative that also works (but I don’t recommend first)

*   `public/assets/icons/...`

Pros: easy to reference by fixed URL (`/assets/icons/...`)  
Cons: encourages “random assets anywhere” over time; harder to refactor/bundle; less discoverable than keeping it near map styling.

### Quick rule

*   **If it’s used by OpenLayers styles → `src/map/styles/icons/`**
*   **If it’s used by general UI (rare) → `src/ui/assets/` or just use MUI icons**

If you want a clean convention, add one line to `AGENTS.md` under “Repo structure”:

*   `src/map/styles/icons/` — static marker SVGs used by OpenLayers.

## Prompt:
how do we call the "track" behind airplanes that shows it's flight path

## Response:
In aviation / tracking systems, that line behind an aircraft has a few **well-established names**. The key is picking one that’s both **technically correct** and **UI-friendly**.

Here’s the landscape, from most standard to most UX-safe.

* * *

The canonical technical terms
-----------------------------

### **Flight track**

**Best default.**  
This is the most widely accepted term in aviation, surveillance, and ADS-B systems.

*   Used by ATC, ADS-B tools, radar systems
*   Neutral: works for live, historical, fused, or simulated data
*   Scales well to drones later

**Recommended internal name:** `flightTrack`  
**UI label:** “Flight track”

* * *

### **Track history**

Emphasizes time rather than geometry.

*   Common in surveillance/radar systems
*   Slightly more abstract than “flight track”

**Good for:** history panels, toggles  
**Less ideal for:** layer names

* * *

### **Trajectory**

Mathematically precise.

*   Correct in physics / analytics contexts
*   Sounds heavy in UI

**Use when:** talking about analysis, prediction, or simulation  
**Avoid as primary UI label**

* * *

Terms you should avoid (or use very carefully)
----------------------------------------------

### ❌ “Trail”

*   Sounds visual-only
*   Ambiguous (could mean exhaust, wake, or decorative line)
*   Sometimes used in games, not serious surveillance

### ❌ “Breadcrumbs”

*   Informal, debug-y
*   Fine for internal jokes, not for operators

### ❌ “Path”

*   Too generic
*   Doesn’t imply time or ordering clearly

* * *

Recommended terminology stack (clean + future-proof)
----------------------------------------------------

### Internal domain / code

```ts
FlightTrack
TrackPoint
trackId
trackPoints[]
```

For drones later, this generalizes cleanly to:

```ts
Track
TrackPoint
entityKind: "aircraft" | "drone"
```

### Map layer names

*   `flight-tracks`
*   later: `entity-tracks`

### UI labels

*   Toggle: **“Show flight tracks”**
*   Tooltip: **“Flight track (last 10 minutes)”**
*   Details panel: **“Track history”**

* * *

How this fits your DB & mock model
----------------------------------

This aligns perfectly with what you already designed:

*   **observations** → raw points
*   **tracks / track\_points** → cleaned or grouped flight tracks
*   **truth.mfjson / observations.ndjson** → track replay

So you’re not inventing terminology—you’re matching how ATC, ADS-B tools, and counter-UAS systems already think.

* * *

One-sentence recommendation
---------------------------

> Call it a **Flight Track** (internally and in UI), store it as a sequence of **TrackPoints**, and reserve **Trajectory** for analytics and simulation discussions.

If you want, next we can:

*   Define **how long a flight track should be** (last N points vs last T minutes)
*   Decide **when tracks fade or break** (gaps, landings, handovers)
*   Or standardize **naming for drones vs aircraft** so they stay aligned

## Prompt:
analyze Vasikas repo for refactor - what code implementation issues appear and in the end suggest the big picture path to solve them

## Response:
Could you please clarify what specific aspects of the andresmoks720/VASIKAS repository you'd like me to focus on for the refactor analysis? For example:

*   Are you primarily concerned with code quality (e.g. structure, duplication, logic flow)?
*   Are there particular modules or components you want examined in more detail?
*   Should I focus on a frontend, backend, or fullstack perspective?
*   Do you want suggestions for architectural restructuring, testing, performance, or style conventions?

Let me know the angle so I can tailor the analysis effectively.

## Prompt:
code quality and extendability for planned developments (we have talked about)
it is fully frontend right now.

suggest architectural restructuring, testing, performance, or style conventions.

## Response:
Got it. I’ll analyze the code quality and architecture of the VASIKAS frontend repo to assess its extendability for upcoming features like drone track visualization, sensor integration, geofence creation, and more.

I’ll review key implementation issues, performance concerns, testing gaps, and offer architectural restructuring suggestions to ensure the system is maintainable and scalable.

I’ll follow up once the evaluation is ready. Meanwhile, feel free to continue with other tasks.

Research completed in 10m · 38 sources · 16 searches

## Response:
Codebase Overview and Readiness for Future Features
===================================================

Architecture & Code Structure
-----------------------------

The VASIKAS frontend is organized into clear layers, which bodes well for upcoming features. The **feature-based folder structure** is logical: e.g. `src/features/*` for UI panels, `src/map/*` for OpenLayers integration, `src/services/*` for data/polling, etc[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/ARCHITECTURE.md#L14-L19)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L181-L190). This separation largely adheres to best practices and will help accommodate new components like real sensor feeds or geofence tools. Notably, the **MapShell** layout keeps the map mounted persistently while the sidebar content swaps based on URL state[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/ARCHITECTURE.md#L3-L12). This design (a “map-first” persistent view) is appropriate for a real-time surveillance app, ensuring the map (and its state like zoom/center) doesn’t reset on navigation[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/UI_RULES.md#L80-L88).

**Planned features** like **real sensor APIs, backend persistence, geofences, and layer toggling** should fit into the current structure with minimal friction. For example:

*   _Real sensor API integration:_ The code already uses an environment flag `VITE_USE_MOCKS` to switch between mock files and real endpoints[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L86-L94). The services (e.g. `useSensorsStream` in `sensorsClient.ts`) call either `/mock/sensors.json` or a real `ENV.sensorsUrl()` based on that flag[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/sensors/sensorsClient.ts#L24-L32). This indirection means plugging in a real API URL is straightforward without altering component logic. Domain-specific mapping (converting DTOs to `Sensor` objects) is encapsulated in the service layer, which is good. As long as the real API returns similar data (or the mapping functions are updated accordingly), the panels and map can remain unchanged. This is a **flexible design** that will ease Phase 5 (live sensor client) and Phase 4 (live ADS-B) integration[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/IMPLEMENTATION_PLAN.md#L65-L73).
*   _Backend persistence:_ Currently, some features use in-memory stores (e.g. `geofenceStore`, `sensorStore`) for CRUD operations[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/geofences/GeofencesPanel.tsx#L39-L47)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L56-L64). These act as local stand-ins for a database. The architecture anticipates moving to a backend in Phase 6[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/IMPLEMENTATION_PLAN.md#L65-L73) – a likely bottleneck will be refactoring these stores into API clients. Because the code has clean boundaries, this should be manageable: for example, geofence creation is confined to `GeofencesPanel` calling `geofenceStore.createCircle()` then refreshing the list[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/geofences/GeofencesPanel.tsx#L54-L62). To persist, that logic can be replaced with an API call (e.g. `await geofenceClient.create()`), and the UI would remain mostly the same aside from handling async responses. **One caution:** currently the app assumes a single source of truth (the frontend store). Once a backend is authoritative, ensuring the UI stays in sync will require careful design. It may be wise to introduce a state management solution or use React Query for server state, so that, for example, adding a geofence updates all relevant components consistently. The code already merges “user sensors” from `sensorStore` with polled sensors[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L104-L113)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L150-L159), which shows awareness of combining local and remote data. Extending this pattern to geofences (and other persisted data) by merging local changes with backend-fetched lists could smooth the transition.
*   _Geofences & map layering:_ The geofence functionality is well modularized. Geofence shapes and data live in `geofenceStore` and are synced to the map via `mapApi.setGeofences(...)` events[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L277-L285)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L290-L298). The **OpenLayers layer for geofences** is created once in `MapView` and updated via these events, meaning the UI panel doesn’t touch OpenLayers directly (good separation)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L219-L227)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L233-L240). This design is suitable for adding more layers or drawing tools. The docs explicitly tell developers how to add new layers under `src/map/layers/*` and wire them into `MapView`[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/ARCHITECTURE.md#L22-L29). Future **map tool layering** (like additional overlays or a toggle UI) is supported by the existing `mapApi.setLayerVisibility(...)` event and the stored refs to each OL layer[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L320-L329)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L334-L341). For instance, the code ensures the ADS-B layer is visible when the “airplanes” tool is active[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L726-L734); similar logic could hide or show layers per tool. Currently, not all layers are dynamically toggled (sensors, drones, etc., stay on by default), but the plumbing is in place to change that. Going forward, implementing a UI control for layer visibility would be relatively easy: the control would call `mapApi.setLayerVisibility('sensors', false)` for example, and the event handler in `MapView` already adjusts the OL layer’s visibility[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L320-L328)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L334-L337).

In summary, **the overall architecture is sound and forward-looking**. It enforces boundaries (no direct OL usage in React panels, no data-fetching in components, etc.) which helps maintain clarity as features grow[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L215-L224)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L227-L235). Each planned feature has an obvious “slot” in the structure (e.g. a new service for persistence, new panel under `features/` for a new tool, etc.). This separation will help keep the codebase extendable and prevent it from turning into a tangled monolith as new capabilities are added.

Component Organization & Clarity
--------------------------------

The component structure is generally clear and idiomatic React. Each panel (AirTrafficPanel, SensorsPanel, etc.) is focused on **presenting data** and handling user interactions, while delegating data-fetching to hooks in the services layer[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L98-L101)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L136-L144). This is a good separation of concerns that aligns with best practices. Some specific observations:

*   **File/Component structure:** Components are sensibly grouped by feature. For example, all sensor-related UI lives in `SensorsPanel.tsx` (with a small `SensorRow` subcomponent inside for list items[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L150-L159)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L2-L5)), and the logic specific to sensors (like formatting the “updated Xs ago” timestamp) is encapsulated there[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L28-L36). Shared UI bits (like `StatusPill`, `EmptyState`, or `KeyValueRow`) are in a `ui/` folder for reuse[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L190-L198), which helps avoid duplication. This organization makes the code easy to navigate and reason about.
*   **MapView complexity:** The `MapView` component is relatively large (~800 lines) because it aggregates all map layer logic. While it is logically organized (initialization, then one effect per data source to update features, etc.), it is a **dense component**. As more layers or map interactions are added (geofences, NOTAMs, perhaps future heatmaps or additional overlays), consider refactoring some of its internal logic into helper modules or hooks. For example, each layer’s update logic could potentially be a custom hook (e.g. `useSensorLayer(sensors, selectedEntity)` to handle syncing sensor features) to break the code into smaller units. Even without hooks, pulling out some repeated patterns into functions would improve clarity – e.g. a helper to add/update point features from a data array (since the ADS-B and drone effects share a lot of logic around reusing existing features vs creating new ones[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L496-L505)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L581-L589)). Keeping `MapView.tsx` manageable will ensure that future developers can safely modify layer behavior or add new ones without fear of breaking unrelated parts.
*   **State management and URL coordination:** The approach to state is minimalistic but effective. The URL is treated as the source of truth for high-level state (current tool, selected entity, history date/area), via the custom `useSidebarUrlState` hook[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/useSidebarUrlState.ts#L26-L35)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/useSidebarUrlState.ts#L48-L57). This hook cleanly wraps React Router’s hooks, parsing the `:tool` path param and `?entity` query into a structured state object[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/useSidebarUrlState.ts#L31-L40). This design keeps **UI state in sync with the URL** for back/forward navigation and bookmarking, which is excellent for a SPA that might be deployed as a standalone app. The implementation is straightforward and well-tested (there’s a corresponding `urlState.test.ts` to verify parsing/formatting) – another sign of code quality. The coordination between URL state and the rest of the app is also well thought out: for example, selecting an item on the map updates the `?entity=` query (via `MapView` calling `onSelectEntity` callback)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/MapShell.tsx#L88-L96), and the sidebar reacts by rendering `ObjectDetailsPanel` when `entity` is set. Moreover, the `selectEntity` function is careful to use `replace: true` by default to avoid cluttering the browser history with selection changes[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/useSidebarUrlState.ts#L56-L64) – a nice usability touch.
*   **Context and shared state:** The app avoids heavy state libraries (Redux/MobX, etc.), which is appropriate for the current scope. Instead, it uses React Context for sharing data streams (`StreamsProvider`)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/streams/StreamsProvider.tsx#L15-L23). This context provides a **single source of truth for live data** (drones, aircraft, sensors) so that multiple components can use it without redundant API calls[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/streams/StreamsProvider.tsx#L16-L24). For instance, the map and the list panels both consume `useSharedDronesStream()`, but thanks to context they tap into the _same_ polling stream rather than each hooking their own poller. This prevents unnecessary network load and keeps data consistent across UI. The pattern of isolating data fetching in hooks (like `useAdsbStream`, `useSensorsStream`) and then exposing them via context is a clean solution for state management at this scale. It should continue to scale for new data sources (e.g. if a new context for user profiles or notifications is needed later, it can follow the same pattern). One thing to monitor is **performance**: because the StreamsProvider mounts at the top and polls all feeds continuously, the app is doing work even if the user isn’t viewing a particular feed. Right now, that’s fine (and ensures the map overlays are always up-to-date), but if data sources multiply or become very high-frequency, you might implement conditional polling (e.g. only poll ADS-B data if the layer is visible or the user’s current view requires it). The current design doesn’t have such conditional logic, but adding it could be done by checking the `tool` or a user preference before starting a poll. This could be a future enhancement to avoid wasting resources, especially when integrating real APIs that might have rate limits.

In general, the components are easy to read and modify. Prop drilling is minimal (mostly just passing `tool` and URL params into child components) since context is used for broad needs. The clarity of one-component-per-file (with perhaps a small helper component within) is maintained, and consistent styling via MUI keeps the markup clean. **Enforcing some conventions** (like always using functional components and hooks, no legacy class components, and using the provided ESLint config to catch inconsistencies) will further maintain this clarity. The `.eslintrc.cjs` and formatting rules in place should be run regularly (perhaps integrate with a pre-commit hook or CI) to ensure code style remains uniform as the team grows.

State & URL Coordination
------------------------

As touched on above, state is handled in a React-idiomatic way. A few additional remarks on this, especially in light of future features:

*   The **URL contract** (paths for tools, query for selected entities and history context) is well-defined in docs[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L317-L325) and enforced in code. This makes the app easily **extensible** for new routes or query params. For example, if “replaying scenarios” (history mode) needs additional query parameters (say a `t=` timestamp for playback position), the existing `urlState.ts` helpers can be extended to parse/format that. The code already handles `hDate` and `hArea` for history context in a generic way[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/layout/MapShell/useSidebarUrlState.ts#L35-L43). Ensuring any new URL param also goes through a single source of truth (like extending `useSidebarUrlState`) will keep the coordination tight and avoid bugs where one component thinks the state is something else.
*   **Global state introduction:** One upcoming feature is **user accounts & sessions**. Currently, the app stubs out an `useAuth()` hook (in `auth.ts`) that always returns a mock logged-in user[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L264-L272)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L374-L382). To implement real auth (Phase 8), a likely approach is adding an AuthProvider context similar to StreamsProvider. This context can hold user info, a login method, etc., and wrap the app in `App.tsx`. Given that the architecture thus far avoids global mutable singletons (aside from the purpose-built `mapApi` event emitter), using a context for auth is appropriate. This will keep user state accessible where needed (e.g. to show/hide certain UI for non-admins) without cluttering unrelated components. When adding such global state, continue to follow the pattern used by StreamsProvider: initialize it high in the tree and provide custom hooks for consumers (e.g. a `useAuth()` hook already exists as a facade). This hides implementation details and makes it easy to mock in tests (just as tests currently mock `useSharedAdsbStream` or others[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/air/AirTrafficPanel.test.tsx#L7-L15)).
*   **Potential need for a state library:** At the current size, React’s built-in tools suffice. If the app were to introduce significantly more complex state (e.g. caching large amounts of historical data, or coordinating real-time updates in a more complex way), it might be worth considering a state management library or query caching library. For instance, if “replay scenarios” means loading possibly large historical datasets (imagine a timeline of thousands of drone positions), using something like **React Query** to fetch and cache that data could help. It would manage background refetching, caching, and provide out-of-the-box staleness handling (some of which you’ve custom-built in `usePolling`). That said, introducing such a library has costs in complexity, and the team wisely decided to hold off on Redux/MobX until necessary[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L420-L428). My recommendation is to continue with the current lightweight approach; it’s working well. Only consider an external state tool if you find yourself writing a lot of boilerplate to prop-drill or to keep derived state in sync. So far, the URL + Context strategy is covering these needs elegantly.

Testing Coverage and Strategy
-----------------------------

The repository shows a strong emphasis on testing, which is great to see in a prototype. Both **unit tests and end-to-end tests** are present, targeting critical functionality:

*   **Unit tests:** Key pure functions and small modules are tested (for example, `urlState.test.ts` for the URL parsing logic, `adsbClient.test.ts` for data mapping rules, `trackStore.test.ts` for the track history logic, etc.). The tests verify important domain behaviors like altitude formatting conversions, callsign parsing, track sorting[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/adsbClient.test.ts#L136-L144)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/adsbClient.test.ts#L170-L177), etc. This ensures that the core data transformations adhere to the domain rules documented (e.g. no naked altitudes, always meters stored, etc. per UI\_RULES[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/UI_RULES.md#L112-L120)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L233-L242)). Having these tests means future refactors (like moving logic to the backend) can be done with confidence – you can run the suite to catch any regressions in calculation or parsing.
*   **Component tests:** Some React components have tests via React Testing Library and Vitest. For instance, there are tests for `AirTrafficPanel` and `SensorsPanel` rendering expected output[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/air/AirTrafficPanel.test.tsx#L36-L44). These tests mock the data hooks and URL hook so the component can be tested in isolation. They ensure that given a sample piece of state (e.g. one aircraft), the panel displays the formatted altitude and speed correctly[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/air/AirTrafficPanel.test.tsx#L38-L45). This is valuable for catching issues in presentation logic and conditional rendering. The presence of these tests indicates good practice – continue writing similar tests for new panels or complex components (like if you add a Timeline slider component for history playback, consider writing tests for its behavior). One area that might need more unit tests in the future is the map interaction logic. Right now, because `MapView` relies on OpenLayers, it’s tricky to unit-test directly. However, many pieces are pure or can be tested in isolation (e.g. `to3857/to4326` transforms, helper functions like `notamGeometryToOl()` which could be fed sample data, etc.). As map logic grows, factor out what you can into testable functions and add tests for them. This will prevent subtle bugs in coordinate math or filtering from creeping in.
*   **Integration & E2E tests:** The project uses Playwright for end-to-end smoke tests. The Implementation Plan lists scenarios like verifying the app loads with the map, switching tools updates the sidebar, clicking a marker opens the details. These cover the high-level sanity checks. It’s worth expanding E2E tests as new user flows appear: for example, tests for the geofence creation UI (Phase 2’s deliverables) have likely been added (the plan mentions a “Phase 2 E2E: Editable world smoke test”[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/IMPLEMENTATION_PLAN.md#L19-L24) which presumably clicks “Add Geofence”, draws it, etc.). Make sure to include scenarios for login (when implemented), and scenario replay (e.g. “navigate to /history and ensure data from a specific date is shown”). Playwright is a good choice here because it can handle multi-page flows and map interactions (to some extent – verifying canvas map contents is hard, but you can at least verify that the expected markers exist via DOM or that certain panels update as you scrub a timeline).

Overall, test coverage seems **targeted and appropriate**. The tests focus on critical logic (rather than trivial getters or simple component output), which is the right balance. A suggestion for maintainability is to automate running these tests (and linting) in CI, so that any breaking change in a future feature is caught early. Also consider using coverage reports to see if any critical modules lack tests – for instance, if `notamInterpreter.ts` (the NOTAM parsing) isn’t yet tested, that would be a good addition given its complexity.

Performance & Rendering Considerations
--------------------------------------

Thus far, the performance of the app is likely governed by two main factors: **polling frequency** and **map rendering efficiency**. The architecture has taken some steps to handle these, but future expansions (more data, real-time high frequency updates, many entities) will require vigilance.

*   **Polling and data updates:** The custom `usePolling` hook is well-implemented, with support for aborting in-flight requests and marking data “stale” if updates lag[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/polling/usePolling.ts#L126-L135)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/polling/usePolling.ts#L190-L199). The polling intervals are currently set to 1Hz for drones/sensors and 10s for ADS-B by default[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L96-L100). These are reasonable for a prototype. If in the future real sensors produce data faster (or if you simulate a “swarm” of hundreds of drones), you will need to be careful with how much work is done on each tick. As it stands, the data transformation per tick is fairly light (e.g. mapping a dozen aircraft JSON entries to objects). However, the **map updating** can be heavier: each polling tick triggers an effect in `MapView` that may call `source.clear()` and add a bunch of features anew (for sensors and drones)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L423-L432)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L556-L564). For a handful of objects, that’s negligible, but clearing and redrawing dozens or hundreds of features every second could start affecting frame rates (and cause visible flicker if not done carefully). The ADS-B handling is more efficient: it reuses existing OL features for aircraft when possible and only removes those no longer present[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L496-L505)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L528-L535). **Refactoring sensor and drone updates to a similar incremental approach** would help performance. Instead of clearing all sensor features on each poll, you could track previous sensors and update positions or add/remove incrementally. This would reduce DOM thrash in the canvas and likely be smoother. Even if it’s not needed now, it’s something to keep in mind as load grows.
*   **Map rendering and overlays:** OpenLayers is quite performant with vector layers, but high entity counts or complex geometries (like detailed NOTAM polygons) could slow it down. The current code limits track history to 30 points or 10 minutes per aircraft[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/trackStore.ts#L20-L28)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/trackStore.ts#L74-L83), which is a good guardrail to prevent unbounded growth in line features. For a **“swarm simulation”** (many moving drones), performance might become a concern. Some mitigations to consider:
    *   Use WebGL-backed layers for very large point counts (OL has a WebGL PointsLayer that can handle thousands of points efficiently).
    *   Throttle redraws – e.g. if polling is 1Hz but positions change minorly, you might not need to redraw every single second for every drone. This is speculative; likely you _do_ want real-time updates, but for extremely high volumes, you might sample or ease updates.
    *   Ensure that any heavy computations (distance calculations, projections) are done outside of critical render path or are memoized. The code already memoizes the base map layer creation[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L127-L136) and uses `useMemo` for derived data like `droneTracks` placeholder[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L539-L547), which is good. Continue using memoization for any expensive derivations.
*   **Selection and re-renders:** The interplay of React state and OL state is generally managed well. One nuance: highlighting the selected entity on the map. The code uses OL style functions that check if a feature is the selected one and changes its appearance[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L176-L185)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L204-L213). Initially, those style functions captured `selectedEntity` from props at mount time, which could go stale as selection changes. The team addressed this by forcing layer re-styling on selection change (calling `layer.changed()` on all layers)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L718-L724) and in the drone layer even resetting the style function with the latest selection via a ref[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L597-L605)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L619-L627). This works, but is a bit of a workaround. A cleaner approach might be to store a “selected” property on features and let style functions simply look at `feature.get('selected')`. Then when selection changes, you’d just tag the new selected feature with `feature.set('selected', true)` and untag the old, and OL would restyle automatically. This would avoid messing with closures and ensure the style always reflects internal feature state. It’s not a critical issue (the current solution does function, as evidenced by tests and usage), but it’s worth considering as a **refinement for code simplicity**. It would enforce the idea that map rendering is a pure function of feature properties, which is easier to reason about than a function capturing external React state.
*   **Memory usage:** So far, no obvious memory leaks are present. Every `setInterval` or event subscription in `MapView` is cleaned up on unmount or dependency change[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L254-L263)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L380-L389). The polling hook also clears intervals and aborts fetches on unmount[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/polling/usePolling.ts#L180-L188). This discipline should continue. With a long-running app (as one monitoring UI might be open for hours in a control room), watch for any accumulation of data (the trackStore already caps history; similarly ensure something like NOTAM data doesn’t keep growing if the feed is long-lived – likely NOTAMs are relatively static, though). If you implement a **replay feature**, be mindful to clear or paginate data if the user can load an entire day’s worth of telemetry; don’t keep all of it in memory if not needed. Perhaps load history in slices or simplify it when older than a certain threshold.

In summary, **performance is adequate now but needs attention as features expand**. The architecture is not inherently slow – in fact using an offscreen canvas (OL) for rendering means the React reconcilation is not a bottleneck (React just renders the container and a few controls, OL handles the heavy drawing). The key will be efficient updates to OL layers and not overwhelming the browser with too many operations at once. Given the current patterns (using refs and direct OL API calls inside effects), continuing that approach is fine. Just consider more granular control (e.g., only update the drones layer when drone data actually changes, etc. – React’s dependency arrays already help with this by tying effects to `[drones]` or `[aircraft]` so they don’t run unnecessarily[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L423-L432)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L457-L465)).

OpenLayers Integration & UI Boundaries
--------------------------------------

One of the strong suits of this codebase is the clear boundary between map logic and UI logic. **OpenLayers is confined to `src/map`** and interacted with through a narrow `mapApi` interface for the rest of the app[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/ARCHITECTURE.md#L14-L19)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L219-L227). This is a sound architectural decision that prevents tight coupling. Panels use `mapApi` methods like `mapApi.centerOnEntity(...)` or `mapApi.setTrackVisibility(...)` instead of reaching into the map directly[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/objectDetails/ObjectDetailsPanel.tsx#L124-L132)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/objectDetails/ObjectDetailsPanel.tsx#L138-L146). This decoupling means that, for example, the ObjectDetails panel doesn’t need to know anything about OpenLayers – it just emits an intent (“focus this drone” or “show this trajectory”) and the map module handles it. That’s excellent for maintainability and for potentially swapping out the map library in the future (unlikely, but the point is the UI doesn’t depend on OL specifics).

A few notes on this integration:

*   **mapApi event emitter:** The `MapApi` class is essentially a simple pub-sub (with `.on()` and `.emit()` for events)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/mapApi.ts#L17-L26)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/mapApi.ts#L60-L67). It works for now given the limited number of events. If the number of map-driven events grows a lot, you might consider a more robust pattern (even just using a third-party tiny event emitter or using RxJS observables). But likely, the usage will remain limited to a handful of events like these. The events cover setting data (geofences, NOTAMs), view actions (center/focus), and toggles. This covers foreseeable interactions. One thing to ensure: **panels should not misuse mapApi to do things outside its small domain.** The current API is nicely constrained (essentially “set data to map” and “change view/visibility”)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/mapApi.ts#L36-L44)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/mapApi.ts#L48-L57). If a panel is ever tempted to do more (like manipulate individual features or layers in a custom way), consider expanding mapApi appropriately so the panel still doesn’t directly touch OL. Maintaining this boundary will keep the app’s reactive UI logic separate from imperative map manipulation logic, which is important for sanity.
*   **Future map features:** If features like drawing tools (e.g. user drawing a geofence polygon on the map) or drag-and-drop on map markers are added, you’ll need to decide how to handle those events. Right now, the data flow is mostly one-directional (services → map, user clicks → URL → details). If, say, the user could edit a geofence by dragging its border on the map, then OL would produce events that need to update React state. In that case, you might publish an event from `mapApi` (e.g. `mapApi.on("geofence-modified", ...)` which a panel or service listens to in order to update the store). This is speculative, but the point is that the **event emitter approach can be extended to map→UI communication** as well, not just UI→map. Just be cautious to avoid too much event soup – keep event types discrete and document their payloads. Given the forethought in docs so far, that shouldn’t be an issue (just update `ARCHITECTURE.md` or similar with any new event types and their purpose).
*   **Geofence and NOTAM layering:** You have a good pattern with geofences where the data is stored in a service (`geofenceStore`) and injected into the map and UI from there. NOTAMs are handled similarly: fetched via `notamClient` and then passed to `mapApi.setNotams` to draw[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L300-L308)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L310-L318). The **“interpretation”** of NOTAM JSON into geometry is done in a dedicated module (`notamInterpreter.ts`) with domain types[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L276-L284). This is excellent because it isolates the gnarly parsing logic. As noted in the docs, eventually this will move to the backend[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L280-L284). When that happens, the front-end can likely drop a lot of this code and just consume an API that provides already-interpreted NOTAMs. Thanks to how it’s structured, that should be easy: e.g. `notamClient.fetchAll()` could simply hit an API endpoint and return `NormalizedNotam[]` (the same domain type), bypassing `notamInterpreter` entirely. So the **abstraction layers are working in your favor** here.
*   **Map and UI coupling:** The only minor coupling I notice is that `MapView` knows about some UI state like the current `tool` (to ensure certain layers visible)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L726-L734). Currently it doesn’t do much with `tool` except that. In the future, if tools correspond to significantly different map modes, you might handle that differently. For example, if “History” tool should freeze the live updates and show historical data, you might not want the live Streams running. Right now, navigating to `/history` would still leave StreamsProvider polling in the background (the map would still be showing live drones unless you explicitly hide those layers). This is something to think about: maybe in history mode, you’ll set `VITE_USE_MOCKS=0` and point the services to history endpoints instead, or you’ll unmount StreamsProvider and mount a HistoryProvider. The architecture doesn’t cover that explicitly, but it’s an edge case of the persistent map design – it’s assuming all tools share the same base map context. It’s probably fine because you could also simply hide live layers and show a static overlay for history. Just ensure that the user isn’t confused by seeing live data when they intended to see past data. This might mean adding a bit more logic either in MapView or around Streams when `tool === "history"` (e.g. pause polling or use different sources). The cleanest might be to **extend StreamsProvider to be tool-aware**, so that in history mode it either switches to a different data source or stops. Right now there is no such logic (history panel might still be WIP). Keep an eye on that; it’s more of a design consideration than a code problem, but it will influence how you write the code.

Refactoring Suggestions for Future Sustainability
-------------------------------------------------

Based on the evaluation above, here are concrete suggestions to improve code quality and support the upcoming roadmap:

1.  **Enforce Structural & Style Conventions:** Continue and strengthen the conventions already in place:
    *   **Layer boundaries:** Maintain the rule that map-related code stays in `src/map` and never leaks into UI components[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L219-L227). Code reviews should flag any import of `ol/` classes in feature panels or services. The same goes for domain logic – keep using `src/shared` for any unit or time conversions so they remain single-sourced[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/docs/ARCHITECTURE.md#L14-L19). This prevents inconsistencies (e.g. two different ways to format an altitude).
    *   **Consistent naming:** Ensure all components and hooks follow a clear naming scheme. For example, use `SomethingPanel` for all sidebar panels, `useSomethingStream` for data hooks, etc. This consistency is partly there; just codify it to avoid confusion as more pieces are added.
    *   **File organization:** Encourage one React component per file (which you do), and co-locate related small components or styles. You might introduce an `index.ts` in each feature folder to export the main panel and any sub-components, making imports cleaner. For instance, `features/air/index.ts` could export `AirTrafficPanel` so that other modules import from `"@/features/air"` rather than a deep path. This is minor, but as the project grows it helps encapsulate feature modules.
    *   **ESLint/Prettier rules:** The project already has an ESLint config; using it diligently will enforce style (like no unused vars, proper hook dependencies, etc.). If not already, consider adding a Prettier config to standardize formatting (indentation, quotes, etc.) across contributions. This reduces noise in diffs and keeps style debates out of PRs.
    *   **Comments & docs:** Encourage documentation of non-obvious code sections. The docs in `docs/` are excellent; also adding brief comments in code where tricky logic occurs (e.g. the reasoning behind certain magic numbers in trackStore or the OL style closures) can help new devs. In particular, note the reasoning of things like `layer.changed()` on selection with a comment so future maintainers understand it’s to refresh styles due to closed-over state.
2.  **Simplify or Introduce Helper Abstractions:** Look for patterns that could be abstracted to avoid repetition or complexity:
    *   **Map layer updates:** Abstract common logic for updating vector layers. Both ADS-B and drone layers manage point + track features. You could create a utility in `src/map/layers/` that given a vector source, updates or adds a feature with a given ID and geometry. For example, a function `upsertPointFeature(source, id, coordinates)` that either sets a new feature or updates an existing one’s geometry. Similarly for track lines. This would remove duplicate code and centralize how feature IDs are constructed (you have conventions like `flight:${id}` vs `flightTrack:${id}`[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L463-L471)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L496-L505)). A helper could ensure those IDs are used consistently and perhaps encapsulate the logic of reusing existing features. Not only does this reduce code bulk, it also makes it less error-prone to implement future layers (they can reuse the same helper).
    *   **Selection highlighting:** As discussed, consider simplifying how selection state is passed to OL. Using feature properties (`feature.set("selected", true)`) and a style function that reads `feature.get("selected")` would eliminate the need for `layer.setStyle` on each selection change[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L597-L605). This is an abstraction of sorts: treating “selected” as just another piece of data on features. It aligns with how OL likes to work and would let you remove some of the special-case code with refs. You’d still keep the rule that Panels don’t manipulate OL directly – they’d call something like `mapApi.setFocus(kind, id)` which under the hood could mark the feature as selected and maybe also center the view.
    *   **Polling & data merging utilities:** Right now, the sensor service manually subscribes to its store for local sensor additions[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/sensors/sensorsClient.ts#L53-L61). If more such scenarios arise (multiple data sources to merge), you might abstract a pattern for “merge local and remote data”. Perhaps a custom hook or utility that given a polling result and a local store, returns a merged list and automatically triggers re-renders on store changes. This is somewhat niche, but if known-drones or other entities will have a similar concept (mixing live feed and user-defined entries), a helper could prevent writing similar code in multiple places.
    *   **Testing harness improvements:** The setup is good with MSW for network mocking and RTL for components. As the app grows, consider if any **test utilities** could reduce boilerplate. For example, a custom render that wraps components with `StreamsProvider` and router, so you don’t have to mock those in every test. You have to be careful not to turn tests into integration tests inadvertently, but providing context defaults can speed up writing tests for components that require those providers. Another utility could be a function to create sample domain objects (like a factory for Drone or Aircraft objects) to use in tests, ensuring they always have valid shape. This avoids duplicating object literals across tests (some duplication is fine, but if it grows, a factory helps).
    *   **Overcomplicated logic:** Identify if any logic can be simplified. For instance, the `SensorsPanel` splits base vs user sensors and then renders two sections conditionally[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L104-L113)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/features/sensors/SensorsPanel.tsx#L150-L159). This is clear enough, but you could imagine factoring that out if more panels do something similar. It’s not overengineered now – in fact the code is pretty straightforward – so there’s no urgent need to DRY things up at the expense of clarity. Just keep an eye out that complexity doesn’t creep in as features are added. If a function starts doing too many things (e.g. if `ObjectDetailsPanel` grows a lot to handle more entity types or editing, maybe split it into subcomponents per type), refactor early rather than later.
3.  **Anticipate Architectural Bottlenecks:**
    *   **Real-time data flood:** With real sensor data, especially if using WebSockets or high-frequency updates, the current polling approach might not scale. One bottleneck is React’s render loop – currently, state updates happen at most every second (for drones/sensors) because of polling. If you switch to a push model (e.g. server-sent events or web sockets streaming positions), you could end up causing React state updates dozens of times per second. That would overwhelm the UI. To mitigate, you could batch or throttle updates. For instance, collect incoming messages over 500ms intervals and then update context state once with the latest data. Or use requestAnimationFrame to tie updates to screen refresh rate. The architecture should accommodate this by possibly altering how `useSharedDronesStream` works under the hood (maybe it uses websockets but still only calls `setState` occasionally). The takeaway: **be mindful of update frequency**. The code’s modularity means you can swap the implementation without changing consumers, which is good. Just ensure the new implementation (say in Phase 5 or beyond) doesn’t naively set state too often.
    *   **Backend integration complexity:** Introducing a backend (Phase 6/7) will raise questions of data synchronization and authority. A potential bottleneck is that currently the frontend assumes it can manage state (for geofences, etc.) easily. Once multiple users or an external system can change data, you’ll need a strategy to keep the UI updated. Polling the backend for changes is one way (consistent with the current approach, just pointing to a different source). Using web sockets for server push is another. Either way, you might find that **a lot of similar polling logic is needed for backend data** (like geofences, user-created sensors, etc.). In that case, consider generalizing the polling hook to handle authenticated requests or different serialization. Possibly the existing `usePolling` can be extended or reused – it already handles the heavy lifting of periodic fetch and staleness. If the backend offers a unified endpoint (maybe a long-poll or a stream of all changes), that could simplify things, but often you’ll have separate APIs. Just beware of **race conditions** or conflicts: e.g. if two users add a geofence at nearly the same time, and one user’s app is polling every 5s, they might not see the other’s geofence immediately. For a security app, data consistency is important. Using faster polling or sockets for critical data might be needed. Ensure the architecture can plug this in – likely by adding new service hooks or extending StreamsProvider to include those channels.
    *   **User accounts & roles:** The codebase is currently in “admin mode” always[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L264-L272)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L374-L382). When roles and access control come into play, you might encounter architectural friction if not planned. For example, certain panels might be visible only to admins (maybe “Known Drones” management or geofence editing). The routing and component rendering might need to be gated. A simple approach is to have `useAuth()` provide the current user’s roles and then conditionally render buttons or entire panels based on that. To avoid peppering role checks everywhere, you could introduce a higher-order component or wrapper for routes that checks auth. But given the small number of protected areas, conditionals inline are fine. Just keep things like that in mind: e.g. a future requirement might be “non-admins can view drones but not add geofences”. The code should be structured such that it’s easy to disable or hide the Add button in `GeofencesPanel` if `user.role !== 'admin'`. Right now that panel doesn’t consider auth at all, but injecting `useAuth()` there and doing a quick check is trivial. So not a bottleneck per se, but something to implement carefully to maintain UX clarity.
    *   **Scalability of map interactions:** If the “swarm” scenario implies possibly dozens of drones and other objects, consider the **usability** as well – which can affect architecture. You might need grouping or filtering (maybe an ability to focus on one drone and temporarily declutter others). Implementing that could involve additional state (like “selected swarm leader” or filtering criteria) which might live in URL or context. The architecture can handle it – perhaps via query params or a context – but it’s an example of where thinking ahead helps. If you suspect certain features will be needed for managing many objects, you can design the state now (even if not used yet). For instance, a query param like `?focus=drone:123` could be introduced to indicate which drone is primary. That’s currently handled implicitly by selection, but maybe a concept of “swarm group” or “filtered area” could be another param. In short: identify possible _data flows_ for new features early so you can extend the routing or state scheme in a backward-compatible way.
4.  **Refactor/Rearchitect for Sustainability:**
    *   **Modularize the MapView:** As mentioned, splitting `MapView` logic by layer or function could make future maintenance much easier. One idea is to use **custom hooks for each layer** – e.g. `useSensorLayer(mapRef, sensorData, selectedEntity)` that encapsulates the effect currently in `MapView` for sensors[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L423-L432). This hook could be called inside MapView to attach the layer. It would still rely on closure variables but could take `selectedEntity` as a dependency properly. This would shrink the MapView component and isolate layer-specific quirks (like the coverage area styling, or future geofence drawing logic) into self-contained units. You already have separate modules for creating layers (`maaAmetOrthoWmts.ts`, `notams.ts` etc.), which is great[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/map/MapView.tsx#L219-L224). Taking it a step further with hooks or small sub-components might be worth it if MapView gains complexity (for instance, if MapView needs to handle editing interactions, that code could live in a `GeofenceEditLayer` hook).
    *   **Sustainable testing and CI:** As the codebase grows, ensure that the **testing strategy scales** too. Add tests for any new critical logic (e.g. if you implement a complex algorithm for predicting drone collisions or something, treat it like the altitude formatting – put it in shared and test it). Consider running E2E tests in a CI pipeline with each merge, so you catch any integration issues immediately. It might also be worthwhile to run some performance tests or at least use the browser devtools to monitor how the app performs with, say, 50 drones. If issues are found, refactor earlier rather than later.
    *   **Planning for Phase 6+:** Phase 6 (backend DB) and Phase 7 (proxies) will shift the app from “frontend-first” to more of a client-server model. One potential rearchitecture here is to introduce a **central API module** that all services use for fetches. Right now, each service directly calls `fetch(url)` inside `usePolling` or similar[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/polling/usePolling.ts#L134-L143). In a more integrated system, you might have a thin wrapper around fetch that injects auth tokens or handles base URLs. For example, a `apiClient.get('/drones')` that under the hood does `fetch(VITE_API_BASE + '/drones', { headers: auth… })`. This would prevent scattering auth logic throughout services. While not strictly necessary, it’s a good abstraction once a real backend exists. It also allows one spot to, say, refresh an auth token if it expires (since all requests funnel through it). Keep this in mind – the earlier you introduce such an abstraction (even if it just wraps window.fetch now), the easier it will be to expand.
    *   **User session management:** When implementing sessions, ensure to persist login state (probably in localStorage or via cookies if your backend uses them). A common pitfall is to assume a single “demo” user (which you have now) and then bolt on login later in a hurry. Since you’ve planned for it (with `VITE_AUTH_MODE` flag[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/agents.md#L264-L272)), do it cleanly: maybe a dedicated login page or modal, and on login success, set a context state and also store a token. Then all API calls pick up that token. None of this is in the code yet, but laying the groundwork (e.g. the suggested apiClient wrapper, and perhaps a placeholder route for login that currently just auto-logins as demo) could make the real implementation smoother.
    *   **Support for scenario replay:** This might require a slightly different data handling mode. One idea is to create a **“HistoryPlayer” service or context** separate from StreamsProvider. For example, when in history mode, you might not want to reuse the live Streams at all. Instead, you could have a `HistoryProvider` that fetches historical data (maybe as a whole batch or in chunks) and provides a hook like `useHistoryFrame(time)` that gives the state of all entities at a given timestamp. This is admittedly more complex, but trying to shoehorn history playback into the live polling hooks could get messy (e.g. you’d have to disable polling, load data, then simulate motion). It might be cleaner to instantiate a parallel set of state for history. Your router can ensure either StreamsProvider _or_ HistoryProvider is active, not both. This approach isolates the concerns and avoids tangled if/else in the polling hooks for “if history mode, do X”. The downside is duplicating some logic (history data likely uses same types as live data), but you can reuse the domain types and perhaps some mapping code.
    If implementing this, also separate the UI: maybe `HistoryPanel` for controls and a timeline, and the MapView can listen to a “current time” to display positions. Actually, since MapView currently derives positions from context, you’d need to feed it the historical positions instead. Perhaps the simplest hack: reuse the map layers but point them to _either_ live context or history context. This could be done if `useSharedDronesStream()` internally either calls live hook or a history hook based on some context. There are multiple ways; but key suggestion: **don’t convolute the live logic to handle history, consider a separate mode**. That will keep each simpler and more robust.
    *   **Swarm simulation considerations:** If simulation means user can run a scenario of many drones, maybe allow pausing/resuming, etc., you might incorporate that into the state (like a “simulation running” flag or speed control). Architecturally, this again suggests a specialized context or store for simulation scenarios, rather than overloading the live Streams. You could load a scenario file (maybe similar to the mock JSON) and then the simulation context “plays” it (similar to how `motionTick` works for mocks[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/adsbClient.ts#L18-L25)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/adsb/adsbClient.ts#L179-L185) but perhaps more controlled). Keeping simulation separate ensures the real feeds aren’t impacted and vice versa. The existing design for mocks (with a timer tick computing positions via `computeDroneAtTime`[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/drones/droneClient.ts#L33-L41)[GitHub](https://github.com/andresmoks720/VASIKAS/blob/815c8c864adf8fcb8fc7c03c38f947a4b605037a/src/services/drones/droneClient.ts#L45-L54)) is actually a good prototype of how a simulation mode might operate. Generalize that: instead of using it only when `ENV.useMocks`, allow a “playback mode” that uses a similar ticking mechanism on a recorded track.

In conclusion, the VASIKAS frontend is **well-architected and in a strong position to evolve**. By adhering to the established patterns (context for shared state, pure service logic, strict module boundaries) and applying the refactorings suggested (modularizing map logic, abstracting repetitive code, planning for mode-specific data handling), the codebase will remain clean and maintainable. As new phases roll out, always circle back to the principles in your docs: _Clarity beats cleverness, single source of truth, transform at boundaries, etc._ Those have served well so far. With careful attention to these details, the app can scale up to real-time data, multi-user operation, and complex scenarios without a deterioration in code quality or performance.

## Prompt:
suggest 5 codex prompts to improve the code

## Response:
Thought for 10s

Here are **5 high-leverage Codex prompts** to improve code quality + extendability (without changing your product scope). Each one is written so an agent can execute it as a focused PR.

* * *

1) Split `MapView` into layer modules + small “layer controllers”
-----------------------------------------------------------------

**Why:** `MapView` always becomes a 1000-line monster in map apps. Kill that early.

```md
Implement a refactor to reduce MapView complexity by extracting layer logic into dedicated modules.

Constraints (AGENTS.md):
- OpenLayers code stays in src/map/*
- src/features/* must NOT import OpenLayers
- WGS-84 lon/lat in domain; transform at OL boundary only
- NO PROXY

TASK:
1) Create a “layer controller” pattern:
   - src/map/layers/controllers/createDronesLayerController.ts
   - src/map/layers/controllers/createSensorsLayerController.ts
   - src/map/layers/controllers/createGeofencesLayerController.ts
   - src/map/layers/controllers/createNotamsLayerController.ts (if exists)
Each controller returns:
   - layer: VectorLayer
   - setData(data): void
   - setSelection(entityRef|null): void (optional)
   - dispose(): void
2) Update src/map/MapView.tsx to:
   - initialize controllers once
   - add their layers to the map
   - wire mapApi events to controller methods
   - keep MapView mostly orchestration (no per-layer feature logic)
3) Ensure behavior remains identical.
4) Add minimal unit tests for any extracted pure helpers (not OL).
5) Update docs/ARCHITECTURE.md (if structure changes) and docs/IMPLEMENTATION_PLAN.md -> Current status.
Run: npm run typecheck && npm run lint && npm run test.
```

* * *

2) Replace “clear + re-add all features” with incremental feature updates
-------------------------------------------------------------------------

**Why:** This is the #1 map perf killer once you have more than “toy” data (swarm, many sensors).

```md
Improve OpenLayers vector layer update performance by using incremental feature upserts.

Constraints:
- No OpenLayers in src/features/*
- Keep feature geometry in EPSG:4326 in domain; transform at creation/update boundary.
- Avoid pixel-perfect E2E assertions.

TASK:
1) Identify layers that currently do `source.clear()` on each poll (likely drones/sensors).
2) Implement a generic helper in src/map/utils/featureUpsert.ts:
   - upsertPointFeature(source, id, lonLat4326, props)
   - removeMissingFeatures(source, allowedIdsSet, idPrefix?)
   - updateGeometryIfChanged(feature, newGeometry)
3) Update drones/sensors layer controllers to:
   - upsert features by stable IDs
   - only update changed features
   - remove features that disappeared
4) Add a dev-only perf counter log (optional):
   - number of features updated/added/removed per tick
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
Run: npm run typecheck && npm run lint && npm run test.
```

* * *

3) Simplify selection highlighting: set `feature.set('selected', true)` instead of style closure hacks
------------------------------------------------------------------------------------------------------

**Why:** Style functions capturing React state get messy and fragile. Feature properties are cleaner.

```md
Refactor map selection highlighting to avoid style closures over React state.

Constraints:
- Only src/map/* may touch OpenLayers
- URL selection state stays in ?entity=kind:id
- Map selection should still update URL via callback
- No proxy

TASK:
1) Introduce a selection manager in src/map/selection/selectionManager.ts:
   - setSelectedEntity(entityRef|null)
   - internally tracks previous selection and toggles feature properties:
     - feature.set('selected', true/false)
2) Update layer styles so they depend on feature properties:
   - if feature.get('selected') => highlight (halo / thicker stroke)
   - otherwise normal
3) Update MapView wiring so when selectedEntity changes:
   - selectionManager updates feature flags without resetting layer style functions
   - no layer.changed() hacks unless truly required
4) Ensure click-on-map still selects entity and updates URL.
5) Add unit tests for selection manager logic (pure parts only; OL-specific bits can be smoke-tested).
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
Run: npm run typecheck && npm run lint && npm run test.
```

* * *

4) Introduce a tiny `apiClient` wrapper for fetch + consistent error handling (still NO PROXY)
----------------------------------------------------------------------------------------------

**Why:** Right now each service/client will reinvent timeouts, JSON parsing, and errors. Centralize that.

```md
Create a shared apiClient wrapper and refactor services to use it.

Constraints:
- NO PROXY (all browser fetch)
- Do not add new runtime deps
- Must support AbortController
- Must keep last-good-data behavior in polling hooks

TASK:
1) Add src/services/http/apiClient.ts:
   - getJson<T>(url, { signal, timeoutMs? }): Promise<T>
   - typed ApiError with { kind: "network"|"http"|"parse", status?, message, url }
   - optional helper: withTimeout(signal, ms)
2) Refactor notamClient, sensorsClient, dronesClient, adsbClient to use apiClient.getJson.
3) Ensure each client still supports mock mode (VITE_USE_MOCKS).
4) Add unit tests for apiClient error cases using Vitest (mock fetch).
5) Update docs/DATA_SOURCES.md (note consistent error handling) and docs/IMPLEMENTATION_PLAN.md -> Current status.
Run: npm run typecheck && npm run lint && npm run test.
```

* * *

5) Testing ergonomics: add domain factories + render helpers + stronger smoke paths
-----------------------------------------------------------------------------------

**Why:** Tests get painful if every test builds giant objects and mocks router/providers by hand.

```md
Improve test maintainability by adding factories and render helpers.

Constraints:
- Keep tests focused: pure logic in unit tests; OL heavy stuff in E2E
- Do not introduce new testing frameworks (use existing Vitest/RTL/MSW/Playwright)

TASK:
1) Add test factories under src/shared/test/factories/:
   - makeDrone(), makeAircraft(), makeSensor(), makeGeofence(), makeNotam()
   - always valid by UI_RULES (altitude.comment present, UTC strings)
2) Add a test render helper under src/shared/test/render.tsx:
   - wraps RTL render with Router + required Providers (StreamsProvider mocked or minimal)
   - helper to set initial route (e.g. /air?entity=...)
3) Refactor existing component tests to use factories + render helper.
4) Add 1 Playwright “smoke path” test if missing:
   - load map -> switch tools -> create geofence circle -> add sensor -> verify selection updates URL
   (do not do pixel assertions)
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
Run: npm run test && npm run test:e2e.
```

* * *

If you run these five, you’ll end up with:

*   a maintainable map core (controllers + clean selection)
*   much better performance headroom for swarms
*   consistent fetch/error handling ready for backend later
*   tests that don’t become a chore

Next natural “big win” after these would be **ScenarioPlayer + NDJSON replay** integration, but the above will make that implementation way easier.

## Prompt:
how to create a system to track tests and test coverage of this project

## Response:
Thought for 19s

To “track tests and test coverage” in a way that actually helps you ship (instead of worshipping a percentage), build a 3-layer system:

1.  **Local, fast feedback** (Vitest + coverage; Playwright smoke)
2.  **CI enforcement** (GitHub Actions checks + thresholds)
3.  **Visibility** (coverage reports + a simple test catalog + dashboards)

Below is a concrete setup that fits your stack (React + Vite + TS, Vitest/RTL, MSW, Playwright) and your rules (map is integration-heavy; pure logic gets unit tests).

* * *

1) Define what you’re measuring (so coverage numbers aren’t nonsense)
---------------------------------------------------------------------

### Test layers

*   **Unit tests (Vitest)**: pure logic (parsers, formatters, DTO→domain mapping, geo helpers, URL state)
*   **Component tests (RTL + Vitest)**: panel rendering, empty states, form flows (create geofence, add sensor)
*   **E2E smoke (Playwright)**: “smoke path” flows; _don’t try to coverage-instrument the map canvas_

### Coverage philosophy

*   Aim for **high coverage in `src/shared/` and `src/services/`**
*   Accept lower coverage in `src/map/` (OpenLayers integration) because it’s better verified by E2E + a few integration tests

* * *

2) Add scripts to `package.json`
--------------------------------

Keep your existing scripts, add these:

```json
{
  "scripts": {
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "test:coverage:ui": "vitest --ui --coverage",
    "test:e2e:report": "playwright test --reporter=html"
  }
}
```

* * *

3) Configure Vitest coverage (thresholds + sane include/exclude)
----------------------------------------------------------------

Create `vitest.config.ts` (or extend existing) with coverage settings:

```ts
import { defineConfig } from "vitest/config";
import react from "@vitejs/plugin-react";

export default defineConfig({
  plugins: [react()],
  test: {
    environment: "jsdom",
    setupFiles: ["src/test/setupTests.ts"],
    coverage: {
      provider: "v8",
      reporter: ["text", "html", "lcov", "json-summary"],
      reportsDirectory: "coverage",
      include: ["src/**/*.{ts,tsx}"],
      exclude: [
        "src/**/*.d.ts",
        "src/**/__tests__/**",
        "src/**/test/**",
        "src/test/**",
        "src/mocks/**",
        "src/**/index.ts",
        "src/app/main.tsx" // bootstrap noise
      ],
      thresholds: {
        // Start realistic. Raise over time.
        lines: 70,
        functions: 60,
        branches: 55,
        statements: 70
      }
    }
  }
});
```

Then add `src/test/setupTests.ts`:

```ts
import "@testing-library/jest-dom";
```

### Pro move: “ratchet” thresholds

Start with modest thresholds, then gradually increase them as you stabilize the code. Don’t set 95% and then spend a week testing getters.

* * *

4) Track E2E tests as a first-class artifact (not coverage)
-----------------------------------------------------------

In `playwright.config.ts`, make reporting and artifacts easy:

```ts
import { defineConfig } from "@playwright/test";

export default defineConfig({
  testDir: "e2e",
  reporter: [["list"], ["html", { open: "never" }]],
  use: {
    trace: "on-first-retry",
    screenshot: "only-on-failure",
    video: "retain-on-failure"
  }
});
```

This gives you stable test results + HTML report you can upload in CI.

* * *

5) CI: make tests + coverage a required gate
--------------------------------------------

Add `.github/workflows/ci.yml`:

```yaml
name: CI

on:
  pull_request:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - run: npm ci
      - run: npm run typecheck
      - run: npm run lint
      - run: npm run test:coverage

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage
          path: coverage

  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - run: npm ci
      - run: npx playwright install --with-deps
      - run: npm run build
      - run: npm run test:e2e

      - name: Upload playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
```

Then in GitHub repo settings, mark these checks **required** on PRs:

*   `CI / test`
*   `CI / e2e`

That’s your basic “system.”

* * *

6) Add a lightweight “test register” so you know what’s covered
---------------------------------------------------------------

Coverage tells you “how much,” not “what.” Add:

`docs/TESTING.md` with a simple matrix like:

*   **Smoke path (E2E):**
    *   Load map, switch tools, create circle geofence, add sensor, select entity
*   **Unit coverage “must haves”:**
    *   URL parsing
    *   altitude formatting rules
    *   ft↔m conversions
    *   NOTAM interpreter (fixtures)
    *   DTO→domain mapping

This becomes your human-readable tracking system.

Optional: add `docs/TEST_CASES.md` with stable IDs:

*   `E2E-001 Load app + map`
*   `E2E-002 Create circle geofence`
*   `UNIT-ALT-001 formatAltitude shows comment`
*   etc.

This is surprisingly useful when the project grows.

* * *

7) Visibility: choose one “coverage dashboard” path
---------------------------------------------------

### Option A (easy): artifacts only

*   CI uploads `coverage/` and `playwright-report/` as artifacts.
*   Good enough for internal teams.

### Option B (best dev UX): Codecov

*   Add Codecov upload step (1 small action)
*   PRs get a comment with coverage diff (great for review discipline)

### Option C (heavyweight): SonarCloud

*   More rules + maintainability metrics, but more setup

If you’re early-stage and moving fast: **Artifacts + thresholds + required checks** is already a strong system.

* * *

8) Project-specific coverage rules (fits your map-heavy app)
------------------------------------------------------------

Make it explicit in `docs/TESTING.md`:

*   Target **≥80% coverage** in:
    *   `src/shared/**`
    *   `src/services/**`
*   Accept lower coverage in:
    *   `src/map/**` (validate via E2E smoke + a few integration tests)
*   Never chase coverage in:
    *   generated files, type-only modules, bootstrap

* * *

9) Maintenance habits that keep the system alive
------------------------------------------------

*   Every PR that adds logic must add **either** unit tests **or** an E2E step (prefer unit unless it’s map behavior).
*   Keep `docs/IMPLEMENTATION_PLAN.md` updated (you already enforce this—good).
*   Monthly: bump thresholds slightly if the repo is stable (coverage ratchet).

* * *

If you want, I can write a single Codex prompt that implements **everything above** (scripts + vitest config + CI workflow + docs/TESTING.md + a starter test-case matrix) in one clean PR.

## Prompt:
create 5 first prompts to add such tests and coverage with codex

## Response:
Here are **5 “first PR” Codex prompts** to establish a real test+coverage tracking system. They’re ordered so you can merge them one by one without chaos.

* * *

Prompt 1 — Add Vitest coverage + reports + thresholds
-----------------------------------------------------

```md
Implement “Coverage v1” for this repo.

Constraints:
- npm only
- keep existing scripts intact
- do not add proxy
- keep map rendering tests minimal; focus on pure logic

TASK:
1) Add/modify vitest config to enable coverage:
   - provider: v8
   - reporters: text, html, lcov, json-summary
   - output dir: coverage/
2) Add npm scripts:
   - test:coverage -> vitest run --coverage
   - test:watch -> vitest
3) Configure coverage include/exclude so we measure src/**/*.{ts,tsx} but exclude:
   - src/mocks/**
   - src/test/**
   - **/*.d.ts
   - index barrels and app bootstrap if noisy
4) Add conservative initial thresholds (project-wide):
   - lines 70, statements 70, branches 55, functions 60
5) Ensure npm run test:coverage passes.
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status (mention coverage is enabled).

Return summary of files changed.
```

* * *

Prompt 2 — Add testing docs + a test register (what’s covered)
--------------------------------------------------------------

```md
Add a lightweight test tracking system in docs.

Constraints:
- keep it short and practical
- align with AGENTS.md testing philosophy: unit for logic, e2e for map integrations

TASK:
1) Create docs/TESTING.md that defines:
   - test layers (unit/component/e2e)
   - what should be tested where
   - how to run tests locally (commands)
   - coverage philosophy (high in shared/services; lower acceptable in map)
2) Create docs/TEST_CASES.md as a simple register with stable IDs:
   - UNIT-URL-001 parseTool/parseEntity
   - UNIT-ALT-001 formatAltitude comment rule
   - UI-SENS-001 SensorsPanel empty/list render
   - E2E-SMOKE-001 load map + switch tools
   Add status columns: Implemented? Location? Notes?
3) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Do not change runtime code.
```

* * *

Prompt 3 — Add GitHub Actions CI: typecheck + lint + unit coverage + artifacts
------------------------------------------------------------------------------

```md
Add CI workflow for tests + coverage.

Constraints:
- npm only
- do not add secrets
- keep it minimal, fast, and reliable

TASK:
1) Add .github/workflows/ci.yml with two jobs:
   - test job:
     - npm ci
     - npm run typecheck
     - npm run lint
     - npm run test:coverage
     - upload coverage/ as artifact
2) Ensure workflow triggers on pull_request and push to main.
3) Keep node version 20.
4) Update docs/TESTING.md with CI notes and docs/IMPLEMENTATION_PLAN.md -> Current status.

No Playwright yet in this prompt.
```

* * *

Prompt 4 — Add Playwright job + a basic E2E smoke + artifact report
-------------------------------------------------------------------

```md
Add E2E smoke testing with Playwright in CI.

Constraints:
- avoid pixel-perfect map assertions
- the smoke should validate core navigation and sidebar changes
- keep it robust and fast

TASK:
1) Ensure Playwright is configured:
   - playwright.config.ts in repo root (or existing location)
   - reporter includes HTML (open: never)
   - trace on first retry, screenshot/video on failure
2) Create e2e/smoke.spec.ts that:
   - loads /air
   - asserts a stable UI element exists (sidebar header/title)
   - switches tools via toolbar/buttons (air -> sensors -> geofences -> history)
   - asserts sidebar content changes (text-based assertions)
3) Extend .github/workflows/ci.yml with an e2e job:
   - npm ci
   - npx playwright install --with-deps
   - npm run build
   - npm run test:e2e
   - upload playwright-report as artifact always
4) Update docs/TEST_CASES.md to mark E2E-SMOKE-001 implemented, and update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

Prompt 5 — Add “first meaningful coverage” tests in critical logic modules
--------------------------------------------------------------------------

```md
Increase real coverage by adding tests for the most critical pure logic modules.

Constraints:
- prioritize src/shared and src/services
- follow UI_RULES: altitude must include comment; UTC handling rules
- do not add OpenLayers tests here

TASK:
1) Add/expand unit tests for:
   a) src/layout/MapShell/urlState.ts:
      - parseTool fallback
      - parseEntity valid/invalid
      - formatEntity roundtrip
   b) src/shared/units/altitude.ts:
      - meters<->feet conversion
      - formatAltitude ensures comment appears next to altitude
      - NOTAM/aircraft formatting shows both m and ft (if function exists)
   c) one DTO->domain mapping client (adsbClient or droneClient):
      - handles missing fields safely
      - outputs domain object with correct units
2) Add 1 RTL component test:
   - SensorsPanel renders empty state
   - SensorsPanel renders list row with status/stale indicator (if present)
3) Ensure npm run test and npm run test:coverage pass and thresholds still pass.
4) Update docs/TEST_CASES.md with test IDs and file locations.
5) Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

If you want a **single mega-prompt** that does all five in one PR, I can write that too—but merging them separately tends to keep review + debugging sane.

## Prompt:
create prompts that would create such testing culture for agents in our project

## Response:
Thought for 10s

Below are **copy/paste Codex prompts** designed to _teach and enforce_ a testing culture for agents working in your repo. These aren’t “one-off tasks” — they’re **repeatable operating procedures** that push agents into the habit of: _plan tests → implement → prove → document_.

You can use them as **PR templates**: each prompt yields a small, reviewable change and reinforces the norms.

* * *

1) “Test Plan First” Prompt (before touching code)
--------------------------------------------------

Use this at the start of any non-trivial ticket.

```md
You are implementing a change in this repo. Before writing code, produce a concrete TEST PLAN and update the test register.

Constraints (AGENTS.md):
- Unit tests for pure logic (shared/services/url parsing/formatters/mappers)
- E2E/Playwright for map/integration flows (avoid pixel assertions)
- NO PROXY

TASK:
1) Write a short “Test Plan” section in the PR diff by updating docs/TEST_CASES.md:
   - Add 2–6 new test cases with stable IDs (UNIT-*, UI-*, E2E-*)
   - For each: purpose, layer (unit/ui/e2e), and target file
2) Update docs/IMPLEMENTATION_PLAN.md -> Current status:
   - add “In progress: <feature> (tests planned: <IDs>)”
3) Only after the test plan is committed, implement the code + tests.

Definition of Done:
- Test cases are registered in docs/TEST_CASES.md
- Implementation includes the tests listed
- npm run typecheck && npm run lint && npm run test pass
- If map-related: npm run test:e2e includes at least one smoke step verifying UI/URL change
```

* * *

2) “Red-Green” Prompt for pure logic (formatters/parsers/mappers)
-----------------------------------------------------------------

For anything in `src/shared/**` or `src/services/**`.

```md
Implement this change with a “red-green” workflow for pure logic.

TASK:
1) Add/extend unit tests FIRST (Vitest):
   - Create failing tests that capture the desired behavior (include edge cases)
   - Keep tests small and explicit
2) Implement the logic until tests pass
3) Add one “regression test” for a likely future bug (off-by-one, invalid input, nulls)
4) Ensure coverage is meaningful:
   - avoid snapshot tests for pure functions
5) Run and ensure:
   - npm run test
   - npm run test:coverage
6) Update docs/TEST_CASES.md with implemented locations + mark status “done”.
7) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Constraints:
- Do not import OpenLayers into tests.
- Keep UTC + unit rules (UI_RULES.md).
```

* * *

3) “Map Feature = E2E Proof” Prompt (no pixel nonsense)
-------------------------------------------------------

For anything that touches OpenLayers or map overlays.

```md
Implement this map-related change and prove it via E2E.

Constraints:
- OpenLayers code only in src/map/*
- Panels must not import OpenLayers
- E2E should verify UI/URL behavior, not pixel-perfect map rendering

TASK:
1) Add/extend a Playwright test FIRST (or alongside) that:
   - navigates to the relevant tool route
   - performs the user action (click marker, create geofence, toggle layer)
   - asserts URL/query state changes OR sidebar content changes OR list count changes
2) Implement the map change.
3) Add unit tests only for extracted pure helpers (geo conversions, parsing, filters).
4) Ensure:
   - npm run test:e2e passes
   - test artifacts are deterministic (no random sleeps; use expect().toBeVisible() etc.)
5) Update docs/TEST_CASES.md:
   - include the E2E test ID and file location
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Never:
- assert exact pixel colors/positions on the map canvas
- add a proxy to make endpoints work
```

* * *

4) “Bugfix = Regression Test Mandatory” Prompt
----------------------------------------------

This creates a real “no bug without a test” culture.

```md
Fix this bug and ensure it never returns.

TASK:
1) Add a failing test that reproduces the bug:
   - Unit test if it’s a pure function or mapping
   - RTL component test if it’s rendering behavior
   - Playwright test if it’s a flow/regression involving map or routing
2) Only after the test fails, implement the fix.
3) Ensure the new test is minimal and explains the bug scenario clearly.
4) Add the test case ID to docs/TEST_CASES.md with a short “Bug prevented” note.
5) Run:
   - npm run typecheck
   - npm run lint
   - npm run test
   - (and npm run test:e2e if it’s an e2e regression)

Update docs/IMPLEMENTATION_PLAN.md -> Current status.
```

* * *

5) “Refactor with Guardrails” Prompt (no drive-by rewrites)
-----------------------------------------------------------

Refactors tend to delete tests; this prompt prevents that.

```md
Refactor code while preserving behavior, and add safety tests for changed boundaries.

TASK:
1) Identify behavior surfaces affected by refactor:
   - URL contract
   - domain formatting rules (altitude/time/units)
   - polling staleness handling
   - map layer visibility/selection semantics
2) Add/confirm tests exist for each surface:
   - If missing, add a minimal test BEFORE refactoring
3) Perform the refactor in small commits:
   - mechanical move (no behavior change)
   - then behavior improvement (if needed)
4) Ensure no coverage drop in critical areas (shared/services).
5) Update docs/TEST_CASES.md:
   - mark any new tests as “done”
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Hard constraints:
- No new dependencies unless explicitly requested.
- No OpenLayers inside features panels.
```

* * *

6) “Definition of Done Enforcement” Prompt (culture-as-code)
------------------------------------------------------------

This one is great to run occasionally — it “teaches the repo” by updating AGENTS.

```md
Strengthen testing culture by codifying it in repo docs.

TASK:
1) Update AGENTS.md with a “Testing Culture” section that states:
   - every non-trivial change must add/adjust tests
   - bugfixes require a regression test
   - map work requires Playwright proof (no pixel assertions)
   - docs/TEST_CASES.md must be updated in the same PR
   - docs/IMPLEMENTATION_PLAN.md must be updated in the same PR
2) Create or update docs/TESTING.md with:
   - test pyramid expectations for this repo
   - coverage philosophy: high for shared/services, integration via e2e for map
   - commands to run + CI expectations
3) Add a PR checklist template under .github/pull_request_template.md:
   - checkboxes for typecheck/lint/tests/coverage/e2e + docs updates
4) Ensure no runtime code is changed.

Outcome: future agents will follow the same norms automatically.
```

* * *

7) “Test Debt Payment Sprint” Prompt (ratchet coverage without drama)
---------------------------------------------------------------------

Use this when you want to steadily improve without refactoring.

```md
Pay down test debt in the highest-leverage modules.

TASK:
1) Identify top 3 modules in src/shared or src/services that lack tests (formatters/mappers/parsers/polling).
2) Add unit tests that cover:
   - happy path
   - null/missing fields
   - invalid input
   - boundary values (0, negative, huge, empty string)
3) Add 1 RTL test for a panel that’s under-tested (empty + list render).
4) Update docs/TEST_CASES.md with IDs and locations.
5) Run test:coverage and if thresholds are met, optionally bump thresholds by +2 lines/statement (tiny ratchet).
6) Update docs/IMPLEMENTATION_PLAN.md -> Current status.

Do not change product behavior. Only tests + minimal refactors to enable testing.
```

* * *

### If you want this to _really_ stick

Make the workflow enforceable:

*   Add `.github/pull_request_template.md` with checkboxes
*   CI required checks: `typecheck`, `lint`, `test:coverage`, `test:e2e`
*   Require updates to `docs/IMPLEMENTATION_PLAN.md` and `docs/TEST_CASES.md` for “non-trivial” work (you already enforce the plan — extending that to the test register is a nice cultural lock)

These prompts basically turn “testing culture” into a repeatable ritual that even chaotic AI agents will follow.



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)